# -*- coding: utf-8 -*-

# === BLOQUE 0 ‚Äî OBJETIVOS DEL PROGRAMA 5R6M-1-2-4-8-16 ===
#
# Este script coordina:
# - Lectura de CSV enriquecidos de los bots fulll45‚Äìfulll50
# - Control de Martingala 1-2-4-8-16
# - Gesti√≥n de tokens DEMO/REAL
# - IA (XGBoost) para probabilidades de √©xito
# - HUD visual con Prob IA, % √©xito, saldo, meta y eventos
#
# √çNDICE DE BLOQUES:
#   BLOQUE 1 ‚Äî IMPORTS Y ENTORNO B√ÅSICO
#   BLOQUE 2 ‚Äî CONFIGURACI√ìN GLOBAL (MARTINGALA, HUD, AUDIO, IA)
#   BLOQUE 3 ‚Äî CONFIGURACI√ìN DE REENTRENAMIENTO Y MODOS IA
#   BLOQUE 4 ‚Äî AUDIO (INIT Y REPRODUCCI√ìN)
#   BLOQUE 5 ‚Äî TOKENS, BOT_NAMES Y ESTADO GLOBAL
#   BLOQUE 6 ‚Äî LOCKS, FIRMAS Y UTILIDADES CSV
#   BLOQUE 7 ‚Äî ORDEN DE REAL Y CONTROL DE TOKEN
#   BLOQUE 8 ‚Äî NORMALIZACI√ìN Y PUNTAJE DE ESTRATEGIA
#   BLOQUE 9 ‚Äî DETECCI√ìN DE MARTINGALA Y REINICIOS
#   BLOQUE 10 ‚Äî IA: DATASET, MODELO Y PREDICCI√ìN
#   BLOQUE 11 ‚Äî HUD Y PANEL VISUAL
#   BLOQUE 12 ‚Äî CONTROL MANUAL REAL Y CONDICIONES SEGURAS
#   BLOQUE 13 ‚Äî LOOP PRINCIPAL, WEBSOCKET Y TECLADO
#   BLOQUE 99 ‚Äî RESUMEN FINAL DE LO QUE SE LOGRA
#
# Nota:
#   Esta organizaci√≥n NO cambia la l√≥gica del programa.
#   Solo a√±ade estructura para facilitar futuras modificaciones.
#
# === FIN BLOQUE 0 ===

# === BLOQUE 1 ‚Äî IMPORTS Y ENTORNO B√ÅSICO ===
import os, csv, time, random, asyncio, json, re
from collections import deque
from unicodedata import normalize
import threading
from datetime import datetime, timedelta
from contextlib import contextmanager
import sys
import shutil
import joblib
import numpy as np
import pandas as pd
import importlib
import traceback

import math
import hashlib
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, f1_score, fbeta_score, brier_score_loss
from sklearn.calibration import CalibratedClassifierCV
from sklearn.linear_model import LogisticRegression
from sklearn.isotonic import IsotonicRegression

import warnings
warnings.filterwarnings(
    "ignore",
    message="X does not have valid feature names, but StandardScaler was fitted with feature names"
)


def _load_optional_module(name: str):
    try:
        return importlib.import_module(name)
    except Exception:
        return None


websockets = _load_optional_module("websockets")
WEBSOCKETS_OK = websockets is not None


colorama = _load_optional_module("colorama")
if colorama is not None:
    Fore = colorama.Fore
    Style = colorama.Style
    init = colorama.init
else:
    class _NoColor:
        def __getattr__(self, _name):
            return ""
    Fore = _NoColor()
    Style = _NoColor()
    def init(*args, **kwargs):
        return None

pygame = _load_optional_module("pygame")
PYGAME_OK = pygame is not None
if not PYGAME_OK:
    class _DummyMixer:
        def get_init(self):
            return False
        def pre_init(self, *args, **kwargs):
            return None
        def init(self, *args, **kwargs):
            return None
        def quit(self):
            return None
        def Sound(self, *args, **kwargs):
            return None

    class _DummyPygame:
        mixer = _DummyMixer()

    pygame = _DummyPygame()

winsound = _load_optional_module("winsound")

# ============================================================
# XGBoost (robusto): permite correr aunque xgboost no est√©
# ============================================================
try:
    import xgboost as xgb  # opcional (por compatibilidad)
    from xgboost import XGBClassifier
    _XGBOOST_OK = True
except Exception:
    xgb = None
    XGBClassifier = None
    _XGBOOST_OK = False

# --- Teclado Windows (seguro y √∫nico) ---
try:
    import msvcrt as _msvcrt
    class _MSWrap:
        def __bool__(self): return True
        def kbhit(self):
            try: return _msvcrt.kbhit()
            except Exception: return False
        def getch(self):
            try: return _msvcrt.getch()
            except Exception: return b''
    msvcrt = _MSWrap()
    HAVE_MSVCRT = True
except Exception:
    class _DummyMS:
        def __bool__(self): return False
        def kbhit(self): return False
        def getch(self): return b''
    msvcrt = _DummyMS()
    HAVE_MSVCRT = False

# Forzar la ruta fija al directorio del script
try:
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    print(f"üìÅ Directorio de trabajo fijado a: {script_dir}")
except Exception as e:
    print(f"‚ö†Ô∏è No se pudo cambiar al directorio del script: {e}. Usando cwd actual.")

init(autoreset=True)
# === FIN BLOQUE 1 ===

# === BLOQUE 2 ‚Äî CONFIGURACI√ìN GLOBAL (MARTINGALA, HUD, AUDIO, IA) ===
# === CONFIGURACI√ìN DE MARTINGALA ===
MARTI_ESCALADO = [1, 2, 4, 8, 16, 32]  # Escalado ajustado a 6 pasos
MONTO_TOL = 0.01  # Tolerancia para redondeos
SONAR_TAMBIEN_EN_DEMO = False  # Activar sonidos para victorias en DEMO
SONAR_SOLO_EN_GATEWIN = True   # Solo sonar dentro de la ventana GateWIN
SONAR_FUERA_DE_GATEWIN = False # Permitir sonidos fuera de GateWIN si se se habilita
AUDIO_TIMEOUT_S = 0  # 0 significa sin timeout

# === REMATE (modo cierre solo con WIN) ===
MODO_REMATE = True           # Continuar hasta WIN o fin de Martingala
REMATE_SIN_TOPE = False      # Limitado por MAX_CICLOS

# === HUD / Layout ===
HUD_LAYOUT = "bottom_center"  # Fijado en centro inferior
HUD_VISIBLE = True       # Para ocultarlo con tecla

# --- Objetivos / umbrales globales de IA ---
IA_OBJETIVO_REAL_THR = 0.70   # objetivo de calidad REAL (meta: 70% aprox)
IA_ACTIVACION_REAL_THR = 0.85 # m√≠nimo operativo para activar se√±al REAL
IA_ACTIVACION_REAL_THR_POST_N15 = 0.75  # al cumplir n m√≠nimo por bot, el umbral operativo baja solo hasta 75%
IA_ACTIVACION_REAL_MIN_N_POR_BOT = 15   # condici√≥n: todos los bots deben tener al menos n=15

# --- Or√°culo visual ---
ORACULO_THR_MIN   = IA_ACTIVACION_REAL_THR
ORACULO_N_MIN     = 40
ORACULO_DELTA_PRE = 0.05

# Umbral visual/alerta: alineado al m√≠nimo operativo REAL
IA_VERDE_THR = IA_ACTIVACION_REAL_THR
IA_SUCESO_LOOKBACK = 16
IA_SUCESO_DELTA_MIN = 0.035
IA_SUCESO_EVENTO_MIN = 0.55
IA_SENSOR_DOM_HOT = 0.95
IA_SENSOR_MIN_HOT_FEATS = 3
IA_SENSOR_MIN_SAMPLE = 30
IA_REDUNDANCY_SCORE_PENALTY = 0.03
IA_SENSOR_PLANO_SCORE_PENALTY = 0.04
IA_SUCESO_SCORE_WEIGHT = 0.08
IA_OBSERVE_THR = 0.70
AUTO_REAL_THR = IA_OBJETIVO_REAL_THR      # techo: mantener foco en acercarse al 70%
AUTO_REAL_THR_MIN = IA_ACTIVACION_REAL_THR  # piso: permitir activaci√≥n REAL desde 85%
AUTO_REAL_TOP_Q = 0.80    # cuant√≠l de probs hist√≥ricas para calibrar el gate REAL
AUTO_REAL_MARGIN = 0.01   # peque√±o margen para evitar quedar fuera por d√©cimas
AUTO_REAL_LOG_MAX_ROWS = 300  # m√°ximo de se√±ales hist√≥ricas usadas en la calibraci√≥n
AUTO_REAL_LIVE_MIN_BOTS = 3   # m√≠nimos bots con prob viva para calibraci√≥n por tick

# Umbral "operativo/UI" (se√±ales actuales, sem√°foro, etc.)
IA_METRIC_THRESHOLD = IA_ACTIVACION_REAL_THR
# Modo cl√°sico solicitado: activaci√≥n REAL inmediata con prob IA >= 85%.
# Mantiene lock de un solo bot en REAL y ciclo martingala global en HUD.
REAL_CLASSIC_GATE = True

# ‚úÖ Umbral SOLO para auditor√≠a/calibraci√≥n (se√±ales CERRADAS en ia_signals_log)
# Esto es lo que quer√≠as: contar cierres desde 60% sin afectar la operativa.
IA_CALIB_THRESHOLD = 0.60
IA_CALIB_GOAL_THRESHOLD = IA_OBJETIVO_REAL_THR  # objetivo real: medir cierres fuertes cerca de 70%
IA_CALIB_MIN_CLOSED = 200  # m√≠nimo recomendado para considerar estable la auditor√≠a

# Recomendaciones operativas conservadoras (anti-sobreconfianza)
IA_TEMP_THR_HIGH = 0.80              # umbral temporal sugerido cuando la muestra fuerte es baja
IA_MIN_CLOSED_70_FOR_STRUCT = 200    # m√≠nimo de cierres IA>=70% para cambios estructurales
IA_SHRINK_ALPHA = 0.60               # p_ajustada = alpha*p + (1-alpha)*tasa_base
IA_SHRINK_ALPHA_MIN = 0.45           # piso de mezcla (m√°s conservador en descalibraci√≥n fuerte)
IA_SHRINK_ALPHA_MAX = 0.85           # techo de mezcla (m√°s sensible cuando la calibraci√≥n mejora)
IA_BASE_RATE_WINDOW = 300            # cierres recientes para tasa base rolling
# Cap conservador de probabilidad durante warmup para evitar inflado (ej. 99-100%).
IA_WARMUP_PROB_CAP_MIN = 0.70
IA_WARMUP_PROB_CAP_MAX = 0.85
IA_WARMUP_CAP_RAMP_ROWS = 120         # rampa de cap en warmup: permite tocar 75% antes sin abrir 90%
IA_WARMUP_LOW_EVIDENCE_CAP_BASE = 0.80
IA_WARMUP_LOW_EVIDENCE_CAP_POST_N15 = 0.85

AUTO_REAL_ALLOW_UNRELIABLE_POST_N15 = True
AUTO_REAL_UNRELIABLE_MIN_N = 80
AUTO_REAL_UNRELIABLE_MIN_PROB = 0.63  # m√°s permisivo en reliable=false (sube activaci√≥n y riesgo de falsos positivos)
AUTO_REAL_UNRELIABLE_MIN_AUC = 0.50   # si AUC cae bajo azar, no habilitar AUTO aunque post-n15
AUTO_REAL_BLOCK_WHEN_WARMUP = True    # durante warmup evita promoci√≥n AUTO en modo unreliable
# Ajuste m√≠nimo anti-congelamiento lateral: permite bajar el umbral UNREL
# solo cuando hay evidencia operativa consistente por bot.
AUTO_REAL_UNREL_LATERAL_ADAPT_ENABLE = True
AUTO_REAL_UNREL_LATERAL_MIN_N = 70
AUTO_REAL_UNREL_LATERAL_MIN_WR = 0.56
AUTO_REAL_UNREL_LATERAL_MIN_PROB = 0.58
# Bypass controlado: si la compuerta REAL ya est√° s√≥lida en vivo, permitir AUTO
# aunque el modelo siga en warmup/reliable=false.
AUTO_REAL_UNRELIABLE_ALLOW_STRONG_GATE = True
AUTO_REAL_UNRELIABLE_GATE_MIN_PROB = IA_ACTIVACION_REAL_THR_POST_N15

# Guardas por bot para reducir desalineaci√≥n Prob IA vs % √âxito observado en HUD.
IA_PROMO_MIN_WR_POR_BOT = 0.45         # no promover bots con WR rolling claramente negativo
IA_PROMO_MAX_OVERCONF_GAP = 0.18       # si p_real supera WR por >18pp con evidencia, bloquear promoci√≥n

# Gate de calidad operativo (objetivo: mejorar precisi√≥n real, no volumen)
GATE_RACHA_NEG_BLOQUEO = -2.0        # bloquear se√±ales con racha <= -2
GATE_PERMITE_REBOTE_EN_NEG = True    # permitir excepci√≥n si hay rebote confirmado
GATE_ACTIVO_MIN_MUESTRA = 40         # m√≠nimo de cierres por activo para evaluar r√©gimen
GATE_ACTIVO_MIN_WR = 0.48            # si WR reciente por activo cae debajo, bloquear temporalmente
GATE_ACTIVO_LOOKBACK = 180           # cierres recientes por bot para estimar r√©gimen
# Gate por segmentos (payout/vol/hora): prioriza zonas con se√±al estable de racha_actual
GATE_SEGMENTO_ENABLED = True
GATE_SEGMENTO_MIN_MUESTRA = 35
GATE_SEGMENTO_MIN_WR = 0.50
GATE_SEGMENTO_LOOKBACK = 240

# Candados inteligentes: evita bloqueos r√≠gidos en empates/planicies cuando ya
# hay evidencia real robusta de un bot claramente apto.
SMART_LOCKS_ENABLE = True
SMART_CLONE_OVERRIDE_MIN_N = 120
SMART_CLONE_OVERRIDE_MIN_LB = 0.58
SMART_CLONE_OVERRIDE_MIN_PROB = 0.78
SMART_CLONE_OVERRIDE_MIN_GAP = 0.002

# Embudo IA en 2 capas: A=r√©gimen (tradeable), B=prob fina (modelo)
REGIME_GATE_MIN_SCORE = 0.52          # m√≠nimo score de r√©gimen para considerar se√±al
REGIME_GATE_WEIGHT_PROB = 0.70        # peso de la prob del modelo en ranking final
REGIME_GATE_WEIGHT_REGIME = 0.20      # peso de la calidad de r√©gimen
REGIME_GATE_WEIGHT_EVIDENCE = 0.10    # peso de evidencia hist√≥rica real (N + WR)
EVIDENCE_MIN_N_HARD = 60              # si hay >=N evidencia fuerte, exigir WR m√≠nimo
EVIDENCE_MIN_WR_HARD = 0.70           # objetivo de calidad real por bot para habilitar auto-REAL
EVIDENCE_MIN_LB_HARD = 0.65           # candado conservador: l√≠mite inferior m√≠nimo con evidencia fuerte
EVIDENCE_MIN_N_SOFT = 20              # evidencia m√≠nima blanda para validar LB intermedio
EVIDENCE_MIN_LB_SOFT = 0.55           # LB m√≠nimo cuando N a√∫n es intermedio
EVIDENCE_LOW_N_EXTRA_MARGIN = 0.05    # margen extra de p_real si a√∫n no hay N m√≠nimo blando
POSTERIOR_EVIDENCE_K = 80             # inercia: m√°s alto = m√°s peso al hist√≥rico para p_real
POSTERIOR_REGIME_BLEND = 0.35         # mezcla del score de r√©gimen dentro de p_real
EVIDENCE_CACHE_TTL_S = 20.0

# Guardas de honestidad operacional (alineadas al diagn√≥stico)
DIAG_PATH = "diagnostico_pipeline_ia.json"
ORIENTATION_RECHECK_S = 90.0
ORIENTATION_FLIP_MIN_DELTA = 0.03
ORIENTATION_MIN_CLOSED = 80
HARD_GATE_MAX_GAP_HIGH_BINS = 0.10
HARD_GATE_MIN_N_FOR_HIGH_THR = 200
INCREMENTAL_DUP_SCAN_LINES = 6000

# Umbral del aviso de audio (archivo ia_scifi_02_ia53_dry.wav)
AUDIO_IA53_THR = IA_ACTIVACION_REAL_THR

# Anti-spam + rearme
AUDIO_IA53_COOLDOWN_S = 20     # no repetir m√°s de 1 vez cada X segundos por bot
AUDIO_IA53_RESET_HYST = 0.03   # se rearma cuando cae por debajo de (thr - hyst)

# === Cach√© de sonidos ===
SOUND_CACHE = {}
SOUND_LOAD_ERRORS = set()
SOUND_PATHS = {
    "ganancia_real": "ganabot.wav",
    "ganancia_demo": "ganabot.wav",
    "perdida_real": "perdida.wav",
    "perdida_demo": "perdida.wav",
    "meta_15": "meta15%.wav",
    "racha_detectada": "detectaracha.wav",
    "test": "test.wav",
    "ia_53": "ia_scifi_08_53porciento_dry.wav",

}
AUDIO_AVAILABLE = False
META_ACEPTADA = False
MODAL_ACTIVO = False
sonido_disparado = False
# === FIN BLOQUE 2 ===

# === BLOQUE 3 ‚Äî CONFIGURACI√ìN DE REENTRENAMIENTO Y MODOS IA ===
# === CONFIGURACI√ìN DE REENTRENAMIENTO ===
RETRAIN_INTERVAL_ROWS = 100     # por volumen
RETRAIN_INTERVAL_MIN  = 15      # por tiempo
MIN_NEW_ROWS_FOR_TIME = 20      # al menos 20 filas nuevas para reentrenar por tiempo
MAX_DATASET_ROWS = 10000
last_retrain_count = 0
last_retrain_ts    = time.time()  # Inicializado al boot para arranque en fr√≠o
AUTO_RETRAIN_TICK_S = 20.0  # reintento peri√≥dico para no quedarse sin modelo tras warmup
IA_NO_MODEL_LOG_COOLDOWN_S = 30.0  # evita spam cuando a√∫n no hay modelo
_entrenando_lock = threading.Lock()  # Lock para antireentradas en maybe_retrain

# === MODO ENTRENAMIENTO CON POCA DATA (no toca la l√≥gica de IA) ===
LOW_DATA_MODE = True           # True = permite entrenar con muy pocas filas
MIN_FIT_ROWS_PROD = 100        # umbral ‚Äúconfiable‚Äù para producci√≥n (lo que ya usabas)
MIN_FIT_ROWS_LOW  = 4          # umbral m√≠nimo para permitir fit ‚Äúexperimental‚Äù
RELIABLE_POS_MIN  = 20         # m√≠nimos para considerar fiable (calibraci√≥n/umbral estable)
RELIABLE_NEG_MIN  = 20

# Modo manual desactivado: priorizamos automatizaci√≥n completa por Prob IA.
# Si luego quieres volver al modo manual, ponlo en True.
MODO_REAL_MANUAL = False

# Martingala global
marti_paso = 0
marti_activa = False

# Contador global de ciclos de martingala (HUD + orquestaci√≥n autom√°tica)
# 0 = sin p√©rdidas consecutivas en REAL; 1..MAX_CICLOS = racha de p√©rdidas vigente.
marti_ciclos_perdidos = 0

# Anti-repetici√≥n de bot en REAL:
# - Si el HUD est√° en C1, se puede repetir bot.
# - Si el HUD est√° en C2..C{MAX_CICLOS}, se evita reusar el √∫ltimo bot REAL.
ultimo_bot_real = None

# Rotaci√≥n estricta por corrida de martingala REAL (C1..C5)
# Guarda el orden de bots usados en la corrida activa para evitar repeticiones.
bots_usados_en_esta_marti = []

# Auditor√≠a de secuencia martingala (C1..C{MAX_CICLOS}) para traza expl√≠cita.
marti_audit_run_id = 1
marti_audit_historial = deque(maxlen=80)
marti_audit_desviaciones = 0
marti_audit_ultimo_ciclo_ordenado = None

# Nueva: Umbrales m√≠nimos para historial IA
MIN_IA_SENIALES_CONF = 10  # M√≠nimo se√±ales cerradas para confiar en prob_hist
MIN_AUC_CONF = 0.65        # AUC m√≠nimo para audios/colores verdes
MAX_CLASS_IMBALANCE = 0.8  # M√°x proporci√≥n pos/neg para entrenar (evita 99% wins)
AUC_DROP_TOL = 0.05        # Tolerancia para no machacar modelo si AUC baja
TRAIN_REFRESH_STALE_MIN = 45 * 60   # forzar revisi√≥n de refresh si el campe√≥n lleva mucho sin actualizar (s)
TRAIN_REFRESH_MIN_GROWTH = 0.20     # crecimiento m√≠nimo relativo de dataset para considerar stale override
TRAIN_REFRESH_MIN_ABS_ROWS = 60      # crecimiento m√≠nimo absoluto de filas para stale override
TRAIN_REFRESH_MIN_ABS_ROWS_LOWN = 20 # override para modelos peque√±os: refresco m√°s temprano
TRAIN_REFRESH_LOWN_CUTOFF = 180      # n por debajo de esto usa umbral absoluto reducido
TRAIN_CANARY_FORCE_UNRELIABLE = True # canary: refresca probs pero bloquea REAL hasta validar en operaci√≥n cerrada
CANARY_MIN_CLOSED_SIGNALS = 20      # cierres m√≠nimos para decidir salida de canary
CANARY_MIN_HITRATE = 0.50           # hit-rate m√≠nimo de cierres durante canary para promover
CANARY_RETRY_BATCH = 10             # si canary falla, ampliar ventana en este tama√±o
CANARY_EVAL_COOLDOWN_S = 10.0       # evaluar progreso canary como m√°ximo cada N segundos
# Escape controlado: evita deadlock cuando CANARY no acumula cierres pero la compuerta REAL ya est√° s√≥lida.
CANARY_ALLOW_STRONG_GATE_REAL = True
CANARY_STRONG_GATE_MIN_PROB = IA_ACTIVACION_REAL_THR_POST_N15
CANARY_STRONG_GATE_MIN_CONFIRM = 2
TRAIN_ROWS_DROP_GUARD_RATIO = 0.35  # no reemplazar modelo si la muestra cae demasiado vs meta anterior
TRAIN_ROWS_DROP_GUARD_MIN_PREV = 120  # activar guard solo si el modelo previo ya ten√≠a muestra razonable
FEATURE_MAX_DOMINANCE = 0.90  # Si una feature repite >90%, se considera casi constante
TRAIN_WARMUP_MIN_ROWS = 250          # evita declarar modo confiable sin muestra m√≠nima
INPUT_DUP_DIAG_COOLDOWN_S = 25.0     # anti-spam de diagn√≥stico por inputs duplicados
CLONED_PROB_TICKS_ALERT = 3          # ticks consecutivos de probs clonadas para alertar
INPUT_DUP_FINGERPRINT_DECIMALS = 6   # precisi√≥n estable para huella de inputs IA


# Sem√°foro de calibraci√≥n (lectura r√°pida PredMedia/Real/Inflaci√≥n/n)
SEM_CAL_N_ROJO = 30
SEM_CAL_N_AMARILLO = 100
SEM_CAL_INFL_OK_PP = 5.0
SEM_CAL_INFL_WARN_PP = 15.0

# ============================================================
# Defaults IA (centralizados, sin duplicados)
# ============================================================
MIN_TRAIN_ROWS  = 250
TEST_SIZE_FRAC  = 0.20
MIN_TEST_ROWS   = 40
THR_DEFAULT = 0.50
MIN_TRAIN_ROWS_ADAPTIVE = 40  # evita entrenar con train rid√≠culo cuando el dataset a√∫n es chico
MIN_TRAIN_SHARE_ADAPTIVE = 0.60

# Split honesto: TRAIN_BASE (pasado) / CALIB (m√°s reciente) / TEST (√∫ltimo)
CALIB_SIZE_FRAC = 0.15
MIN_CALIB_ROWS = 80

# Feature list can√≥nica (si tu reentreno define otra, ah√≠ la cambias UNA vez)
# ============================================================
# Feature set CORE (13) ‚Äî estable y sin mutaciones
# ============================================================
FEATURE_NAMES_CORE_13 = [
    "rsi_9","rsi_14","sma_5","sma_spread","cruce_sma","breakout",
    "rsi_reversion","racha_actual","payout","puntaje_estrategia",
    "volatilidad","es_rebote","hora_bucket",
]

# Por defecto entrenamos SOLO con las 13 core (modo estable)
FEATURE_NAMES_INTERACCIONES = [
    "racha_x_rebote",
    "rev_x_breakout",
]

# Gobernanza calidad>cantidad: entrenar solo con features que realmente aporten.
FEATURE_ALWAYS_KEEP = ["racha_actual"]
FEATURE_MAX_PROD = 4
FEATURE_SET_PROD_WARMUP = ["racha_actual", "payout", "breakout", "rsi_14", "es_rebote", "puntaje_estrategia"]
FEATURE_SET_CORE_EXT = [
    "racha_actual", "payout", "rsi_14", "breakout",
    "rsi_9", "cruce_sma", "rsi_reversion", "es_rebote",
]
FEATURE_SET_CORE_EXT_MIN_ROWS = 500
FEATURE_MIN_AUC_DELTA = 0.015      # aporte m√≠nimo (|AUC_uni - 0.5|)
FEATURE_MAX_DOMINANCE_GATE = 0.965 # evita casi-constantes
FEATURE_DYNAMIC_SELECTION = True
# Durante warmup evitamos selecci√≥n agresiva para no colapsar a 2-4 features.
FEATURE_FREEZE_CORE_DURING_WARMUP = True
FEATURE_FREEZE_CORE_MIN_ROWS = TRAIN_WARMUP_MIN_ROWS
# Si el modelo anterior colaps√≥ a muy pocas features, permitimos reemplazarlo
# aunque la AUC temporal baje levemente en un reentreno puntual.
FEATURE_MIN_ACCEPTED_COUNT = 6

# Meta objetivo (calidad real en se√±ales fuertes)
IA_TARGET_PRECISION = 0.70
IA_TARGET_PRECISION_FLOOR = 0.65   # piso m√≠nimo para declarar confiable
IA_TARGET_MIN_SIGNALS = 30         # m√≠nimo de se√±ales en zona alta para validar

FEATURE_NAMES_PROD = list(FEATURE_ALWAYS_KEEP)
FEATURE_NAMES_SHADOW = [f for f in FEATURE_NAMES_CORE_13 if f not in FEATURE_NAMES_PROD]
FEATURE_NAMES_DEFAULT = list(FEATURE_NAMES_CORE_13)

class ModeloXGBCalibrado:
    """
    Wrapper picklable para calibrar probabilidades con un holdout temporal (CALIB),
    sin re-entrenar el modelo base. El modelo espera X ya escalado.
    calib_kind: "sigmoid" (Platt con LogisticRegression sobre logit(p)) o "isotonic".
    """
    def __init__(self, modelo_base, calib_kind: str, calib_obj):
        self.modelo_base = modelo_base
        self.calib_kind = str(calib_kind)
        self.calib_obj = calib_obj

    def _calibrar_p(self, p: np.ndarray) -> np.ndarray:
        p = np.asarray(p, dtype=float)
        p = np.clip(p, 1e-6, 1.0 - 1e-6)

        if self.calib_kind == "sigmoid":
            z = np.log(p / (1.0 - p)).reshape(-1, 1)
            p_cal = self.calib_obj.predict_proba(z)[:, 1]
            return np.clip(p_cal, 1e-6, 1.0 - 1e-6)

        # isotonic
        p_cal = self.calib_obj.transform(p)
        return np.clip(np.asarray(p_cal, dtype=float), 1e-6, 1.0 - 1e-6)

    def predict_proba(self, X):
        p_base = self.modelo_base.predict_proba(X)[:, 1]
        p_cal = self._calibrar_p(p_base)
        return np.vstack([1.0 - p_cal, p_cal]).T

    def predict(self, X):
        proba = self.predict_proba(X)[:, 1]
        return (proba >= 0.5).astype(int)

# === FIN BLOQUE 3 ===

# === BLOQUE 4 ‚Äî AUDIO (INIT Y REPRODUCCI√ìN) ===
# Inicializaci√≥n de audio
def init_audio():
    global AUDIO_AVAILABLE, SOUND_CACHE

    # No asumimos nada: recalculamos disponibilidad cada vez
    AUDIO_AVAILABLE = False

    # 1) Asegurar mixer (si no est√° listo)
    if pygame.mixer.get_init():
        AUDIO_AVAILABLE = True
    else:
        drivers = ['directsound', 'winmm', 'wasapi', None]
        configs = [
            (44100, -16, 2, 1024),
            (22050, -16, 2, 512),
            (44100, -16, 1, 1024),
        ]
        for driver in drivers:
            for freq, size, channels, buffer in configs:
                try:
                    if driver:
                        os.environ["SDL_AUDIODRIVER"] = driver
                    pygame.mixer.pre_init(frequency=freq, size=size, channels=channels, buffer=buffer)
                    pygame.mixer.init()
                    AUDIO_AVAILABLE = True
                    break
                except Exception:
                    pass
            if AUDIO_AVAILABLE:
                break

    # 2) Fallback winsound (aunque no tengamos pygame)
    if not AUDIO_AVAILABLE and winsound:
        AUDIO_AVAILABLE = True

    # 3) Cargar sonidos SOLO si mixer est√° operativo
    if pygame.mixer.get_init():
        base_dir = os.path.dirname(__file__)
        for event, filename in SOUND_PATHS.items():
            if event in SOUND_LOAD_ERRORS:
                continue
            path = os.path.join(base_dir, filename)
            if os.path.exists(path):
                try:
                    SOUND_CACHE[event] = pygame.mixer.Sound(path)
                except Exception:
                    SOUND_LOAD_ERRORS.add(event)

def reproducir_evento(evento, es_demo=False, dentro_gatewin=True):
    global sonido_disparado

    if not AUDIO_AVAILABLE:
        return

    # Reglas de GateWIN/DEMO (mismas que ten√≠as)
    if evento != "ia_53":
        if SONAR_SOLO_EN_GATEWIN and (not dentro_gatewin) and (not SONAR_FUERA_DE_GATEWIN):
            return
        if es_demo and not SONAR_TAMBIEN_EN_DEMO:
            return

    # 1) Preferir pygame si est√° cargado
    try:
        if evento in SOUND_CACHE:
            SOUND_CACHE[evento].play()
            sonido_disparado = True
            return
    except Exception:
        pass

    # 2) Fallback winsound (si pygame no est√° usable o no carg√≥ el sonido)
    if winsound:
        try:
            filename = SOUND_PATHS.get(evento)
            if not filename:
                return
            base_dir = os.path.dirname(__file__)
            path = os.path.join(base_dir, filename)
            if os.path.exists(path):
                winsound.PlaySound(path, winsound.SND_FILENAME | winsound.SND_ASYNC)
                sonido_disparado = True
        except Exception:
            pass
# === FIN BLOQUE 4 ===

# === BLOQUE 5 ‚Äî TOKENS, BOT_NAMES Y ESTADO GLOBAL ===
# Leer tokens del usuario
def leer_tokens_usuario():
    if not os.path.exists("tokens_usuario.txt"):
        return None, None
    try:
        with open("tokens_usuario.txt", "r", encoding="utf-8") as file:
            lines = [line.strip() for line in file.readlines()]
            if len(lines) < 2:
                return None, None
            token_demo, token_real = lines[0], lines[1]
            if not token_demo or not token_real:
                return None, None
            return token_demo, token_real
    except Exception:
        return None, None

# Escritura at√≥mica de token
def write_token_atomic(path, content):
    temp_path = path + ".tmp"
    try:
        with open(temp_path, "w", encoding="utf-8") as f:
            f.write(content)
            f.flush()
            os.fsync(f.fileno())
        os.replace(temp_path, path)
        return True
    except Exception:
        try:
            if os.path.exists(temp_path):
                os.remove(temp_path)
        except Exception:
            pass
        return False


# Orden operativo recomendado (calidad real primero):
# 1) fulll47: mejor hit-rate y menor inflaci√≥n del set comparado.
# 2) fulll50/fulll45: rendimiento similar pero con muestra algo mayor.
# 3) fulll48: intermedio, baja muestra.
# 4) fulll49/fulll46: sobreconfianza alta y peor hit-rate reciente.
BOT_NAMES = ["fulll47", "fulll50", "fulll45", "fulll48", "fulll49", "fulll46"]
IA53_TRIGGERED = {bot: False for bot in BOT_NAMES}
IA53_LAST_TS = {bot: 0.0 for bot in BOT_NAMES}
TOKEN_FILE = "token_actual.txt"
DERIV_WS_URL = "wss://ws.derivws.com/websockets/v3?app_id=1089"
saldo_real = "--"
SALDO_INICIAL = None
META = None
meta_mostrada = False
eventos_recentes = deque(maxlen=8)
reinicio_forzado = asyncio.Event()

salir = False
pausado = False
reinicio_manual = False

LIMPIEZA_PANEL_HASTA = 0
ULTIMA_ACT_SALDO = 0
REFRESCO_SALDO = 12
MAX_CICLOS = len(MARTI_ESCALADO)
huellas_usadas = {bot: set() for bot in BOT_NAMES}
SNAPSHOT_FILAS = {bot: 0 for bot in BOT_NAMES}
REAL_ENTRY_BASELINE = {bot: 0 for bot in BOT_NAMES}  # filas al entrar/reafirmar REAL
OCULTAR_HASTA_NUEVO = {bot: False for bot in BOT_NAMES}
t_inicio_indef = {bot: None for bot in BOT_NAMES}
last_update_time = {bot: time.time() for bot in BOT_NAMES}
LAST_REAL_CLOSE_SIG = {bot: None for bot in BOT_NAMES}  # evita procesar el mismo cierre REAL varias veces
REAL_OWNER_LOCK = None  # owner REAL en memoria (evita carreras de lectura de archivo)
REAL_LOCK_MISMATCH_SINCE = 0.0
REAL_LOCK_RECONCILE_S = 6.0

try:
    last_sig_por_bot
except NameError:
    last_sig_por_bot = {b: None for b in BOT_NAMES}

estado_bots = {
    bot: {
        "resultados": [], 
        "token": "DEMO", 
        "trigger_real": False,
        "ganancias": 0, 
        "perdidas": 0, 
        "porcentaje_exito": None,
        "tamano_muestra": 0,
        "prob_ia": None,              # guardar√° prob REAL (0..1). OJO: ya NO la forzamos a 0 por ‚Äúno se√±al‚Äù
        "ia_ready": False,           # True solo si logramos armar features + predecir sin error
        "ia_last_err": None,         # texto corto del motivo si no se pudo predecir
        "ia_last_prob_ts": 0.0,      # timestamp de la √∫ltima prob calculada
        "ciclo_actual": 1,
        "modo_real_anunciado": False, 
        "ultimo_resultado": None,
        "reintentar_ciclo": False,
        "remate_active": False,
        "remate_start": None,
        "remate_reason": "",
        "fuente": None,  
        "real_activado_en": 0.0,  
        "ignore_cierres_hasta": 0.0,
        "real_timeout_first_warn": 0.0,
        "modo_ia": "off",  # Nueva para modo (off, low_data, modelo)
        "ia_seniales": 0,  # contadores para medir IA
        "ia_aciertos": 0,
        "ia_fallos": 0,
        "ia_senal_pendiente": False,  # Flag para operaci√≥n recomendada por IA
        "ia_prob_senal": None,        # prob IA en el momento de la se√±al
        "ia_regime_score": 0.0,       # capa A (r√©gimen)
        "ia_evidence_n": 0,           # soporte hist√≥rico en umbral objetivo
        "ia_evidence_wr": 0.0         # win-rate real en umbral objetivo
    }
    for bot in BOT_NAMES
}
IA90_stats = {bot: {"n": 0, "ok": 0, "pct": 0.0, "pct_raw": 0.0, "pct_smooth": 50.0} for bot in BOT_NAMES}
# Ventana corta para diagnosticar el bloqueo dominante del embudo en HUD.
HUD_BLOQUEO_WINDOW = 120
HUD_BLOQUEOS_RECIENTES = deque(maxlen=HUD_BLOQUEO_WINDOW)

EVENTO_MAX_CHARS = 220

def _normalizar_evento_texto(msg: str, max_chars: int = EVENTO_MAX_CHARS) -> str:
    try:
        txt = str(msg if msg is not None else "")
    except Exception:
        txt = ""
    for ch in ("\r", "\n", "\t"):
        txt = txt.replace(ch, " ")
    txt = " ".join(txt.split())
    if len(txt) > int(max_chars):
        txt = txt[: max(0, int(max_chars) - 1)] + "‚Ä¶"
    return txt
# --- BLINDAJE: asegurar s√≠mbolos cr√≠ticos si faltan (no pisa definiciones reales) ---
if "RENDER_LOCK" not in globals():
    RENDER_LOCK = threading.Lock()

if "agregar_evento" not in globals():
    def agregar_evento(msg: str):
        try:
            ts = time.strftime("%H:%M:%S")
            limpio = _normalizar_evento_texto(msg)
            eventos_recentes.appendleft(f"{ts} {limpio}")
        except Exception:
            try:
                print(_normalizar_evento_texto(msg))
            except Exception:
                pass
# --- /BLINDAJE ---

# === FIN BLOQUE 5 ===

# === BLOQUE 6 ‚Äî LOCKS, FIRMAS Y UTILIDADES CSV ===
def _firma_registro(feature_names, row_vals, label):
    """
    Firma estable anti-duplicados:
    - Formato fijo para floats (evita variaciones 0.1 vs 0.10000000002)
    """
    parts = []
    for v in row_vals:
        try:
            parts.append(f"{float(v):.6f}")
        except Exception:
            parts.append(str(v))
    try:
        parts.append(str(int(label)))
    except Exception:
        parts.append(str(label))
    return "|".join(parts)

# Contar filas en CSV (sin header)
def contar_filas_csv(bot_name: str) -> int:
    ruta = f"registro_enriquecido_{bot_name}.csv"
    if not os.path.exists(ruta):
        return 0
    for encoding in ["utf-8", "latin-1", "windows-1252"]:
        try:
            with open(ruta, "r", newline="", encoding=encoding, errors="replace") as f:
                n = sum(1 for _ in f) - 1
                return max(0, n)
        except Exception as e:
            print(f"‚ö†Ô∏è Error contando filas en {ruta}: {e}")
            continue
    return 0

# Contar filas en dataset_incremental.csv (sin contar header)
def contar_filas_incremental() -> int:
    """
    Devuelve n√∫mero de filas (sin header) de dataset_incremental.csv.

    Optimizado:
    - Cachea (pos, size, rows) para evitar re-escaneo completo en cada llamada.
    - Si el archivo crece, cuenta solo las l√≠neas nuevas.
    """
    try:
        path = "dataset_incremental.csv"

        if not os.path.exists(path):
            contar_filas_incremental._cache = {"pos": 0, "rows": 0, "size": 0}
            return 0

        cache = getattr(contar_filas_incremental, "_cache", None)
        size = os.path.getsize(path)

        # Recuento completo en binario (robusto a encoding)
        def _count_full_rows() -> int:
            total = 0
            last_byte = b""
            with open(path, "rb") as f:
                while True:
                    chunk = f.read(1024 * 1024)
                    if not chunk:
                        break
                    total += chunk.count(b"\n")
                    last_byte = chunk[-1:]
            # Si el archivo NO termina en \n, hay una l√≠nea final sin salto
            if size > 0 and last_byte != b"\n":
                total += 1
            # Quita header si existe
            return max(0, total - 1)

        # Sin cache o el archivo se redujo/trunc√≥: recuenta todo
        if (not cache) or (size < int(cache.get("size", 0) or 0)) or (int(cache.get("pos", 0) or 0) > size):
            rows = _count_full_rows()
            contar_filas_incremental._cache = {"pos": size, "rows": rows, "size": size}
            return rows

        # Si no cambi√≥, devuelve cache
        if size == int(cache.get("size", 0) or 0):
            return int(cache.get("rows", 0) or 0)

        # Creci√≥: cuenta solo l√≠neas nuevas desde la √∫ltima posici√≥n
        pos = int(cache.get("pos", 0) or 0)
        new_lines = 0
        with open(path, "rb") as f:
            f.seek(pos)
            while True:
                chunk = f.read(1024 * 1024)
                if not chunk:
                    break
                new_lines += chunk.count(b"\n")

        rows = int(cache.get("rows", 0) or 0) + new_lines
        contar_filas_incremental._cache = {"pos": size, "rows": rows, "size": size}
        return rows

    except Exception:
        return 0

# Lock de archivo
@contextmanager
def file_lock(path="real.lock", timeout=5.0, stale_after=30.0):
    """
    Lock por archivo (cross-platform) con protecci√≥n anti-colisi√≥n:

    - NO borra el lock de otro proceso activo.
    - Solo intenta limpiar locks *stale* (viejos) si supera stale_after segundos.
    - Si no logra adquirir lock, contin√∫a SIN exclusi√≥n (como ya ven√≠as haciendo),
      pero sin destruir el lock ajeno.
    """
    start_time = time.time()
    fd = None
    acquired = False

    try:
        # 1) Intento normal por timeout
        while (time.time() - start_time) < float(timeout):
            try:
                fd = os.open(path, os.O_CREAT | os.O_EXCL | os.O_RDWR)
                acquired = True
                break
            except FileExistsError:
                time.sleep(0.10)
            except Exception:
                time.sleep(0.10)

        # 2) Si no se pudo, evaluar si el lock parece "stale"
        if not acquired:
            age = None
            try:
                age = time.time() - os.path.getmtime(path)
            except Exception:
                age = None

            if age is not None and age > float(stale_after):
                # Solo si es viejo de verdad, intentamos limpiar
                try:
                    os.remove(path)
                    fd = os.open(path, os.O_CREAT | os.O_EXCL | os.O_RDWR)
                    acquired = True
                except Exception as e:
                    try:
                        print(f"‚ö†Ô∏è Lock stale no se pudo limpiar ({path}): {e}. Contin√∫o sin exclusi√≥n.")
                    except Exception:
                        pass
            else:
                # Lock reciente: NO tocarlo
                try:
                    print(f"‚ö†Ô∏è No se adquiri√≥ lock ({path}) en {timeout}s (lock reciente). Contin√∫o sin exclusi√≥n.")
                except Exception:
                    pass

        # 3) Ejecutar la secci√≥n cr√≠tica (con o sin lock adquirido)
        yield

    finally:
        if acquired and fd is not None:
            try:
                os.close(fd)
            except Exception:
                pass
            try:
                os.remove(path)
            except Exception:
                pass
# ============================================================
# DATASET INCREMENTAL ‚Äî Reparaci√≥n de esquema "mutante"
# (header viejo / columnas extra / filas con campos de m√°s)
# Objetivo: mantener SIEMPRE un CSV estable para pandas/IA.
# ============================================================

# Reusar el set core (13) para que incremental y entrenamiento nunca diverjan
try:
    INCREMENTAL_FEATURES_V2 = list(FEATURE_NAMES_CORE_13)
except Exception:
    INCREMENTAL_FEATURES_V2 = [
        "rsi_9","rsi_14","sma_5","sma_spread","cruce_sma","breakout",
        "rsi_reversion","racha_actual","payout","puntaje_estrategia",
        "volatilidad","es_rebote","hora_bucket",
    ]
# === LOCK ESTRICTO (solo para escrituras sensibles como incremental.csv) ===
@contextmanager
def file_lock_required(path: str, timeout: float = 6.0, stale_after: float = 30.0):
    """
    Igual que file_lock, pero:
    - Si NO adquiere lock, NO ejecuta la secci√≥n cr√≠tica (yield False).
    - Para escrituras que NO toleran concurrencia (append CSV).
    """
    start_time = time.time()
    fd = None
    acquired = False

    try:
        while (time.time() - start_time) < float(timeout):
            try:
                fd = os.open(path, os.O_CREAT | os.O_EXCL | os.O_RDWR)
                acquired = True
                break
            except FileExistsError:
                time.sleep(0.10)
            except Exception:
                time.sleep(0.10)

        if not acquired:
            age = None
            try:
                age = time.time() - os.path.getmtime(path)
            except Exception:
                age = None

            if age is not None and age > float(stale_after):
                try:
                    os.remove(path)
                    fd = os.open(path, os.O_CREAT | os.O_EXCL | os.O_RDWR)
                    acquired = True
                except Exception:
                    acquired = False

        yield acquired

    finally:
        if acquired and fd is not None:
            try:
                os.close(fd)
            except Exception:
                pass
            try:
                os.remove(path)
            except Exception:
                pass
# === /LOCK ESTRICTO ===

def _canonical_incremental_cols(feature_names: list | None = None) -> list:
    fn = feature_names if feature_names else INCREMENTAL_FEATURES_V2
    return list(fn) + ["result_bin"]

def _safe_float(x):
    try:
        if x is None:
            return None
        if isinstance(x, str):
            x = x.strip()
            if x == "":
                return None
        v = float(x)
        if not np.isfinite(v):
            return None
        return v
    except Exception:
        return None

def _safe_int01(x):
    try:
        if x is None:
            return None
        if isinstance(x, str):
            x = x.strip()
            if x == "":
                return None
        v = int(float(x))
        if v not in (0, 1):
            return None
        return v
    except Exception:
        return None

def reparar_dataset_incremental_mutante(ruta: str = "dataset_incremental.csv", cols: list | None = None) -> bool:
    """
    Repara dataset_incremental.csv cuando qued√≥ 'mutante' por:
    - header corrupto (ej: racha...ia) o incompleto
    - filas con m√°s/menos columnas (ej: bot_id, activo_id metidos)
    - mezcla de esquemas (Expected X fields, saw Y)

    Estrategia:
    - Reescribe un CSV limpio con columnas can√≥nicas (cols).
    - Si el archivo actual tiene columnas can√≥nicas presentes, mapea por header.
    - Si el header no es usable, intenta rescate por POSICI√ìN:
        * len>=16: [0..12] + [15] (drop bot_id/activo_id)
        * len==15: [0..12] + [14]
        * len==14: [0..12] + [13]  (13 feats + label)
        * len>len(cols): toma primeras (len(cols)-1) + √∫ltima como label
    - Crea backup del archivo original con sufijo .bak_<epoch>.
    """
    cols = cols or _canonical_incremental_cols()
    if not os.path.exists(ruta):
        return False

    # Leer header y detectar mutaci√≥n
    header_list = None
    enc_usado = None
    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            with open(ruta, "r", newline="", encoding=enc, errors="replace") as f:
                first = f.readline()
            header_list = [h.strip() for h in first.strip().split(",")] if first else []
            enc_usado = enc
            break
        except Exception:
            continue

    if header_list is None:
        return False

    # Si el header ya es can√≥nico, igual escanear r√°pido por longitudes
    header_ok = (header_list == cols)
    header_has_canonical = set(cols).issubset(set(header_list))

    needs_repair = not header_ok

    # Escaneo r√°pido de longitudes (si hay mezcla de campos, se marca mutante)
    try:
        with open(ruta, "r", newline="", encoding=enc_usado or "utf-8", errors="replace") as f:
            reader = csv.reader(f)
            _ = next(reader, None)  # header
            for j, row in enumerate(reader, start=1):
                if not row:
                    continue
                if len(row) != len(header_list):
                    needs_repair = True
                    break
                if j >= 3000:
                    break
    except Exception:
        needs_repair = True

    if not needs_repair:
        return False

    # Armar filas limpias
    cleaned_rows = []
    header_index = {name: i for i, name in enumerate(header_list)} if header_has_canonical else {}

    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            with open(ruta, "r", newline="", encoding=enc, errors="replace") as f:
                reader = csv.reader(f)
                _ = next(reader, None)  # header
                for row in reader:
                    if not row:
                        continue

                    new_row = None

                    # 1) Si el header contiene columnas can√≥nicas, mapear por nombre
                    if header_has_canonical:
                        try:
                            new_row = [row[header_index[c]] if header_index[c] < len(row) else "" for c in cols]
                        except Exception:
                            new_row = None

                    # 2) Rescate por posici√≥n si el header es in√∫til
                    if new_row is None:
                        ncols = len(cols)
                        rlen = len(row)

                        # Casos exactos: (13 feats + extras + label)
                        # Usamos SIEMPRE row[-1] como label (m√°s seguro) y tomamos las 13 primeras como feats.
                        if ncols == 14 and rlen == 16:
                            # 13 feats + bot_id + activo_id + label
                            new_row = [row[i] for i in range(13)] + [row[-1]]
                        elif ncols == 14 and rlen == 15:
                            # 13 feats + (1 extra) + label
                            new_row = [row[i] for i in range(13)] + [row[-1]]
                        elif ncols == 14 and rlen == 14:
                            # 13 feats + label
                            new_row = [row[i] for i in range(13)] + [row[-1]]
                        elif rlen >= ncols:
                            # Caso general: toma primeras features y el √∫ltimo como label
                            new_row = list(row[:ncols - 1]) + [row[-1]]
                        else:
                            continue


                    # Validaci√≥n y casteo (features float, label int 0/1)
                    feats = []
                    ok = True
                    for x in new_row[:-1]:
                        v = _safe_float(x)
                        if v is None:
                            ok = False
                            break
                        feats.append(v)

                    lab = _safe_int01(new_row[-1])
                    if not ok or lab is None:
                        continue

                    cleaned_rows.append(feats + [lab])
            break
        except Exception:
            continue

    # Reescritura at√≥mica con backup
    tmp = ruta + ".tmp_repair"
    try:
        with open(tmp, "w", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow(cols)
            for r in cleaned_rows:
                w.writerow(r)
            f.flush()
            os.fsync(f.fileno())

        backup = f"{ruta}.bak_{int(time.time())}"
        backed_up = False

        # 1) Intento preferido: renombrar (r√°pido y at√≥mico)
        try:
            os.replace(ruta, backup)
            backed_up = True
        except Exception:
            backed_up = False

        # 2) Fallback: copiar (cuando rename falla por permisos/locks)
        if not backed_up:
            try:
                shutil.copy2(ruta, backup)
                backed_up = True
            except Exception:
                backed_up = False

        # 3) Si NO hay backup, NO pisamos el original
        if not backed_up:
            raise RuntimeError("No se pudo crear backup del incremental; se aborta reparaci√≥n para no perder datos.")

        os.replace(tmp, ruta)
        return True

    except Exception as e:
        try:
            if os.path.exists(tmp):
                os.remove(tmp)
        except Exception:
            pass
        fn_evt = globals().get("agregar_evento", None)
        try:
            if callable(fn_evt):
                fn_evt(f"‚ö†Ô∏è Incremental: reparaci√≥n fall√≥: {e}")
            else:
                print(f"‚ö†Ô∏è Incremental: reparaci√≥n fall√≥: {e}")
        except Exception:
            print(f"‚ö†Ô∏è Incremental: reparaci√≥n fall√≥: {e}")
        return False

# Firma persistente anti-duplicados
_SIG_DIR = ".sigcache"
os.makedirs(_SIG_DIR, exist_ok=True)

def _sig_path(bot): 
    safe = str(bot).replace("/", "_").replace("\\", "_")
    return os.path.join(_SIG_DIR, f"{safe}.sig")

def _load_recent_sigs(bot: str, max_keep: int = 50) -> list:
    """
    Devuelve lista de firmas recientes (√∫ltimas N) desde disco.
    Compatible con formato viejo (1 sola firma).
    """
    try:
        p = _sig_path(bot)
        if not os.path.exists(p):
            return []
        with open(p, "r", encoding="utf-8", errors="replace") as f:
            lines = [ln.strip() for ln in f.read().splitlines() if ln.strip()]
        if not lines:
            return []
        return lines[-int(max_keep):]
    except Exception:
        return []

def _sig_in_cache(bot: str, sig: str, max_keep: int = 50) -> bool:
    try:
        return sig in set(_load_recent_sigs(bot, max_keep=max_keep))
    except Exception:
        return False

def _append_sig_cache(bot: str, sig: str, max_keep: int = 50):
    """
    Guarda firma al final, manteniendo solo √∫ltimas N (y sin duplicados internos).
    """
    try:
        max_keep = int(max_keep)
        if max_keep < 5:
            max_keep = 5

        lst = _load_recent_sigs(bot, max_keep=max_keep)
        # mover al final si existe
        lst = [x for x in lst if x != sig] + [sig]
        lst = lst[-max_keep:]

        with open(_sig_path(bot), "w", encoding="utf-8") as f:
            f.write("\n".join(lst))
    except Exception:
        pass
# === COMPAT: helpers legacy (evita NameError y mantiene tu l√≥gica actual) ===
def _load_last_sig(bot: str) -> str | None:
    """
    Compatibilidad: versiones antiguas esperaban una sola firma.
    Hoy guardamos varias en _sigcache; devolvemos la √∫ltima.
    """
    try:
        lst = _load_recent_sigs(bot, max_keep=50)
        if not lst:
            return None
        return lst[-1]
    except Exception:
        return None

def _save_last_sig(bot: str, sig: str):
    """
    Compatibilidad: guarda como ‚Äú√∫ltima firma‚Äù, manteniendo historial.
    """
    try:
        _append_sig_cache(bot, sig, max_keep=50)
    except Exception:
        pass
# === /COMPAT ===

def _make_sig(row_dict):
    """Firma estable para comparar filas entre reinicios (sin timestamp si no existe)."""
    try:
        # Orden determinista
        data = {k: row_dict.get(k) for k in sorted(row_dict.keys())}
        s = json.dumps(data, ensure_ascii=False, sort_keys=True)
        return hashlib.sha256(s.encode("utf-8")).hexdigest()
    except:
        return None

_INCREMENTAL_SIG_CACHE = {"mtime": 0.0, "sigs": set()}

def _load_incremental_signatures(ruta: str, feats: list, max_rows: int = INCREMENTAL_DUP_SCAN_LINES) -> set:
    """Carga firmas recientes del incremental para bloquear duplicados exactos aunque reinicie el bot."""
    try:
        if not os.path.exists(ruta):
            return set()
        mtime = float(os.path.getmtime(ruta) or 0.0)
        cache = _INCREMENTAL_SIG_CACHE
        if cache.get("mtime") == mtime and cache.get("sigs"):
            return set(cache.get("sigs") or set())

        sigs = set()
        with open(ruta, "r", encoding="utf-8", errors="replace", newline="") as f:
            rows = list(csv.DictReader(f))
        if max_rows > 0:
            rows = rows[-int(max_rows):]
        for r in rows:
            try:
                vals = [float(r.get(k, 0.0) or 0.0) for k in feats]
                lab = int(float(r.get("result_bin", 0) or 0))
                sigs.add(_firma_registro(feats, vals, lab))
            except Exception:
                continue
        _INCREMENTAL_SIG_CACHE["mtime"] = mtime
        _INCREMENTAL_SIG_CACHE["sigs"] = set(sigs)
        return sigs
    except Exception:
        return set()

def _incremental_signature_exists(ruta: str, sig: str, feats: list) -> bool:
    try:
        return sig in _load_incremental_signatures(ruta, feats, max_rows=INCREMENTAL_DUP_SCAN_LINES)
    except Exception:
        return False

# Nueva: Validar fila para incremental (blindaje contra basura)
def validar_fila_incremental(fila_dict, feature_names):
    # Asegura numericidad real
    for k in feature_names:
        v = fila_dict.get(k, None)
        try:
            v = float(v)
            if not np.isfinite(v):
                return False, f"{k}=NaN/inf"
        except Exception:
            return False, f"{k}=no num√©rico"
        fila_dict[k] = v  # normaliza en sitio

    # Rangos l√≥gicos b√°sicos
    if not (0 <= fila_dict.get("rsi_9", 50) <= 100):
        return False, "RSI_9 fuera de 0-100"
    if not (0 <= fila_dict.get("rsi_14", 50) <= 100):
        return False, "RSI_14 fuera de 0-100"
    if not (0 <= fila_dict.get("payout", 0.0) <= 1.5):
        return False, "Payout fuera de 0-1.5"
    if "volatilidad" in fila_dict and not (0 <= fila_dict["volatilidad"] <= 1):
        return False, "Volatilidad fuera de 0-1"
    if "es_rebote" in fila_dict and not (0 <= fila_dict["es_rebote"] <= 1):
        return False, "es_rebote fuera de 0-1"
    if "hora_bucket" in fila_dict and not (0 <= fila_dict["hora_bucket"] <= 1):
        return False, "hora_bucket fuera de 0-1"

    return True, ""
        
def _anexar_incremental_desde_bot_CANON(bot: str, fila_dict_or_full: dict, label: int | None = None, feature_names: list | None = None) -> bool:
    """
    Anexa 1 fila al dataset_incremental.csv de forma estable:
    - Header can√≥nico (anti "mutante")
    - Lock dedicado (incremental.lock) para evitar choques
    - Repair del CSV SOLO bajo lock (evita corrupci√≥n por concurrencia)
    - Retry ante PermissionError (Excel/OneDrive/AV)
    - Anti-duplicado por firma persistente (_sigcache por bot)
    """
    try:
        ruta = "dataset_incremental.csv"
        feats = feature_names or INCREMENTAL_FEATURES_V2
        cols = _canonical_incremental_cols(feats)

        if not isinstance(fila_dict_or_full, dict) or not fila_dict_or_full:
            return False

        # Label: aceptar par√°metro o leer del dict
        if label is None:
            lb = fila_dict_or_full.get("result_bin", None)
            try:
                label = int(float(lb))
            except Exception:
                return False

        try:
            label = int(label)
        except Exception:
            return False
        if label not in (0, 1):
            return False

        # Dict solo con features can√≥nicas
        fila_dict = {k: fila_dict_or_full.get(k, None) for k in feats}

        # Validaci√≥n fuerte
        ok, why = validar_fila_incremental(fila_dict, feats)
        if not ok:
            fn_evt = globals().get("agregar_evento", None)
            try:
                if callable(fn_evt):
                    fn_evt(f"‚ö†Ô∏è Incremental: fila descartada {bot}: {why}")
            except Exception:
                pass
            return False

        row_vals = [float(fila_dict[k]) for k in feats]
        sig = _firma_registro(feats, row_vals, label)

        # Anti-duplicado persistente (cache local + escaneo incremental reciente)
        if _sig_in_cache(bot, sig, max_keep=50):
            return False
        if _incremental_signature_exists(ruta, sig, feats):
            return False

        attempts = 8
        base_sleep = 0.08

        with file_lock_required("incremental.lock", timeout=6.0, stale_after=30.0) as got:
            if not got:
                fn_evt = globals().get("agregar_evento", None)
                try:
                    if callable(fn_evt):
                        fn_evt("‚ö†Ô∏è Incremental: no se pudo adquirir lock (incremental.lock). Fila omitida para evitar corrupci√≥n.")
                except Exception:
                    pass
                return False

            # ‚úÖ Bajo lock: asegurar existencia + header estable + repair si hace falta
            if os.path.exists(ruta):
                try:
                    with open(ruta, "r", encoding="utf-8", errors="replace", newline="") as f:
                        first = f.readline().strip()
                    header_now = [h.strip() for h in first.split(",")] if first else []
                    if header_now != cols:
                        reparar_dataset_incremental_mutante(ruta=ruta, cols=cols)
                except Exception:
                    try:
                        reparar_dataset_incremental_mutante(ruta=ruta, cols=cols)
                    except Exception:
                        pass
            else:
                try:
                    with open(ruta, "w", newline="", encoding="utf-8") as f:
                        w = csv.writer(f)
                        w.writerow(cols)
                        f.flush()
                        os.fsync(f.fileno())
                except Exception:
                    return False

            # Append con retry
            for n in range(attempts):
                try:
                    with open(ruta, "a", newline="", encoding="utf-8") as f:
                        w = csv.writer(f)
                        w.writerow(row_vals + [label])
                        f.flush()
                        os.fsync(f.fileno())

                    _save_last_sig(bot, sig)
                    try:
                        _INCREMENTAL_SIG_CACHE.setdefault("sigs", set()).add(sig)
                        _INCREMENTAL_SIG_CACHE["mtime"] = float(os.path.getmtime(ruta) or 0.0)
                    except Exception:
                        pass
                    return True

                except PermissionError:
                    time.sleep(base_sleep * (n + 1) + random.uniform(0, 0.07))
                    continue
                except Exception:
                    break

        return False

    except Exception:
        return False
        
# === Canonizaci√≥n: aunque existan duplicados en el archivo, esta es la versi√≥n oficial ===
anexar_incremental_desde_bot = _anexar_incremental_desde_bot_CANON
       
# === FIN BLOQUE 6 ===

# === BLOQUE 7 ‚Äî ORDEN DE REAL Y CONTROL DE TOKEN ===
# === ORDEN DE REAL (handshake maestro‚Üíbot) ===
ORDEN_DIR = "orden_real"

def _ensure_dir(p):
    try:
        os.makedirs(p, exist_ok=True)
    except Exception as e:
        print(f"‚ö†Ô∏è Fall√≥ creaci√≥n de dir {p}: {e}")

def _atomic_write(path: str, text: str):
    tmp = path + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        f.write(text)
        f.flush(); os.fsync(f.fileno())
    os.replace(tmp, path)

def path_orden(bot: str) -> str:
    _ensure_dir(ORDEN_DIR)
    return os.path.join(ORDEN_DIR, f"{bot}.json")

# === PATCH: REAL INMEDIATO EN HUD AL EMITIR ORDEN (sin esperar compra) ===
# Objetivo:
# - Al emitir una ORDEN manual (bot+ciclo), reservar REAL y mostrarlo YA en HUD.
# - Evitar recursi√≥n/doble llamada.
# - Si activar_real_inmediato se llama desde otro flujo (no orden_real),
#   asegurar que el bot tenga tambi√©n su orden_real.json escrita (sin recursi√≥n).

_last_real_push_ts = {bot: 0.0 for bot in BOT_NAMES}

def limpiar_orden_real(bot: str):
    """
    Evita re-entradas fantasma:
    si se liber√≥ REAL, la orden ya no debe quedar viva.
    """
    try:
        p = path_orden(bot)
        if os.path.exists(p):
            os.remove(p)
    except Exception:
        pass

def _set_ui_token_holder(holder: str | None):
    """
    Sincroniza UI + estado interno:
    - token (texto REAL/DEMO)
    - trigger_real (l√≥gica)
    Adem√°s: si un bot DEJA de ser holder REAL, limpia su estado REAL residual
    para evitar "REAL fantasma" y escudos pegados.
    """
    try:
        now = time.time()
        for b in BOT_NAMES:
            # ultra defensivo: si por algo falta el dict del bot, lo crea
            if b not in estado_bots or not isinstance(estado_bots.get(b), dict):
                estado_bots[b] = {}

            is_holder = bool(holder) and (b == holder)
            prev_token = estado_bots[b].get("token", "DEMO")

            # UI base
            estado_bots[b]["token"] = "REAL" if is_holder else "DEMO"
            estado_bots[b]["trigger_real"] = True if is_holder else False

            # Si dej√≥ de ser REAL, limpiar residuos (solo si antes era REAL)
            if (not is_holder) and (prev_token == "REAL"):
                estado_bots[b]["modo_real_anunciado"] = False
                estado_bots[b]["real_activado_en"] = 0.0

                # micro-colch√≥n anti-carreras: evitamos leer cierres viejos justo al soltar token
                estado_bots[b]["ignore_cierres_hasta"] = now + 1.5

                estado_bots[b]["fuente"] = None

                # IA / pending
                estado_bots[b]["ia_senal_pendiente"] = False
                estado_bots[b]["ia_prob_senal"] = None

                # Remate
                estado_bots[b]["remate_active"] = False
                estado_bots[b]["remate_start"] = None
                estado_bots[b]["remate_reason"] = ""

                # Ciclo vuelve a default (solo al perder REAL)
                estado_bots[b]["ciclo_actual"] = 1

    except Exception:
        pass

def _enforce_single_real_standby(owner: str | None):
    """
    Si hay owner REAL activo, deja a los dem√°s bots en standby estricto:
    - token DEMO visual
    - sin se√±al IA pendiente
    """
    try:
        if owner not in BOT_NAMES:
            return
        for b in BOT_NAMES:
            if b == owner:
                continue
            estado_bots[b]["token"] = "DEMO"
            estado_bots[b]["ia_senal_pendiente"] = False
            estado_bots[b]["ia_prob_senal"] = None
    except Exception:
        pass

def _escribir_orden_real_raw(bot: str, ciclo: int):
    """
    Escritura RAW de orden_real (sin activar_real_inmediato, sin recursi√≥n).
    """
    ciclo = max(1, min(int(ciclo), MAX_CICLOS))
    payload = {"bot": bot, "ciclo": ciclo, "ts": time.time()}
    try:
        _atomic_write(path_orden(bot), json.dumps(payload, ensure_ascii=False))
        agregar_evento(f"üìù Orden REAL escrita para {bot}: ciclo #{ciclo}")
    except Exception as e:
        try:
            agregar_evento(f"‚ö†Ô∏è Fall√≥ escritura de orden para {bot}: {e}")
        except Exception:
            pass

def activar_real_inmediato(bot: str, ciclo: int, origen: str = "orden_real"):

    """
    Reserva REAL y actualiza HUD de forma INMEDIATA.

    Regla anti ‚Äú√≥rdenes fantasma‚Äù:
    - SOLO si origen == "manual" se auto-escribe orden_real.json aqu√≠.
    - Si la orden viene por escribir_orden_real(...), ese wrapper YA escribe el JSON.
    - Flujos de sync/UI/token jam√°s deben escribir orden_real.json.
    """
    global LIMPIEZA_PANEL_HASTA, sonido_disparado, marti_paso, REAL_OWNER_LOCK, REAL_ENTRY_BASELINE

    try:
        if bot not in BOT_NAMES:
            return

        now = time.time()

        # üîí No permitir reemplazar owner REAL activo por otro bot.
        # Solo se puede activar si no hay owner o si es el mismo bot.
        try:
            owner_lock = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
        except Exception:
            owner_lock = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None
        if owner_lock in BOT_NAMES and owner_lock != bot:
            try:
                agregar_evento(f"üîí REAL bloqueado: {owner_lock.upper()} sigue activo. Ignorando intento de {bot.upper()}.")
            except Exception:
                pass
            try:
                if origen == "orden_real":
                    limpiar_orden_real(bot)
            except Exception:
                pass
            return


        # Anti doble-disparo (tecla rebotona)
        if (now - _last_real_push_ts.get(bot, 0.0)) < 0.25:
            return
        _last_real_push_ts[bot] = now

        ciclo_obj = max(1, min(int(ciclo), MAX_CICLOS))

        # Baseline REAL: a partir de aqu√≠ reci√©n aceptamos cierres para este turno.
        try:
            REAL_ENTRY_BASELINE[bot] = int(contar_filas_csv(bot) or 0)
        except Exception:
            REAL_ENTRY_BASELINE[bot] = 0

        # Idempotencia token_sync: evita re-enganche/spam si ya est√° el mismo holder/ciclo.
        if origen == "token_sync":
            try:
                owner_now = leer_token_actual()
                cyc_now = int(estado_bots.get(bot, {}).get("ciclo_actual", 1) or 1)
                if owner_now == bot and cyc_now == ciclo_obj:
                    return
            except Exception:
                pass

        # ‚úÖ Solo ‚Äúmanual‚Äù auto-escribe orden_real (la orden expl√≠cita)
        if origen == "manual":
            try:
                _escribir_orden_real_raw(bot, ciclo_obj)
            except Exception:
                pass

        prev_holder = None
        try:
            prev_holder = leer_token_actual()  # sincroniza UI
        except Exception:
            prev_holder = None

        # Reservar lock owner en memoria + token REAL en archivo
        REAL_OWNER_LOCK = bot

        # Reservar token REAL en archivo SOLO cuando corresponde:
        # - orden_real: orden expl√≠cita ya escrita por wrapper
        # - manual: el propio activar_real_inmediato puede escribir orden_real
        # - token_sync: sincroniza token sin tocar orden_real.json
        if origen in ("orden_real", "manual", "token_sync"):
            with file_lock():
                write_token_atomic(TOKEN_FILE, f"REAL:{bot}")



        # 2) Estado interno inmediato (HUD)
        _set_ui_token_holder(bot)
        estado_bots[bot]["trigger_real"] = True
        estado_bots[bot]["ciclo_actual"] = ciclo_obj

        # Congelar probabilidad de se√±al al entrar REAL (si no estaba ya fijada)
        # para evitar divergencia visual/ACK durante toda la operaci√≥n.
        try:
            if not isinstance(estado_bots[bot].get("ia_prob_senal"), (int, float)):
                p_live = estado_bots[bot].get("prob_ia", None)
                if isinstance(p_live, (int, float)) and 0.0 <= float(p_live) <= 1.0:
                    estado_bots[bot]["ia_prob_senal"] = float(p_live)
        except Exception:
            pass

        # Marcas de ‚Äúentrada a real‚Äù
        first_entry = not bool(estado_bots[bot].get("modo_real_anunciado", False))
        if first_entry or (prev_holder != bot):
            estado_bots[bot]["modo_real_anunciado"] = True
            estado_bots[bot]["real_activado_en"] = now
            estado_bots[bot]["ignore_cierres_hasta"] = now + 15.0
            estado_bots[bot]["real_timeout_first_warn"] = 0.0

            # Snapshot visual/diagn√≥stico (independiente del baseline REAL)
            try:
                SNAPSHOT_FILAS[bot] = contar_filas_csv(bot)
            except Exception:
                SNAPSHOT_FILAS[bot] = 0

            # Mantener marti_paso global coherente con el ciclo elegido
            try:
                marti_paso = ciclo_obj - 1
            except Exception:
                pass

            try:
                agregar_evento(f"üö® REAL INMEDIATO ({origen}) ‚Üí {bot.upper()} | ciclo #{ciclo_obj}")
            except Exception:
                pass

            # Sonido de activaci√≥n (solo si tu config lo permite)
            try:
                reproducir_evento("racha_detectada", es_demo=False, dentro_gatewin=True)
            except Exception:
                pass

            LIMPIEZA_PANEL_HASTA = 0
            sonido_disparado = False

        # 3) Redibujar panel YA
        try:
            fn_panel = globals().get("mostrar_panel", None)
            if callable(fn_panel):
                with RENDER_LOCK:
                    fn_panel()
        except Exception:
            pass

        # 4) Saldo en background (no frena UI)
        try:
            loop = asyncio.get_running_loop()
            fn_saldo = globals().get("obtener_saldo_real", None)
            if callable(fn_saldo):
                loop.create_task(fn_saldo())
            else:
                fn_refresh = globals().get("refresh_saldo_real", None)
                if callable(fn_refresh):
                    loop.create_task(fn_refresh(forzado=True))
        except Exception:
            pass

        # 5) Log de promociones
        try:
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            with open("registro_promociones.txt", "a", encoding="utf-8") as log:
                log.write(f"{timestamp} - Token REAL (inmediato) asignado a {bot} (ciclo {ciclo_obj})\n")
        except Exception:
            pass

    except Exception:
        pass

def escribir_orden_real(bot: str, ciclo: int) -> bool:
    global REAL_OWNER_LOCK
    """
    Wrapper oficial:
    - Escribe orden_real.json (RAW)
    - Activa REAL inmediato en HUD + token file
    """
    ciclo = max(1, min(int(ciclo), MAX_CICLOS))

    # üîí No crear orden si ya hay otro owner REAL activo.
    try:
        owner_lock = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
    except Exception:
        owner_lock = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None

    if owner_lock in BOT_NAMES and owner_lock != bot:
        try:
            agregar_evento(f"üîí Orden REAL bloqueada para {bot.upper()}: {owner_lock.upper()} est√° activo.")
        except Exception:
            pass
        return False

    # ‚úÖ Auditor√≠a Real vs Ficticia: abrir se√±al SOLO si esta orden est√° respaldada por IA (prob >= umbral)
    try:
        st = estado_bots.get(str(bot), {}) if isinstance(estado_bots, dict) else {}
        prob_sig = st.get("prob_ia")
        modo_sig = str(st.get("modo_ia") or "").upper()
        thr_sig = float(get_umbral_operativo())
        if isinstance(prob_sig, (int, float)) and modo_sig not in ("", "OFF", "0") and float(prob_sig) >= thr_sig:
            ep_sig = ia_audit_get_last_pre_epoch(str(bot))
            if isinstance(ep_sig, (int, float)) and int(ep_sig) > 0:
                log_ia_open(str(bot), int(ep_sig), float(prob_sig), float(thr_sig), str(st.get("fuente") or "ORDEN_REAL"))
    except Exception:
        pass

    _escribir_orden_real_raw(bot, ciclo)
    activar_real_inmediato(bot, ciclo, origen="orden_real")

    owner_after = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
    ok = owner_after == bot
    if ok:
        _marti_audit_log_orden(ciclo, bot=bot, origen="escribir_orden_real")
        if int(ciclo) == 1:
            agregar_evento("üü¢ MARTI-AUDIT: apertura expl√≠cita en C1 (nuevo ciclo confirmado).")
        _marcar_compuerta_real_consumida()
        DYN_ROOF_STATE["last_real_open_ts"] = float(time.time())
    return ok
# === FIN PATCH REAL INMEDIATO ===
# === IA ACK (handshake maestro‚Üíbot: confirma que el PRE-TRADE ya fue evaluado) ===
IA_ACK_DIR = "ia_ack"
_LAST_IA_ACK_HEARTBEAT_TS = 0.0

def path_ia_ack(bot: str) -> str:
    _ensure_dir(IA_ACK_DIR)
    return os.path.join(IA_ACK_DIR, f"{bot}.json")

def _prob_ia_para_ack(bot: str, st: dict | None = None):
    """
    Prob IA efectiva para ACK:
    - Si el bot tiene una se√±al ya seleccionada (ia_prob_senal), la conservamos para
      evitar que el ACK oscile durante reintentos/token-sync.
    - Si no hay se√±al bloqueada, SOLO usamos prob_ia viva cuando el bot reporta
      ia_ready=True y modo_ia != off.

    Esto evita mostrar 0.0% fantasma cuando prob_ia qued√≥ en default durante resets.
    """
    try:
        st = st if isinstance(st, dict) else estado_bots.get(str(bot), {})
        p_lock = st.get("ia_prob_senal", None)
        if isinstance(p_lock, (int, float)) and 0.0 <= float(p_lock) <= 1.0:
            return float(p_lock)

        ia_ready = bool(st.get("ia_ready", False))
        modo = str(st.get("modo_ia", "off") or "off").strip().lower()
        p_live = st.get("prob_ia", None)
        if ia_ready and (modo != "off") and isinstance(p_live, (int, float)) and 0.0 <= float(p_live) <= 1.0:
            return float(p_live)
    except Exception:
        pass
    return None

def _resolver_prob_en_juego_ack(bot: str, st: dict | None = None):
    """Devuelve (prob_en_juego, source) para unificar la fuente de verdad del ACK."""
    try:
        st = st if isinstance(st, dict) else estado_bots.get(str(bot), {})
        p_lock = st.get("ia_prob_senal", None)
        if isinstance(p_lock, (int, float)) and 0.0 <= float(p_lock) <= 1.0:
            return float(p_lock), "SENAL"

        ia_ready = bool(st.get("ia_ready", False))
        modo = str(st.get("modo_ia", "off") or "off").strip().lower()
        p_live = st.get("prob_ia", None)
        if isinstance(p_live, (int, float)) and 0.0 <= float(p_live) <= 1.0 and (modo != "off"):
            # MODELO: predicci√≥n lista y usable para decisi√≥n real.
            if ia_ready:
                return float(p_live), "MODELO"
            # LOW_DATA/NO_READY: mostramos prob viva del maestro como referencia visual
            # (evita ocultar 54.2% en bot cuando el HUD s√≠ la est√° mostrando).
            if float(p_live) > 0.0:
                return float(p_live), "HUD"

        if modo == "off":
            return None, "OFF"
        return None, "NO_READY"
    except Exception:
        return None, "NO_READY"

def escribir_ia_ack(bot: str, epoch: int | None, prob: float | None, modo_ia: str, meta: dict | None):
    """
    Escribe un ACK por-bot para que el bot muestre la prob IA asociada a su PRE.
    Incluye:
      - prob: prob calibrada (0..1) o None
      - prob_raw: prob sin calibrar (0..1), si est√° disponible
      - calib_factor: factor aplicado (si aplica)
      - auc / thr / reliable desde model_meta
    """
    try:
        ack_path = path_ia_ack(bot)
        os.makedirs(os.path.dirname(ack_path), exist_ok=True)

        st = estado_bots.get(str(bot), {}) if isinstance(estado_bots, dict) else {}

        p_hud = _prob_ia_para_ack(bot, st)
        p_play, p_source = _resolver_prob_en_juego_ack(bot, st)
        decision_id = st.get("ia_decision_id")
        if not decision_id:
            ep = int(epoch) if epoch is not None else 0
            decision_id = f"{bot}|{ep}"
        payload = {
            "bot": str(bot),
            "epoch": int(epoch) if epoch is not None else 0,
            "prob": float(prob) if isinstance(prob, (int, float)) else None,
            # prob_hud/modo_hud = valor vigente que pinta el HUD del maestro (fuente visual principal)
            "prob_hud": p_hud,
            "has_prob_hud": isinstance(p_hud, (int, float)),
            "ia_ready": bool(st.get("ia_ready", False)),
            "modo_hud": str(st.get("modo_ia", "off") or "off").upper(),
            "prob_en_juego": p_play,
            "has_prob_en_juego": isinstance(p_play, (int, float)),
            "prob_source": str(p_source),
            "decision_id": str(decision_id),
            "ack_ts": time.time(),
            "prob_raw": float(st.get("prob_ia_raw")) if isinstance(st.get("prob_ia_raw"), (int, float)) else None,
            "calib_factor": float(st.get("cal_factor")) if isinstance(st.get("cal_factor"), (int, float)) else None,
            "auc": float((meta or {}).get("auc", 0.0) or 0.0),
            "thr": float((meta or {}).get("threshold", 0.0) or 0.0),
            "real_thr": float(get_umbral_real_calibrado()),
            "real_thr_cap": float(AUTO_REAL_THR),
            "reliable": bool((meta or {}).get("reliable", True)),
            "modo": str(modo_ia).upper() if modo_ia else "OFF",
            "model_version": str((meta or {}).get("trained_at", "")),
            "ts": time.time()
        }

        with open(ack_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def refrescar_ia_ack_desde_hud(intervalo_s: float = 1.0):
    """
    Heartbeat de ACK: mantiene `ia_ack/<bot>.json` sincronizado con el HUD.
    Objetivo: que los bots vean la prob IA vigente del maestro durante GateWin,
    incluso si no entraron filas nuevas de CSV en ese instante.
    """
    global _LAST_IA_ACK_HEARTBEAT_TS
    now = time.time()
    if (now - float(_LAST_IA_ACK_HEARTBEAT_TS or 0.0)) < float(intervalo_s):
        return

    meta = leer_model_meta() or {}
    for bot in BOT_NAMES:
        try:
            st = estado_bots.get(bot, {}) if isinstance(estado_bots, dict) else {}
            ep = st.get("ultimo_epoch_pretrade", 0)
            if ep is None:
                ep = 0
            ep = int(float(ep)) if str(ep).strip() != "" else 0
            if ep <= 0:
                continue

            p_eff = _prob_ia_para_ack(bot, st)
            modo = str(st.get("modo_ia", "off") or "off").upper()
            escribir_ia_ack(bot, ep, p_eff if isinstance(p_eff, (int, float)) else None, modo, meta)
        except Exception:
            continue

    _LAST_IA_ACK_HEARTBEAT_TS = now
# Leer token actual
def leer_token_actual():
    """
    Lee token_actual.txt y adem√°s sincroniza el HUD (estado_bots[*]["token"])
    para que REAL/DEMO se refleje sin esperar compra del bot.
    Prioriza lock en memoria para evitar parpadeos DEMO durante REAL en curso.
    """
    holder = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None

    # Si ya hay owner REAL en memoria, mantenemos sincron√≠a visual inmediata.
    if holder in BOT_NAMES:
        _set_ui_token_holder(holder)
        _enforce_single_real_standby(holder)
        return holder

    if not os.path.exists(TOKEN_FILE):
        _set_ui_token_holder(None)
        return None
    try:
        with open(TOKEN_FILE, encoding="utf-8", errors="replace") as f:
            linea = (f.read() or "").strip()
        if linea.startswith("REAL:"):
            bot_name = linea.split(":", 1)[1].strip()
            if bot_name in BOT_NAMES:
                holder = bot_name
            elif bot_name == "none":
                holder = None
        _set_ui_token_holder(holder)
        if holder in BOT_NAMES:
            _enforce_single_real_standby(holder)
        return holder
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è Error leyendo token: {e}")
        except Exception:
            pass
        fallback = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None
        _set_ui_token_holder(fallback)
        if fallback in BOT_NAMES:
            _enforce_single_real_standby(fallback)
        return fallback


def leer_token_archivo_raw():
    """
    Lee token_actual.txt SIN priorizar REAL_OWNER_LOCK (para reconciliar desincron√≠as).
    Retorna bot owner REAL o None.
    """
    if not os.path.exists(TOKEN_FILE):
        return None
    try:
        with open(TOKEN_FILE, encoding="utf-8", errors="replace") as f:
            linea = (f.read() or "").strip()
        if not linea.startswith("REAL:"):
            return None
        bot_name = linea.split(":", 1)[1].strip()
        if bot_name in BOT_NAMES:
            return bot_name
        return None
    except Exception:
        return None

# Escribir token actual
async def escribir_token_actual(bot):
    """
    Sync UI/token: refleja REAL en HUD y token file.
    ‚ö†Ô∏è Regla: este flujo NO debe generar orden_real.json.
    """
    try:
        try:
            _ = leer_token_actual()  # sincroniza UI
        except Exception:
            pass

        ciclo_objetivo = estado_bots.get(bot, {}).get("ciclo_actual", 1)
        try:
            ciclo_objetivo = int(ciclo_objetivo)
        except Exception:
            ciclo_objetivo = 1

        # ‚úÖ origen "sync_ui": NO debe escribir orden_real.json
        activar_real_inmediato(bot, ciclo_objetivo, origen="token_sync")

        # No bloqueamos: saldo en background
        try:
            asyncio.create_task(obtener_saldo_real())
        except Exception:
            try:
                asyncio.create_task(refresh_saldo_real(forzado=True))
            except Exception:
                pass

    except Exception:
        pass

# Activar remate
def activar_remate(bot: str, reason: str):
    if not estado_bots[bot]["remate_active"]:
        estado_bots[bot]["remate_active"] = True
        estado_bots[bot]["remate_start"] = datetime.now()
        estado_bots[bot]["remate_reason"] = reason

# Cerrar por WIN
def cerrar_por_win(bot: str, reason: str):
    global REAL_OWNER_LOCK, REAL_COOLDOWN_UNTIL_TS
    # Limpieza total de ‚Äúestado REAL‚Äù para evitar REAL fantasma
    try:
        estado_bots[bot]["token"] = "DEMO"
        estado_bots[bot]["trigger_real"] = False
        estado_bots[bot]["ciclo_actual"] = 1
        estado_bots[bot]["modo_real_anunciado"] = False
        estado_bots[bot]["fuente"] = None
        estado_bots[bot]["real_activado_en"] = 0.0
        estado_bots[bot]["ignore_cierres_hasta"] = 0.0


        # Flags IA/pending (si qued√≥ algo colgado)
        estado_bots[bot]["ia_senal_pendiente"] = False
        estado_bots[bot]["ia_prob_senal"] = None

        # Remate limpio
        estado_bots[bot]["remate_active"] = False
        estado_bots[bot]["remate_start"] = None
        estado_bots[bot]["remate_reason"] = ""

    except Exception:
        pass

    # Liberar token global REAL
    REAL_OWNER_LOCK = None
    REAL_COOLDOWN_UNTIL_TS = time.time() + float(_cooldown_post_trade_s())
    try:
        with file_lock():
            write_token_atomic(TOKEN_FILE, "REAL:none")
    except Exception:
        pass
    # Limpiar orden REAL para evitar re-entradas fantasma
    try:
        limpiar_orden_real(bot)
    except Exception:
        pass
    
    # Sync inmediato del HUD/token para evitar ‚ÄúREAL fantasma‚Äù
    try:
        _set_ui_token_holder(None)
    except Exception:
        pass
    
    # Resync de snapshots y panel
    try:
        REAL_ENTRY_BASELINE[bot] = 0
        SNAPSHOT_FILAS[bot] = contar_filas_csv(bot)
    except Exception:
        pass

    try:
        OCULTAR_HASTA_NUEVO[bot] = False
    except Exception:
        pass

    try:
        agregar_evento(f"‚úÖ WIN: REAL liberado para {bot.upper()} ({reason})")
    except Exception:
        pass

    try:
        reinicio_forzado.set()
    except Exception:
        pass

# === FIN BLOQUE 7 ===

# === BLOQUE 8 ‚Äî NORMALIZACI√ìN Y PUNTAJE DE ESTRATEGIA ===
# Normalizar resultado
def normalizar_resultado(texto):
    if texto is None:
        return "INDEFINIDO"

    raw = str(texto)

    # 1) Detectar s√≠mbolos ANTES de normalizaci√≥n ASCII (ASCII los borra)
    if any(sym in raw for sym in ("‚úì", "‚úî", "‚úÖ", "üü¢")):
        return "GANANCIA"
    if any(sym in raw for sym in ("‚úó", "‚ùå", "üî¥", "üü•")):
        return "P√âRDIDA"

    # 2) Normalizaci√≥n de texto (acentos/encoding raros)
    raw = raw.replace("√É‚Ä∞", "√â").replace("P√É‚Ä∞RDIDA", "P√âRDIDA")
    t = normalize("NFKD", raw).encode("ASCII", "ignore").decode("ASCII").strip().upper()

    # Nota: despu√©s de ASCII, "P√âRDIDA" se vuelve "PERDIDA"
    if "PERD" in t or "LOSS" in t:
        return "P√âRDIDA"
    if "GAN" in t or "WIN" in t:
        return "GANANCIA"
    return "INDEFINIDO"
def normalizar_trade_status(ts):
    """
    Normaliza trade_status a can√≥nico del Maestro:
      - "CERRADO"   (CERRADO/CLOSED/SETTLED/etc.)
      - "PRE_TRADE" (PRE_TRADE/PENDIENTE/PENDING/OPEN/ABIERTO/etc.)
      - otros: upper limpio (compat)
    """
    try:
        if ts is None:
            return ""
        s = str(ts).strip().upper()
        if s in ("", "NAN", "NONE"):
            return ""

        # --- CIERRES ---
        if s in (
            "CERRADO", "CERRADA",
            "CLOSED", "CLOSE",
            "SETTLED",
            "SOLD",
            "EXPIRED", "EXPIRE",
            "CANCELLED", "CANCELED",
            "VOID"
        ):
            return "CERRADO"

        # --- PRE / PENDIENTE / ABIERTO ---
        if s in (
            "PRE_TRADE", "PRETRADE",
            "PENDIENTE", "PENDING",
            "OPEN", "ABIERTO", "ABIERTA",
            "IN_PROGRESS", "INPROGRESS", "RUNNING"
        ):
            return "PRE_TRADE"

        return s
    except Exception:
        return ""

def canonicalizar_campos_bot_maestro(row_dict: dict | None):
    """
    Mapeo central BOT -> Maestro para mantener un √∫nico esquema can√≥nico.

    Este normalizador NO inventa datos: solo renombra/duplica aliases conocidos
    hacia los nombres oficiales que consume la IA del maestro.
    """
    out = dict(row_dict or {})

    alias_map = {
        "direction": ("direccion",),
        "ciclo_martingala": ("ciclo",),
        "cruce_sma": ("cruce",),
        "payout_multiplier": ("payout_decimal_rounded",),
    }

    for canon, aliases in alias_map.items():
        if out.get(canon) in (None, ""):
            for a in aliases:
                if out.get(a) not in (None, ""):
                    out[canon] = out.get(a)
                    break

    return out

# ==========================================================
# Payout/ROI ‚Äî Normalizaci√≥n consistente (SIN confundir %)
# Convenci√≥n:
# - payout_total: total recibido (ej 1.95, 15.62)
# - payout (feature IA): ROI = (payout_total / monto) - 1  en [0.0, 1.5]
# ==========================================================
# Reutilizamos _safe_float (BLOQUE 6) para evitar duplicados
_safe_float_local = _safe_float
                                    
def _norm_01(x, lo=0.0, hi=3.5):
    """
    Normaliza x a [0..1] usando rango [lo..hi].
    Si no se puede convertir, devuelve 0.0
    """
    try:
        v = _safe_float_local(x)
        if v is None:
            return 0.0
        v = float(v)
        if not math.isfinite(v):
            return 0.0
        if hi <= lo:
            return 0.0
        t = (v - lo) / (hi - lo)
        return max(0.0, min(1.0, t))
    except Exception:
        return 0.0
      
def extraer_payout_multiplier(row_dict_full: dict):
    """
    payout_multiplier = payout_total / monto (ratio_total).

    Fuentes (en orden):
      1) payout_multiplier (nuevo BOT)
      2) payout_decimal_rounded (legacy ratio)
      3) payout legacy SOLO si parece RATIO (>=1.05 y <=3.50) o si con monto cuadra como total
      4) payout_total / monto

    Blindaje:
      - Si 'payout' parece ROI feature (0..1.5), se IGNORA como ratio/total.
      - Si 'payout' < 1.05, NO se acepta como ratio (en Deriv el ratio t√≠pico >1).
    """
    mult = _safe_float_local(row_dict_full.get("payout_multiplier"))
    if mult is not None and mult > 0:
        return mult

    mult = _safe_float_local(row_dict_full.get("payout_decimal_rounded"))
    if mult is not None and mult > 0:
        return mult

    monto = _safe_float_local(row_dict_full.get("monto"))
    p = _safe_float_local(row_dict_full.get("payout"))  # legacy (a veces ratio, a veces total, a veces ROI feature)

    # üîí Si payout parece ROI-feature (0..1.5), NO usarlo para ratio/total
    if p is not None and 0.0 <= p <= 1.5:
        p = None

    if p is not None and p > 0:
        if monto is not None and monto > 0:
            # Caso 1: p parece ratio t√≠pico (1.05..3.50)
            if 1.05 <= p <= 3.50:
                return p

            # Caso 2: p parece total (grande)
            if p > 3.50:
                return p / monto

            # Caso 3: p es "total peque√±o" (monto<1) donde p/monto cae como ratio
            # Ej: monto=0.5, payout_total=0.975 -> ratio=1.95
            cand = p / monto
            if 1.05 <= cand <= 3.50:
                return cand

            return None
        else:
            # Sin monto: solo aceptar si parece ratio t√≠pico
            if 1.05 <= p <= 3.50:
                return p
            return None

    # Fallback por payout_total expl√≠cito
    pay_total = _safe_float_local(row_dict_full.get("payout_total"))
    if pay_total is None:
        pay_total = _safe_float_local(row_dict_full.get("payout"))  # legacy total a veces

    if pay_total is not None and monto is not None and monto > 0:
        return pay_total / monto

    return None


def extraer_payout_total(row_dict_full: dict):
    """
    payout_total = retorno total (stake + profit).

    Fuentes (en orden):
      1) payout_total (nuevo BOT)
      2) payout legacy si parece total (>3.5)
      3) monto * payout_multiplier (incluye payout_decimal_rounded o ratio legacy)
      4) si payout legacy parece total (monto<1), usarlo como total
    """
    pay_total = _safe_float_local(row_dict_full.get("payout_total"))
    if pay_total is not None and pay_total > 0:
        return pay_total

    monto = _safe_float_local(row_dict_full.get("monto"))
    p = _safe_float_local(row_dict_full.get("payout"))  # legacy

    if p is not None and p > 0:
        # Claramente total
        if p > 3.50:
            return p

        # Caso monto<1: payout_total puede ser 0.975, que cae <=3.5
        if monto is not None and monto > 0:
            # Si p/monto cae como ratio t√≠pico, p es total
            cand = p / monto
            if 0.90 <= cand <= 3.50:
                return p  # total

    mult = extraer_payout_multiplier(row_dict_full)
    if monto is not None and mult is not None and monto > 0 and mult > 0:
        return monto * mult

    return None


def calcular_roi_desde_total_y_monto(payout_total: float, monto: float):
    if payout_total is None or monto is None or monto <= 0:
        return None
    return (payout_total / monto) - 1.0


def calcular_payout_feature(row_dict_full: dict):
    """
    Feature IA 'payout' = ROI = (payout_multiplier - 1).
    Fallback: (payout_total / monto) - 1 si no hay multiplier.
    """
    mult = extraer_payout_multiplier(row_dict_full)

    # ‚úÖ Rescate: algunos logs legacy guardan ratio en "payout" (ej 1.20, 1.35)
    # Esto NO confunde ROI real (ROI t√≠pico ser√≠a 0.20, no 1.20).
    if mult is None:
        try:
            p_leg = row_dict_full.get("payout", None)
            p_leg = float(p_leg) if p_leg is not None else None
            if p_leg is not None and math.isfinite(p_leg) and (1.05 <= p_leg <= 3.50):
                mult = float(p_leg)
        except Exception:
            pass

    if mult is not None:
        roi = float(mult) - 1.0
    else:
        payout_total = extraer_payout_total(row_dict_full)
        monto = _safe_float_local(row_dict_full.get("monto"))
        roi = calcular_roi_desde_total_y_monto(payout_total, monto)


    if roi is None:
        return None

    # clamps defensivos
    if roi < 0:
        roi = 0.0
    if roi > 1.5:
        roi = 1.5

    return roi

def normalizar_roi_0a1(roi):
    """Convierte ROI [0..1.5] a [0..1] cuando necesitas un 'factor'."""
    try:
        if roi is None:
            return 0.0
        roi = float(roi)
        if not math.isfinite(roi):
            return 0.0
        roi = max(0.0, min(roi, 1.5))
        return roi / 1.5
    except Exception:
        return 0.0
  
# Nueva: Clipping de features a rangos l√≥gicos (para blindaje contra outliers)
def clip_feature_values(fila_dict, feature_names):
    ranges = {
        "rsi_9": (0, 100),
        "rsi_14": (0, 100),
        "cruce_sma": (-1, 1),
        "breakout": (0, 1),
        "rsi_reversion": (0, 1),
        "racha_actual": (-50, 50),
        "payout": (0, 1.5),
        "puntaje_estrategia": (0, 1),
        "volatilidad": (0, 1),
        "es_rebote": (0, 1),
        "hora_bucket": (0, 1),
        # sma_5 / sma_20: no clip, pero s√≠ normalizar a float cuando se pueda
    }
    clipped = dict(fila_dict)

    for feat in feature_names:
        val = clipped.get(feat, None)

        # Normaliza a float si se puede
        try:
            if val is None or (isinstance(val, str) and val.strip() == ""):
                clipped[feat] = np.nan
                continue
            v = float(val)
            if not np.isfinite(v):
                clipped[feat] = np.nan
                continue
        except Exception:
            clipped[feat] = np.nan
            continue

        # Aplica clip solo donde hay rango definido
        if feat in ranges:
            lo, hi = ranges[feat]
            clipped[feat] = float(np.clip(v, lo, hi))
        else:
            clipped[feat] = float(v)

    return clipped
    
def calcular_volatilidad_simple(row_dict: dict) -> float:
    """
    Proxy de volatilidad 0‚Äì1 menos saturante que el clip lineal.

    Prioridad:
    1) spread relativo SMA5/SMA20
    2) fallback OHLC (high-low sobre close/open)
    """
    try:
        sma5 = float(row_dict.get("sma_5", 0.0) or 0.0)
        sma20 = float(row_dict.get("sma_20", 0.0) or 0.0)
    except Exception:
        sma5 = 0.0
        sma20 = 0.0

    base = abs(sma20) if abs(sma20) > 1e-9 else 0.0
    spread_pct = (abs(sma5 - sma20) / base) if base > 0 else 0.0

    # Fallback OHLC cuando SMA viene vac√≠o/plano
    if (not math.isfinite(spread_pct)) or spread_pct <= 0.0:
        try:
            hi = float(row_dict.get("high", row_dict.get("max", 0.0)) or 0.0)
            lo = float(row_dict.get("low", row_dict.get("min", 0.0)) or 0.0)
            c0 = float(row_dict.get("close", row_dict.get("precio_cierre", 0.0)) or 0.0)
            o0 = float(row_dict.get("open", row_dict.get("precio_apertura", 0.0)) or 0.0)
            base2 = max(abs(c0), abs(o0), 1e-9)
            spread_pct = abs(hi - lo) / base2
        except Exception:
            spread_pct = 0.0

    if not math.isfinite(spread_pct) or spread_pct <= 0.0:
        return 0.0

    # Compresi√≥n suave: 0 -> 0, crece r√°pido al inicio y evita techo constante.
    vol = 1.0 - math.exp(-40.0 * min(spread_pct, 0.25))
    return float(max(0.0, min(vol, 1.0)))
    

def calcular_volatilidad_por_bot(bot: str, lookback: int = 40) -> float | None:
    """
    Estima volatilidad 0..1 desde historial real del bot (retornos absolutos en close).
    Sirve como fallback cuando la fila puntual viene plana (vol=0 por falta de SMA/OHLC).
    """
    try:
        ruta = f"registro_enriquecido_{bot}.csv"
        if not os.path.exists(ruta):
            return None

        df = None
        for enc in ("utf-8", "utf-8-sig", "latin-1", "windows-1252"):
            try:
                df = pd.read_csv(ruta, encoding=enc, engine="python", on_bad_lines="skip")
                break
            except Exception:
                continue
        if df is None or df.empty:
            return None

        close_col = None
        for c in ("close", "precio_cierre", "price", "spot", "last_price"):
            if c in df.columns:
                close_col = c
                break
        if close_col is None:
            return None

        sclose = pd.to_numeric(df[close_col], errors="coerce").dropna()
        if len(sclose) < 6:
            return None

        sclose = sclose.tail(int(max(8, lookback)))
        rets = sclose.pct_change().replace([np.inf, -np.inf], np.nan).dropna().abs()
        if len(rets) < 4:
            return None

        # Mediana robusta de retorno absoluto + compresi√≥n suave a [0,1]
        med = float(rets.median())
        if (not math.isfinite(med)) or med <= 0.0:
            return None

        vol = 1.0 - math.exp(-120.0 * min(med, 0.20))
        return float(max(0.0, min(vol, 1.0)))
    except Exception:
        return None


# --- Helper: detectar rebote tras racha larga negativa --- 
def calcular_es_rebote(row_dict):
    """
    es_rebote = 1 si:
      - |racha_actual| >= 4  (racha larga, positiva o negativa)
      - y hay se√±al de giro (RSI reversi√≥n alta, breakout fuerte o cruce+fuerza a favor)
    En caso contrario, 0.
    """
    try:
        racha = float(row_dict.get("racha_actual", 0) or 0.0)
    except Exception:
        racha = 0.0

    # Solo consideramos rebote cuando la racha (ganadora o perdedora) es larga
    if abs(racha) < 4:
        return 0.0

    def _safe_num(key, default=0.0):
        try:
            return float(row_dict.get(key, default) or default)
        except Exception:
            return default

    rsi_rev  = _safe_num("rsi_reversion", 0.0)
    breakout = _safe_num("breakout", 0.0)
    cruce    = _safe_num("cruce_sma", 0.0)
    fuerza   = _safe_num("fuerza_vela", 0.0)

    # "Se√±al de giro": cualquiera de estos empuja a rebote
    giro_flag = (
        rsi_rev >= 0.60 or
        breakout >= 0.50 or
        (cruce > 0 and fuerza > 0)
    )

    if not giro_flag:
        return 0.0

    # Intensidad de rebote (evita booleano congelado):
    # combina longitud de racha + fuerza de se√±ales de giro en [0,1].
    intensidad_racha = min(1.0, max(0.0, (abs(racha) - 3.0) / 6.0))
    intensidad_giro = min(
        1.0,
        max(
            0.0,
            0.45 * min(1.0, rsi_rev) +
            0.35 * min(1.0, breakout) +
            0.20 * (1.0 if (cruce > 0 and fuerza > 0) else 0.0)
        )
    )
    return max(0.0, min(1.0, 0.60 * intensidad_racha + 0.40 * intensidad_giro))

def _parse_hora_bucket(row_dict) -> tuple[float, bool]:
    """Parsea hora y devuelve (bucket_0_1, parseado_ok)."""
    def _missing(v):
        if v is None:
            return True
        try:
            if pd.isna(v):
                return True
        except Exception:
            pass
        return isinstance(v, str) and v.strip() == ""

    def _bucket(hour: int, minute: int = 0):
        h = int(max(0, min(23, hour)))
        m = int(max(0, min(59, minute)))
        idx_48 = (h * 2) + (1 if m >= 30 else 0)
        return float(idx_48) / 47.0

    v = (row_dict or {}).get("ts", None)
    if not _missing(v) and isinstance(v, str):
        try:
            dt = pd.to_datetime(v, utc=True, errors="coerce")
            if dt is not None and pd.notna(dt):
                try:
                    dt = dt.tz_convert("America/Lima")
                except Exception:
                    pass
                return _bucket(int(dt.hour), int(dt.minute)), True
        except Exception:
            pass

    for k in ("epoch", "timestamp", "open_epoch", "close_epoch", "entry_epoch", "ts_epoch", "server_time"):
        v = (row_dict or {}).get(k, None)
        if _missing(v):
            continue
        try:
            val = float(v)
            if val > 1e12:
                val = val / 1000.0
            if val > 1e9:
                dt = pd.to_datetime(val, unit="s", utc=True, errors="coerce")
                if dt is not None and pd.notna(dt):
                    try:
                        dt = dt.tz_convert("America/Lima")
                    except Exception:
                        pass
                    return _bucket(int(dt.hour), int(dt.minute)), True
        except Exception:
            pass

    v = (row_dict or {}).get("fecha", None)
    if not _missing(v) and isinstance(v, str):
        try:
            dt = pd.to_datetime(v, errors="coerce")
            if dt is not None and pd.notna(dt):
                return _bucket(int(dt.hour), int(dt.minute)), True
        except Exception:
            pass

    v = (row_dict or {}).get("hora", None)
    if not _missing(v) and isinstance(v, str):
        try:
            s = v.strip()
            if ":" in s:
                h = int(s.split(":")[0])
                if 0 <= h <= 23:
                    mm = 0
                    if len(s.split(":")) >= 2:
                        try:
                            mm = int(s.split(":")[1])
                        except Exception:
                            mm = 0
                    return _bucket(h, mm), True
        except Exception:
            pass

    return 0.0, False


def calcular_hora_bucket(row_dict):
    """Devuelve bucket horario normalizado 0..1 (fallback 0.0)."""
    hb, _ok = _parse_hora_bucket(row_dict)
    return float(hb)


def calcular_hora_features(row_dict: dict) -> tuple[float, float]:
    """
    Contrato horario expl√≠cito:
      - hora_bucket: 0..1
      - hora_missing: 1.0 cuando falta hora parseable, 0.0 en caso contrario.

    Si no hay timestamp parseable, usa hora local actual como fallback suave
    para evitar colapsar hora_bucket en un valor constante hist√≥rico.
    """
    hb, parsed_ok = _parse_hora_bucket(row_dict)
    if not bool(parsed_ok):
        try:
            lt = time.localtime()
            idx48 = int(lt.tm_hour * 2 + (1 if lt.tm_min >= 30 else 0))
            hb = float(max(0, min(47, idx48))) / 47.0
        except Exception:
            hb = 0.0
    try:
        hb = float(hb)
    except Exception:
        hb = 0.0
    hb = float(max(0.0, min(1.0, hb)))
    hm = 0.0 if bool(parsed_ok) else 1.0
    return hb, hm


def _calcular_sma_spread_robusto(row_dict: dict | None) -> float | None:
    """Calcula sma_spread continuo con fallback de denominador para evitar constantes artificiales."""
    try:
        d = dict(row_dict or {})
        sma5 = _safe_float_local(d.get("sma_5"))
        sma20 = _safe_float_local(d.get("sma_20"))
        px = None
        for k in ("close", "cierre", "price", "precio"):
            v = _safe_float_local(d.get(k))
            if v is not None and math.isfinite(float(v)) and abs(float(v)) > 1e-12:
                px = float(v)
                break

        if sma5 is None and sma20 is None:
            return None

        if sma5 is None:
            sma5 = sma20
        if sma20 is None:
            sma20 = sma5

        denom = abs(float(sma20))
        if (not math.isfinite(denom)) or denom <= 1e-12:
            denom = abs(float(px)) if px is not None else 1e-9

        spread = abs(float(sma5) - float(sma20)) / max(denom, 1e-9)
        if not math.isfinite(spread):
            return None
        return float(max(0.0, min(float(spread), 5.0)))
    except Exception:
        return None


def _calcular_eventos_pretrade_desde_historial(df: pd.DataFrame, idx_ref: int, row_base: dict | None = None) -> dict:
    """
    Calcula se√±ales de evento (no estado) para PRE_TRADE usando solo pasado <= idx_ref.
    - cruce_sma: 1 solo si cambia el signo de (sma_5 - sma_20) entre vela previa y actual.
    - breakout: 1 solo si el close rompe max/min de ventana previa (sin incluir vela actual).
    - sma_spread: intensidad continua del spread SMA (0..5) para conservar informaci√≥n.
    """
    out = dict(row_base or {})
    try:
        if df is None or df.empty:
            return out

        if idx_ref not in df.index:
            return out

        pos = int(df.index.get_indexer([idx_ref])[0])
        if pos < 0:
            return out

        d = df.copy()
        for c in ("sma_5", "sma_20", "close", "cierre", "price", "precio", "high", "maximo", "low", "minimo"):
            if c in d.columns:
                d[c] = pd.to_numeric(d[c], errors="coerce")

        row_now = d.iloc[pos]
        sma5 = _safe_float_local(row_now.get("sma_5"))
        sma20 = _safe_float_local(row_now.get("sma_20"))

        # Intensidad de spread SMA (continua)
        if sma5 is not None and sma20 is not None:
            sp = _calcular_sma_spread_robusto({"sma_5": sma5, "sma_20": sma20, "close": row_now.get("close", None)})
            if sp is not None:
                out["sma_spread"] = float(sp)

        # cruce_sma como evento (cambio de signo)
        cruce_evt = 0.0
        if pos >= 1 and sma5 is not None and sma20 is not None:
            row_prev = d.iloc[pos - 1]
            sma5_prev = _safe_float_local(row_prev.get("sma_5"))
            sma20_prev = _safe_float_local(row_prev.get("sma_20"))
            if sma5_prev is not None and sma20_prev is not None:
                prev_diff = float(sma5_prev) - float(sma20_prev)
                now_diff = float(sma5) - float(sma20)
                if (prev_diff < 0.0 <= now_diff) or (prev_diff > 0.0 >= now_diff):
                    cruce_evt = 1.0
        out["cruce_sma"] = cruce_evt

        # breakout como evento (rompe m√°ximo/m√≠nimo de ventana previa)
        breakout_evt = 0.0
        lookback = 20
        if pos >= 2:
            i0 = max(0, pos - lookback)
            hist = d.iloc[i0:pos]
            if not hist.empty:
                close_now = None
                for cc in ("close", "cierre", "price", "precio"):
                    v = _safe_float_local(row_now.get(cc))
                    if v is not None:
                        close_now = float(v)
                        break

                hi_prev = None
                lo_prev = None
                for hc in ("high", "maximo", "close", "cierre"):
                    if hc in hist.columns:
                        s = pd.to_numeric(hist[hc], errors="coerce").dropna()
                        if len(s) > 0:
                            hi_prev = float(s.max())
                            break
                for lc in ("low", "minimo", "close", "cierre"):
                    if lc in hist.columns:
                        s = pd.to_numeric(hist[lc], errors="coerce").dropna()
                        if len(s) > 0:
                            lo_prev = float(s.min())
                            break

                if close_now is not None and hi_prev is not None and lo_prev is not None:
                    if (close_now > hi_prev) or (close_now < lo_prev):
                        breakout_evt = 1.0
        out["breakout"] = breakout_evt

    except Exception:
        return out
    return out


def enriquecer_features_evento(row_dict: dict):
    """Convierte se√±ales binarias en intensidades continuas para reducir dominancia."""
    d = dict(row_dict or {})

    def _f(key, default=0.0):
        try:
            v = d.get(key, default)
            if v in (None, ""):
                return float(default)
            return float(v)
        except Exception:
            return float(default)

    sma5 = _f("sma_5", 0.0)
    sma20 = _f("sma_20", 0.0)
    base = max(abs(sma20), 1e-9)
    spread = abs(sma5 - sma20) / base

    vol_raw = d.get("volatilidad", None)
    if vol_raw in (None, ""):
        vol = calcular_volatilidad_simple(d)
    else:
        try:
            vol = float(vol_raw)
        except Exception:
            vol = calcular_volatilidad_simple(d)
    vol = max(0.0, min(1.0, float(vol)))
    d["volatilidad"] = float(vol)

    rsi9 = _f("rsi_9", 50.0)
    rsi14 = _f("rsi_14", 50.0)
    rsi_center_dist = min(1.0, (abs(rsi9 - 50.0) + abs(rsi14 - 50.0)) / 70.0)

    cruce_raw = _f("cruce_sma", 0.0)
    cruce_int = spread / (spread + 0.0015) if spread > 0 else 0.0
    d["cruce_sma"] = float(max(0.0, min(1.0, 0.75 * cruce_int + 0.25 * (1.0 if cruce_raw >= 0.5 else 0.0))))

    breakout_raw = _f("breakout", 0.0)
    breakout_int = max(0.0, min(1.0, 0.45 * (spread / (spread + 0.0020) if spread > 0 else 0.0) + 0.35 * vol + 0.20 * rsi_center_dist))
    d["breakout"] = float(max(0.0, min(1.0, 0.55 * breakout_int + 0.45 * (1.0 if breakout_raw >= 0.5 else 0.0))))

    low_ext = max(0.0, (35.0 - min(rsi9, rsi14)) / 35.0)
    high_ext = max(0.0, (max(rsi9, rsi14) - 65.0) / 35.0)
    rsi_rev_int = max(low_ext, high_ext, 0.35 * rsi_center_dist)
    d["rsi_reversion"] = float(max(0.0, min(1.0, rsi_rev_int)))

    reb_base = float(max(0.0, min(1.0, calcular_es_rebote(d))))
    racha = abs(_f("racha_actual", 0.0))
    racha_term = max(0.0, min(1.0, racha / 10.0))
    d["es_rebote"] = float(max(0.0, min(1.0, 0.60 * reb_base + 0.25 * d["rsi_reversion"] + 0.15 * racha_term)))

    try:
        pe = calcular_puntaje_estrategia_normalizado(d)
        if pe is not None:
            d["puntaje_estrategia"] = float(max(0.0, min(1.0, float(pe))))
    except Exception:
        pass

    return d

# === Nuevo: c√°lculo enriquecido de puntaje_estrategia normalizado (0‚Äì1) ===
def calcular_puntaje_estrategia_normalizado(fila: dict) -> float:
    """
    Puntaje 0..1 usando se√±ales + RSI + ROI (payout como ROI [0..1.5]).
    Robusto a valores 1.0/0.0 y strings.
    """
    def as_cont01(x):
        try:
            if isinstance(x, str):
                x = x.strip().lower()
                if x in ("1", "true", "yes", "y"):
                    return 1.0
                if x in ("0", "false", "no", "n", ""):
                    return 0.0
            v = float(x)
            if not math.isfinite(v):
                return 0.0
            return max(0.0, min(1.0, v))
        except Exception:
            return 0.0

    score = 0.0

    # IMPORTANTE: score continuo (NO binarizar se√±ales continuas por umbral >=0.5)
    breakout      = as_cont01(fila.get("breakout", 0))
    cruce_sma     = as_cont01(fila.get("cruce_sma", 0))
    rsi_reversion = as_cont01(fila.get("rsi_reversion", 0))
    es_rebote     = as_cont01(fila.get("es_rebote", 0))

    score += breakout * 0.24
    score += cruce_sma * 0.20
    score += rsi_reversion * 0.18
    score += es_rebote * 0.14

    # RSI zona caliente (bonus peque√±o)
    try:
        rsi_9 = float(fila.get("rsi_9", 50.0) or 50.0)
        rsi_14 = float(fila.get("rsi_14", 50.0) or 50.0)
        if rsi_9 >= 70 or rsi_14 >= 70:
            score += 0.05
        if rsi_9 <= 30 or rsi_14 <= 30:
            score += 0.05
    except Exception:
        pass

    # ROI (feature payout) en 0..1
    # Si ya viene como ROI (0..1.5) √∫salo directo; si no, reci√©n calcula.
    roi = fila.get("payout", None)
    try:
        roi = float(roi)
        # Si parece ROI v√°lido
        if (not math.isfinite(roi)) or roi < 0 or roi > 1.5:
            roi = None
    except Exception:
        roi = None

    if roi is None:
        roi = calcular_payout_feature(fila)  # fallback

    roi01 = 0.0
    try:
        roi01 = max(0.0, min(float(roi or 0.0), 1.5)) / 1.5
    except Exception:
        roi01 = 0.0

    score += roi01 * 0.05

    try:
        vol = float(fila.get("volatilidad", 0.0) or 0.0)
    except Exception:
        vol = 0.0
    vol = max(0.0, min(1.0, vol))
    score += 0.08 * vol

    try:
        hb = float(fila.get("hora_bucket", 0.5) or 0.5)
    except Exception:
        hb = 0.5
    hb = max(0.0, min(1.0, hb))
    score += 0.03 * (1.0 - abs((hb * 2.0) - 1.0))

    if not math.isfinite(score):
        score = 0.0
    return max(0.0, min(score, 1.0))

# Leer √∫ltima fila v√°lida
def leer_ultima_fila_con_resultado(bot: str) -> tuple[dict | None, int | None]:
    """
    Devuelve (fila_dict_features_pretrade, label) emparejando:
      - LABEL: desde el √∫ltimo trade CERRADO (GANANCIA/P√âRDIDA)
      - FEATURES: desde el PRE_TRADE/PENDIENTE del mismo epoch (o el m√°s cercano ANTES)

    FIX CLAVE:
      - racha_actual se RECALCULA desde el historial de CIERRES ANTERIORES,
        excluyendo SIEMPRE el cierre actual (anti-contaminaci√≥n).
      - payout(feature) prioriza ratio cotizado (mult/decimal_rounded).
        Si existe payout_total en PRE_TRADE, se usa como fallback seguro (m√°s rango real).
    """
    try:
        ruta = f"registro_enriquecido_{bot}.csv"
        if not os.path.exists(ruta):
            return None, None

        df = None
        for enc in ("utf-8", "latin-1", "windows-1252"):
            try:
                df = pd.read_csv(ruta, sep=",", encoding=enc, engine="python", on_bad_lines="skip")
                break
            except Exception:
                continue

        if df is None or df.empty:
            return None, None
        if "resultado" not in df.columns:
            return None, None

        # Normalizar resultado robusto
        df["resultado_norm"] = df["resultado"].apply(normalizar_resultado)

        # Normalizar trade_status de forma can√≥nica (evita CLOSED/SETTLED vs CERRADO)
        # IMPORTANT√çSIMO:
        # - No basta con que exista la columna: debe haber valores reales.
        # - normalizar_trade_status() canoniza a: "CERRADO" o "PRE_TRADE" (o "")
        ts_source_col = None
        if "trade_status_norm" in df.columns:
            ts_source_col = "trade_status_norm"
        elif "trade_status" in df.columns:
            ts_source_col = "trade_status"

        if ts_source_col:
            try:
                df["trade_status_norm"] = df[ts_source_col].apply(normalizar_trade_status)
            except Exception:
                df["trade_status_norm"] = ""
        else:
            df["trade_status_norm"] = ""

        # has_trade_status = hay valores reales (no solo columna vac√≠a)
        try:
            has_trade_status = df["trade_status_norm"].astype(str).str.strip().ne("").any()
        except Exception:
            has_trade_status = False

        def _calc_racha_pretrade(_df: pd.DataFrame, _idx_close: int) -> float:
            """
            racha_actual PRE-TRADE:
              - Usa SOLO cierres (GANANCIA/P√âRDIDA)
              - Usa SOLO filas con √≠ndice < idx_close (excluye el cierre actual)
              - Si hay trade_status usable, acepta:
                    * CERRADO
                    * "" (legacy sin status) PERO solo si es cierre real por resultado_norm
              - Devuelve racha firmada: +N (wins), -N (losses), 0 si no hay historial
            """
            try:
                try:
                    d = _df.loc[_df.index < _idx_close].copy()
                except Exception:
                    d = _df.copy()

                d = d[d["resultado_norm"].isin(["GANANCIA", "P√âRDIDA"])].copy()
                if d.empty:
                    return 0.0

                if has_trade_status and "trade_status_norm" in d.columns:
                    try:
                        ts = d["trade_status_norm"].astype(str).str.strip()
                        d = d[(ts.eq("CERRADO")) | (ts.eq(""))].copy()
                    except Exception:
                        d = d[d["trade_status_norm"].eq("CERRADO")].copy()

                if d.empty:
                    return 0.0

                seq = d["resultado_norm"].tolist()
                last = seq[-1]
                streak = 0
                for r in reversed(seq):
                    if r == last:
                        streak += 1
                    else:
                        break

                val = float(streak if last == "GANANCIA" else -streak)
                if val > 50:
                    val = 50.0
                if val < -50:
                    val = -50.0
                return val
            except Exception:
                return 0.0

        # 1) √öltimo cierre v√°lido (label)
        df_cerr = df[df["resultado_norm"].isin(["GANANCIA", "P√âRDIDA"])].copy()

        # Si hay trade_status usable, filtramos CERRADO o "" (legacy)
        if has_trade_status:
            try:
                ts = df_cerr["trade_status_norm"].astype(str).str.strip()
                df_cerr = df_cerr[(ts.eq("CERRADO")) | (ts.eq(""))].copy()
            except Exception:
                df_cerr = df_cerr[df_cerr["trade_status_norm"].eq("CERRADO")].copy()

        if df_cerr.empty:
            return None, None

        idx_close = int(df_cerr.index[-1])
        r_close = df.loc[idx_close].to_dict()
        epoch_close = r_close.get("epoch", None)

        res_norm = r_close.get("resultado_norm", None)
        if res_norm not in ("GANANCIA", "P√âRDIDA"):
            res_norm = normalizar_resultado(r_close.get("resultado"))
        label = 1 if res_norm == "GANANCIA" else 0

        # 2) Buscar PRE_TRADE correspondiente (SIN futuro)
        pre_row = None
        pre_idx = None

        if has_trade_status:
            # ‚úÖ OJO: despu√©s del normalizador solo existe PRE_TRADE (no PENDIENTE/OPEN/ABIERTO)
            df_pending = df[df["trade_status_norm"].eq("PRE_TRADE")].copy()

            # evitar futuro: solo filas con √≠ndice <= cierre
            try:
                df_pending = df_pending.loc[df_pending.index <= idx_close]
            except Exception:
                pass

            # prioridad: mismo epoch
            if epoch_close is not None and "epoch" in df_pending.columns:
                try:
                    ep = pd.to_numeric(df_pending["epoch"], errors="coerce")
                    ec = float(epoch_close)
                    same_ep = df_pending[ep.notna() & (ep == ec)].copy()
                except Exception:
                    same_ep = df_pending[df_pending["epoch"] == epoch_close].copy()

                if not same_ep.empty:
                    pre_idx = int(same_ep.index[-1])
                    pre_row = df.loc[pre_idx].to_dict()

            # fallback: √∫ltimo PRE_TRADE antes del cierre
            if pre_row is None and not df_pending.empty:
                pre_idx = int(df_pending.index[-1])
                pre_row = df.loc[pre_idx].to_dict()

        # ‚úÖ Fallback UNIVERSAL:
        # Si no hubo PRE_TRADE (o trade_status era ‚Äúusable‚Äù pero no encontr√≥), usamos la √∫ltima fila NO cierre antes del cierre.
        if pre_row is None:
            try:
                df_before = df.loc[df.index <= idx_close].copy()
            except Exception:
                df_before = df.copy()

            cand = df_before[~df_before["resultado_norm"].isin(["GANANCIA", "P√âRDIDA"])].copy()
            if not cand.empty:
                pre_idx = int(cand.index[-1])
                pre_row = df.loc[pre_idx].to_dict()
            else:
                pre_idx = int(df_before.index[-1])
                pre_row = df.loc[pre_idx].to_dict()

        if pre_row is None:
            return None, None

        row_dict_full = canonicalizar_campos_bot_maestro(pre_row)

        # Se√±ales de evento reales (anti-saturaci√≥n): usar solo historial pasado hasta PRE_TRADE.
        try:
            if pre_idx is not None:
                row_dict_full = _calcular_eventos_pretrade_desde_historial(df, int(pre_idx), row_base=row_dict_full)
        except Exception:
            pass

        # 3) Asegurar monto (stake) desde PRE; si falta, tomar del cierre (monto NO filtra label)
        if ("monto" not in row_dict_full) or (row_dict_full.get("monto") in (None, "", 0, 0.0)):
            if "monto" in r_close:
                row_dict_full["monto"] = r_close.get("monto")

        # 4) Copiar ratio cotizado desde cierre SOLO si viene como multiplier/decimal_rounded (ratio seguro)
        for k in ("payout_multiplier", "payout_decimal_rounded"):
            if (k not in row_dict_full) or (row_dict_full.get(k) in (None, "", 0, 0.0)):
                if k in r_close:
                    row_dict_full[k] = r_close.get(k)

        # 4.9) Anti-leakage duro:
        # - Nunca permitir campos que puedan oler al cierre (resultado/profit).
        for k in ("ganancia_perdida", "profit", "resultado", "resultado_norm"):
            try:
                row_dict_full.pop(k, None)
            except Exception:
                pass

        # payout_total: SOLO lo permitimos si viene del PRE_TRADE/PENDIENTE (no cierre).
        # Importante: detectar CERRADO tambi√©n si viene como CLOSED/SETTLED.
        try:
            ts_pre_norm = normalizar_trade_status(
                pre_row.get("trade_status_norm", None) or pre_row.get("trade_status", None)
            )
        except Exception:
            ts_pre_norm = ""

        if ts_pre_norm == "CERRADO":
            try:
                row_dict_full.pop("payout_total", None)
            except Exception:
                pass
        else:
            try:
                pt = _safe_float_local(row_dict_full.get("payout_total"))
                if pt is not None and pt <= 0:
                    row_dict_full.pop("payout_total", None)
            except Exception:
                try:
                    row_dict_full.pop("payout_total", None)
                except Exception:
                    pass


        # 5) FIX CONTAMINACI√ìN: recalcular racha_actual PRE-TRADE desde historia real
        racha_safe = _calc_racha_pretrade(df, idx_close)
        try:
            old_racha = _safe_float_local(row_dict_full.get("racha_actual"))
        except Exception:
            old_racha = None

        row_dict_full["racha_actual"] = float(racha_safe)

        # opcional: avisar SOLO si hab√≠a valor y cambia fuerte (√∫til para ver contaminaci√≥n)
        try:
            if old_racha is not None and math.isfinite(float(old_racha)):
                if abs(float(old_racha) - float(racha_safe)) >= 1.0:
                    fn_evt = globals().get("agregar_evento", None)
                    if callable(fn_evt):
                        fn_evt(f"üßº racha_actual corregida {bot}: {old_racha:.0f} ‚Üí {racha_safe:.0f} (anti-contaminaci√≥n)")
        except Exception:
            pass

        # Blindaje: si 'payout' existe, puede ser ROI-feature (0..1.5) o total legacy.
        # - ROI-feature: ignorar SIEMPRE (no sirve para ratio)
        # - total grande o ratio inv√°lido: ignorar
        try:
            _p = _safe_float_local(row_dict_full.get("payout"))
            if _p is not None:
                if 0.0 <= _p <= 1.5:
                    row_dict_full["payout"] = None
                elif _p > 3.50:
                    row_dict_full["payout"] = None
                elif _p < 1.05:
                    row_dict_full["payout"] = None
        except Exception:
            pass

        # 6) payout feature (ROI) usando ratio cotizado / payout_total PRETRADE como fallback seguro
        mult = extraer_payout_multiplier(row_dict_full)

        # Si no hay ratio, inferimos por moda hist√≥rica del ratio (SOLO hasta el cierre)
        if mult is None:
            mult_moda = None
            try:
                df_hist = df.loc[df.index <= idx_close].copy()

                cand_cols = []
                if "payout_multiplier" in df_hist.columns:
                    cand_cols.append("payout_multiplier")
                if "payout_decimal_rounded" in df_hist.columns:
                    cand_cols.append("payout_decimal_rounded")

                for col in cand_cols:
                    s = pd.to_numeric(df_hist[col], errors="coerce").dropna()
                    if len(s) > 0:
                        moda = float(s.value_counts().idxmax())
                        if 1.05 < moda < 3.50:
                            mult_moda = moda
                            break
            except Exception:
                mult_moda = None

            if mult_moda is None:
                return None, None
            mult = float(mult_moda)

        try:
            pay_ok = float(mult) - 1.0
        except Exception:
            return None, None

        if not math.isfinite(pay_ok):
            return None, None

        pay_ok = max(0.0, min(pay_ok, 1.5))
        row_dict_full["payout"] = float(pay_ok)

        # 7) Completar derivados si faltan
        vol = _safe_float_local(row_dict_full.get("volatilidad"))
        if vol is None:
            vol = calcular_volatilidad_simple(row_dict_full)
        if vol is None or not math.isfinite(float(vol)):
            return None, None
        row_dict_full["volatilidad"] = float(vol)

        hb = _safe_float_local(row_dict_full.get("hora_bucket"))
        if hb is None:
            hb, hm = calcular_hora_features(row_dict_full)
            row_dict_full["hora_missing"] = float(hm)
        if hb is None or not math.isfinite(float(hb)):
            return None, None
        row_dict_full["hora_bucket"] = float(hb)

        # Enriquecer se√±ales evento para evitar columnas booleanas congeladas
        row_dict_full = enriquecer_features_evento(row_dict_full)

        er = _safe_float_local(row_dict_full.get("es_rebote"))
        if er is None:
            er = calcular_es_rebote(row_dict_full)
        if er is None or not math.isfinite(float(er)):
            return None, None
        row_dict_full["es_rebote"] = float(er)

        pe = None
        try:
            pe = calcular_puntaje_estrategia_normalizado(row_dict_full)
        except Exception:
            pe = None

        if pe is None:
            pe_raw = _safe_float_local(row_dict_full.get("puntaje_estrategia"))
            if pe_raw is None:
                return None, None
            pe = _norm_01(pe_raw)

        pe = float(pe)
        if not math.isfinite(pe):
            return None, None
        pe = max(0.0, min(pe, 1.0))
        row_dict_full["puntaje_estrategia"] = pe

        try:
            sma5 = _safe_float_local(row_dict_full.get("sma_5"))
            sma20 = _safe_float_local(row_dict_full.get("sma_20"))
            if sma5 is not None and sma20 is not None:
                sp = _calcular_sma_spread_robusto({"sma_5": sma5, "sma_20": sma20, "close": row_dict_full.get("close", None)})
                if sp is not None:
                    row_dict_full["sma_spread"] = float(sp)
        except Exception:
            pass

        # 8) Features requeridas (13 core, estricto)
        required = [
            "rsi_9","rsi_14","sma_5","sma_spread","cruce_sma","breakout",
            "rsi_reversion","racha_actual","payout","puntaje_estrategia",
            "volatilidad","es_rebote","hora_bucket",
        ]

        fila_dict = {}
        for k in required:
            fv = _safe_float_local(row_dict_full.get(k))
            if fv is None or not math.isfinite(float(fv)):
                return None, None
            fila_dict[k] = float(fv)

        return fila_dict, int(label)

    except Exception as e:
        print(f"[WARN] leer_ultima_fila_con_resultado({bot}) fallo: {e}")
        return None, None

# ==========================================================
# === BLOQUE 10A ‚Äî AUDITOR√çA DE SE√ëALES IA (solo logging; NO toca trading) ===
# Objetivo:
# - Registrar se√±ales IA (bot, epoch, prob, thr, modo) en ia_signals_log.csv
# - Cerrar se√±ales cuando aparezca el CIERRE real (GANANCIA/P√âRDIDA) para ese epoch
# - Calcular m√©tricas simples (Brier/AUC/Acc) con se√±ales cerradas
# ==========================================================

IA_SIGNALS_LOG = "ia_signals_log.csv"
CANARY_STATE_CACHE = {"ts": 0.0, "meta": None}

# Blindaje: evita crash si threading a√∫n no estaba importado (aunque t√∫ s√≠ lo tienes)
try:
    import threading as _audit_threading
    IA_SIGNALS_LOCK = _audit_threading.Lock()
except Exception:
    class _DummyLock:
        def __enter__(self): return self
        def __exit__(self, exc_type, exc, tb): return False
    IA_SIGNALS_LOCK = _DummyLock()

def _col_as_str_series(df: pd.DataFrame, col: str) -> pd.Series:
    """Devuelve df[col] como Series(str) y trata NaN como vac√≠o (""). Si no existe, Series vac√≠a del tama√±o del df."""
    try:
        if col in df.columns:
            s = df[col]
            try:
                s = s.fillna("")
            except Exception:
                pass
            return s.astype(str)
        return pd.Series([""] * len(df), index=df.index, dtype="object")
    except Exception:
        return pd.Series([""] * len(df), index=df.index, dtype="object")

def _ag_evt(msg: str):
    try:
        fn = globals().get("agregar_evento", None)
        if callable(fn):
            fn(msg)
        else:
            print(msg)
    except Exception:
        pass

def _safe_read_csv_any_encoding(path: str) -> pd.DataFrame | None:
    if not os.path.exists(path):
        return None
    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            return pd.read_csv(path, sep=",", encoding=enc, engine="python", on_bad_lines="skip")
        except Exception:
            continue
    return None

_IA_RUNTIME_CAL_CACHE = {"ts": 0.0, "base_rate": 0.5, "n70": 0}
_GATE_ACTIVO_CACHE = {}
_GATE_SEGMENTO_CACHE = {}


def _bucket_tercil(v: float, q1: float, q2: float) -> str:
    try:
        x = float(v)
    except Exception:
        x = 0.0
    if x <= q1:
        return "bajo"
    if x <= q2:
        return "medio"
    return "alto"


def _inferir_segmento_hora(hb01: float) -> str:
    try:
        hb = int(round(max(0.0, min(1.0, float(hb01))) * 23.0))
    except Exception:
        hb = 12
    h0 = (hb // 6) * 6
    h1 = min(h0 + 5, 23)
    return f"h{h0:02d}-{h1:02d}"


def _segmento_key_from_df(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    d["payout"] = pd.to_numeric(d.get("payout", 0.0), errors="coerce").fillna(0.0)
    d["volatilidad"] = pd.to_numeric(d.get("volatilidad", 0.0), errors="coerce").fillna(0.0)
    d["hora_bucket"] = pd.to_numeric(d.get("hora_bucket", 0.0), errors="coerce").fillna(0.0)

    p_q1 = float(d["payout"].quantile(1/3)) if len(d) else 0.0
    p_q2 = float(d["payout"].quantile(2/3)) if len(d) else 0.0
    v_q1 = float(d["volatilidad"].quantile(1/3)) if len(d) else 0.0
    v_q2 = float(d["volatilidad"].quantile(2/3)) if len(d) else 0.0

    d["seg_payout"] = d["payout"].map(lambda x: _bucket_tercil(x, p_q1, p_q2))
    d["seg_vol"] = d["volatilidad"].map(lambda x: _bucket_tercil(x, v_q1, v_q2))
    d["seg_hora"] = d["hora_bucket"].map(_inferir_segmento_hora)
    d["seg_key"] = d["seg_payout"].astype(str) + "|" + d["seg_vol"].astype(str) + "|" + d["seg_hora"].astype(str)
    return d


def _gate_segmento_ok(bot: str, ctx: dict, ttl_s: float = 45.0):
    """Gate por segmento operativo (payout/vol/hora) para explotar zonas con se√±al y filtrar planas."""
    try:
        if not bool(globals().get("GATE_SEGMENTO_ENABLED", True)):
            return True, 0.5, 0, "off"

        seg_key = "NA|NA|NA"
        try:
            pb = str(ctx.get("seg_payout", "") or "").strip()
            vb = str(ctx.get("seg_vol", "") or "").strip()
            hs = str(ctx.get("seg_hora", "") or "").strip()
            if pb and vb and hs:
                seg_key = f"{pb}|{vb}|{hs}"
        except Exception:
            seg_key = "NA|NA|NA"

        now = time.time()
        key = f"{bot}|{seg_key}"
        c = _GATE_SEGMENTO_CACHE.get(key)
        if c and (now - float(c.get("ts", 0.0))) <= float(ttl_s):
            return bool(c.get("ok", True)), float(c.get("wr", 0.5)), int(c.get("n", 0)), str(c.get("seg", seg_key))

        ruta = f"registro_enriquecido_{bot}.csv"
        if not os.path.exists(ruta):
            return True, 0.5, 0, seg_key

        df = None
        for enc in ("utf-8", "latin-1", "windows-1252"):
            try:
                df = pd.read_csv(ruta, encoding=enc, on_bad_lines="skip")
                break
            except Exception:
                continue

        if df is None or df.empty:
            return True, 0.5, 0, seg_key

        if "trade_status" in df.columns:
            d = df[df["trade_status"].astype(str).str.upper().eq("CERRADO")].copy()
        else:
            d = df.copy()

        if "result_bin" not in d.columns:
            return True, 0.5, 0, seg_key

        d["result_bin"] = pd.to_numeric(d["result_bin"], errors="coerce")
        d = d[d["result_bin"].isin([0, 1])].copy()
        if d.empty:
            return True, 0.5, 0, seg_key

        d = _segmento_key_from_df(d)

        if int(GATE_SEGMENTO_LOOKBACK) > 0 and len(d) > int(GATE_SEGMENTO_LOOKBACK):
            d = d.tail(int(GATE_SEGMENTO_LOOKBACK)).copy()

        seg = d[d["seg_key"].astype(str).eq(str(seg_key))]
        n = int(len(seg))
        wr = float(seg["result_bin"].mean()) if n > 0 else 0.5
        ok = True
        if n >= int(GATE_SEGMENTO_MIN_MUESTRA):
            ok = bool(wr >= float(GATE_SEGMENTO_MIN_WR))

        _GATE_SEGMENTO_CACHE[key] = {"ts": now, "ok": ok, "wr": wr, "n": n, "seg": seg_key}
        return ok, wr, n, seg_key
    except Exception:
        return True, 0.5, 0, "NA|NA|NA"


def _ultimo_contexto_operativo_bot(bot: str) -> dict:
    """Lee contexto reciente (racha/es_rebote/activo) para gate de calidad por se√±al."""
    out = {"racha_actual": 0.0, "es_rebote": 0.0, "activo": "", "seg_payout": "", "seg_vol": "", "seg_hora": ""}
    try:
        row = leer_ultima_fila_features_para_pred(bot)
        if isinstance(row, dict):
            out["racha_actual"] = float(row.get("racha_actual", 0.0) or 0.0)
            out["es_rebote"] = float(row.get("es_rebote", 0.0) or 0.0)
            out["activo"] = str(row.get("activo", "") or "").strip()
            try:
                out["seg_payout"] = _bucket_tercil(float(row.get("payout", 0.0) or 0.0), 0.70, 0.82)
                out["seg_vol"] = _bucket_tercil(float(row.get("volatilidad", 0.0) or 0.0), 0.0008, 0.0018)
                out["seg_hora"] = _inferir_segmento_hora(float(row.get("hora_bucket", 0.0) or 0.0))
            except Exception:
                pass
            return out
    except Exception:
        pass

    # Fallback robusto: leer la √∫ltima fila del CSV enriquecido
    try:
        ruta = f"registro_enriquecido_{bot}.csv"
        if not os.path.exists(ruta):
            return out
        for enc in ("utf-8", "latin-1", "windows-1252"):
            try:
                df = pd.read_csv(ruta, encoding=enc, on_bad_lines="skip")
                if df is None or df.empty:
                    continue
                last = df.iloc[-1].to_dict()
                out["racha_actual"] = float(last.get("racha_actual", 0.0) or 0.0)
                out["es_rebote"] = float(last.get("es_rebote", 0.0) or 0.0)
                out["activo"] = str(last.get("activo", "") or "").strip()
                try:
                    out["seg_payout"] = _bucket_tercil(float(last.get("payout", 0.0) or 0.0), 0.70, 0.82)
                    out["seg_vol"] = _bucket_tercil(float(last.get("volatilidad", 0.0) or 0.0), 0.0008, 0.0018)
                    out["seg_hora"] = _inferir_segmento_hora(float(last.get("hora_bucket", 0.0) or 0.0))
                except Exception:
                    pass
                break
            except Exception:
                continue
    except Exception:
        pass
    return out



def _score_regimen_contexto(ctx: dict) -> float:
    """Capa A del embudo: score 0..1 de calidad de r√©gimen actual."""
    try:
        racha = float(ctx.get("racha_actual", 0.0) or 0.0)
        reb = float(ctx.get("es_rebote", 0.0) or 0.0)
        seg_p = str(ctx.get("seg_payout", "") or "")
        seg_h = str(ctx.get("seg_hora", "") or "")

        score = 0.50
        # racha positiva suma; racha muy negativa resta
        score += max(-0.18, min(0.18, 0.03 * racha))
        # rebote puede rescatar contextos negativos
        score += 0.08 if reb >= 0.5 else 0.0
        # payout bajo suele rendir peor
        if seg_p == "bajo":
            score -= 0.12
        elif seg_p == "alto":
            score += 0.04
        # franjas horarias menos estables -> leve castigo
        if seg_h in ("h00-05", "h18-23"):
            score -= 0.04

        return float(max(0.0, min(1.0, score)))
    except Exception:
        return 0.5


def _wilson_lower_bound(successes: int, n: int, z: float = 1.96) -> float:
    """L√≠mite inferior Wilson (conservador) para probabilidad real."""
    try:
        n = int(n or 0)
        successes = int(successes or 0)
        if n <= 0:
            return 0.0
        p = float(successes) / float(n)
        den = 1.0 + (z * z / n)
        cen = (p + (z * z / (2.0 * n))) / den
        mar = (z * math.sqrt((p * (1.0 - p) / n) + (z * z / (4.0 * n * n)))) / den
        return float(max(0.0, min(1.0, cen - mar)))
    except Exception:
        return 0.0


def _prob_real_posterior(prob_model: float, regime_score: float, ev_n: int, ev_wr: float, ev_lb: float) -> float:
    """Posterior operativa: modelo + evidencia + r√©gimen + bound conservador."""
    try:
        p = float(max(0.0, min(1.0, prob_model)))
        reg = float(max(0.0, min(1.0, regime_score)))
        n = int(max(0, ev_n or 0))
        wr = float(max(0.0, min(1.0, ev_wr or 0.0)))
        lb = float(max(0.0, min(1.0, ev_lb or 0.0)))

        # Peso de evidencia por tama√±o muestral (N/(N+K))
        w = float(n) / float(n + int(POSTERIOR_EVIDENCE_K)) if n >= 0 else 0.0

        # 1) Mezcla modelo-hist√≥rico real
        p_mix = ((1.0 - w) * p) + (w * wr)

        # 2) Ajuste por r√©gimen (score centrado en 0.5)
        reg_adj = 0.5 + ((reg - 0.5) * 0.8)
        p_reg = ((1.0 - float(POSTERIOR_REGIME_BLEND)) * p_mix) + (float(POSTERIOR_REGIME_BLEND) * reg_adj)

        # 3) Candado conservador: acercar a l√≠mite inferior cuando ya hay evidencia
        w_lb = min(0.45, w)
        p_post = ((1.0 - w_lb) * p_reg) + (w_lb * lb)

        return float(max(0.0, min(1.0, p_post)))
    except Exception:
        return float(max(0.0, min(1.0, prob_model or 0.0)))


def _evidencia_bot_umbral_objetivo(bot: str, force: bool = False) -> dict:
    """Resumen por bot en umbral objetivo (N, WR, Brier/ECE) para no inflar se√±ales."""
    try:
        now = time.time()
        cache = globals().setdefault("_EVIDENCE_BOT_CACHE", {})
        key = f"{bot}|{float(IA_CALIB_GOAL_THRESHOLD):.4f}"
        c = cache.get(key)
        if c and (not force) and ((now - float(c.get("ts", 0.0))) <= float(EVIDENCE_CACHE_TTL_S)):
            return c

        rep = auditar_calibracion_seniales_reales(min_prob=float(IA_CALIB_GOAL_THRESHOLD)) or {}
        por_bot = rep.get("por_bot", {}) if isinstance(rep, dict) else {}
        b = por_bot.get(str(bot), {}) if isinstance(por_bot, dict) else {}

        n = int(b.get("n", 0) or 0)
        wr = float(b.get("win_rate", 0.0) or 0.0) if n > 0 else 0.0
        hits = int(round(wr * n)) if n > 0 else 0
        lb = _wilson_lower_bound(hits, n) if n > 0 else 0.0
        brier = b.get("brier", None)
        ece = b.get("ece", None)
        ok_hard = (n < int(EVIDENCE_MIN_N_HARD)) or ((wr >= float(EVIDENCE_MIN_WR_HARD)) and (lb >= float(EVIDENCE_MIN_LB_HARD)))

        out = {
            "ts": now,
            "n": n,
            "wr": wr,
            "hits": int(hits),
            "lb": float(lb),
            "brier": brier,
            "ece": ece,
            "ok_hard": bool(ok_hard),
            "goal": float(IA_CALIB_GOAL_THRESHOLD),
        }
        cache[key] = out
        return out
    except Exception:
        return {"ts": time.time(), "n": 0, "hits": 0, "wr": 0.0, "lb": 0.0, "brier": None, "ece": None, "ok_hard": True, "goal": float(IA_CALIB_GOAL_THRESHOLD)}


def _gate_regimen_activo_ok(bot: str, activo: str = "", ttl_s: float = 45.0):
    """Valida r√©gimen por activo reciente (HZ10/HZ25/HZ50/HZ75) para no mezclar contextos."""
    try:
        now = time.time()
        key = f"{bot}|{activo or '*'}"
        c = _GATE_ACTIVO_CACHE.get(key)
        if c and (now - float(c.get("ts", 0.0))) <= float(ttl_s):
            return bool(c.get("ok", True)), float(c.get("wr", 0.5)), int(c.get("n", 0))

        ruta = f"registro_enriquecido_{bot}.csv"
        if not os.path.exists(ruta):
            return True, 0.5, 0

        df = None
        for enc in ("utf-8", "latin-1", "windows-1252"):
            try:
                df = pd.read_csv(ruta, encoding=enc, on_bad_lines="skip")
                break
            except Exception:
                continue
        if df is None or df.empty:
            return True, 0.5, 0

        if "trade_status" in df.columns:
            d = df[df["trade_status"].astype(str).str.upper().eq("CERRADO")].copy()
        else:
            d = df.copy()

        if "result_bin" not in d.columns:
            return True, 0.5, 0

        d["result_bin"] = pd.to_numeric(d["result_bin"], errors="coerce")
        d = d[d["result_bin"].isin([0, 1])]

        if activo and "activo" in d.columns:
            d = d[d["activo"].astype(str).eq(str(activo))]

        if int(GATE_ACTIVO_LOOKBACK) > 0 and len(d) > int(GATE_ACTIVO_LOOKBACK):
            d = d.tail(int(GATE_ACTIVO_LOOKBACK))

        n = int(len(d))
        wr = float(d["result_bin"].mean()) if n > 0 else 0.5
        ok = True
        if n >= int(GATE_ACTIVO_MIN_MUESTRA):
            ok = bool(wr >= float(GATE_ACTIVO_MIN_WR))

        _GATE_ACTIVO_CACHE[key] = {"ts": now, "ok": ok, "wr": wr, "n": n}
        return ok, wr, n
    except Exception:
        return True, 0.5, 0


def _leer_base_rate_y_n70(ttl_s: float = 30.0):
    """
    Lee m√©tricas r√°pidas desde ia_signals_log para estabilizar operaci√≥n:
    - base_rate rolling en cierres recientes (y en {0,1})
    - n70: cantidad de cierres con prob >= IA_CALIB_GOAL_THRESHOLD
    Cacheado para no cargar CSV en cada tick.
    """
    global _IA_RUNTIME_CAL_CACHE
    now = time.time()
    try:
        if (now - float(_IA_RUNTIME_CAL_CACHE.get("ts", 0.0))) <= float(ttl_s):
            return float(_IA_RUNTIME_CAL_CACHE.get("base_rate", 0.5)), int(_IA_RUNTIME_CAL_CACHE.get("n70", 0))

        _ensure_ia_signals_log()
        df = _safe_read_csv_any_encoding(IA_SIGNALS_LOG)
        base_rate = 0.5
        n70 = 0

        if df is not None and not df.empty and ("y" in df.columns):
            y = pd.to_numeric(df["y"], errors="coerce")
            mask_closed = y.isin([0, 1])
            d = df.loc[mask_closed].copy()
            if not d.empty:
                yv = pd.to_numeric(d["y"], errors="coerce")
                tail = yv.tail(int(max(20, IA_BASE_RATE_WINDOW)))
                if len(tail) > 0:
                    base_rate = float(tail.mean())

                if "prob" in d.columns:
                    pv = pd.to_numeric(d["prob"], errors="coerce")
                    n70 = int(((pv >= float(IA_CALIB_GOAL_THRESHOLD)) & yv.isin([0, 1])).sum())

        _IA_RUNTIME_CAL_CACHE = {"ts": now, "base_rate": float(base_rate), "n70": int(n70)}
        return float(base_rate), int(n70)
    except Exception:
        return 0.5, 0


_IA_ORIENTATION_CACHE = {"ts": 0.0, "invert": False, "auc": None, "auc_flip": None, "source": "none"}
_DIAG_RUNTIME_GATE_CACHE = {"ts": 0.0, "max_gap": 0.0, "n75": 0, "force_evidence": False}

def _leer_gate_desde_diagnostico(ttl_s: float = 60.0) -> dict:
    """Lee guardas operativas desde diagnostico_pipeline_ia.json."""
    global _DIAG_RUNTIME_GATE_CACHE
    now = time.time()
    try:
        if (now - float(_DIAG_RUNTIME_GATE_CACHE.get("ts", 0.0))) <= float(ttl_s):
            return dict(_DIAG_RUNTIME_GATE_CACHE)

        out = {"ts": now, "max_gap": 0.0, "n75": 0, "force_evidence": False}
        if os.path.exists(DIAG_PATH):
            with open(DIAG_PATH, "r", encoding="utf-8", errors="replace") as f:
                diag = json.load(f)
            sig = (diag or {}).get("signals", {}) if isinstance(diag, dict) else {}
            out["max_gap"] = float(sig.get("max_gap_abs_high_bins", 0.0) or 0.0)
            out["n75"] = int((sig.get("by_threshold", {}).get("0.75", {}) or {}).get("n", 0) or 0)
            out["force_evidence"] = (out["max_gap"] > float(HARD_GATE_MAX_GAP_HIGH_BINS)) or (out["n75"] < int(HARD_GATE_MIN_N_FOR_HIGH_THR))

        _DIAG_RUNTIME_GATE_CACHE = out
        return dict(out)
    except Exception:
        return {"ts": now, "max_gap": 0.0, "n75": 0, "force_evidence": False}


def _resolver_orientacion_runtime(ttl_s: float = ORIENTATION_RECHECK_S) -> dict:
    """
    Determina si conviene invertir p->1-p con evidencia cerrada (mismo set p vs 1-p).
    Regla conservadora: jam√°s invertir por heur√≠stica de model_meta con n bajo.
    """
    global _IA_ORIENTATION_CACHE
    now = time.time()
    try:
        if (now - float(_IA_ORIENTATION_CACHE.get("ts", 0.0))) <= float(ttl_s):
            return dict(_IA_ORIENTATION_CACHE)

        inv = False
        auc = None
        auc_flip = None
        source = "none"

        _ensure_ia_signals_log()
        df = _safe_read_csv_any_encoding(IA_SIGNALS_LOG)
        if df is not None and not df.empty and {"prob", "y"}.issubset(df.columns):
            y = pd.to_numeric(df["y"], errors="coerce")
            p = pd.to_numeric(df["prob"], errors="coerce")
            m = y.isin([0, 1]) & p.notna()
            yy = y[m].astype(int)
            pp = p[m].astype(float)
            n = int(len(yy))
            if n >= int(ORIENTATION_MIN_CLOSED) and len(set(yy.tolist())) >= 2:
                auc = float(roc_auc_score(yy, pp))
                auc_flip = float(roc_auc_score(yy, 1.0 - pp))
                if (auc_flip - auc) >= float(ORIENTATION_FLIP_MIN_DELTA):
                    inv = True
                source = "signals"

        _IA_ORIENTATION_CACHE = {"ts": now, "invert": bool(inv), "auc": auc, "auc_flip": auc_flip, "source": source}
        return dict(_IA_ORIENTATION_CACHE)
    except Exception:
        return {"ts": now, "invert": False, "auc": None, "auc_flip": None, "source": "error"}


def _aplicar_orientacion_prob(prob: float | None) -> float | None:
    try:
        if not isinstance(prob, (int, float)):
            return prob
        p = max(0.0, min(1.0, float(prob)))
        ori = _resolver_orientacion_runtime()
        if bool(ori.get("invert", False)):
            return float(max(0.0, min(1.0, 1.0 - p)))
        return p
    except Exception:
        return prob


def _ajustar_prob_operativa(prob: float | None) -> float | None:
    """
    Shrinkage anti-sobreconfianza: p_ajustada = a*p + (1-a)*tasa_base_rolling.
    Regla anti-aplastamiento:
      - En warmup o con pocas se√±ales cerradas, NO se aplica shrink para evitar
        colapsar todo alrededor de la tasa base (s√≠ntoma t√≠pico: 32.x% repetido).
    """
    try:
        if not isinstance(prob, (int, float)):
            return prob
        p = max(0.0, min(1.0, float(prob)))

        base_rate, n70 = _leer_base_rate_y_n70(ttl_s=30.0)

        # Si a√∫n no hay suficiente evidencia cerrada o el modelo sigue en warmup,
        # devolvemos p cruda calibrada (sin shrink).
        try:
            meta = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
            n_samples = int(meta.get("n_samples", meta.get("n", 0)) or 0)
            warmup = bool(meta.get("warmup_mode", n_samples < int(TRAIN_WARMUP_MIN_ROWS)))
        except Exception:
            n_samples = 0
            warmup = True

        if warmup or int(n70) < int(max(MIN_IA_SENIALES_CONF, 12)):
            return p

        # Alpha adaptativo por calibraci√≥n reciente:
        # - sube un poco cuando el modelo est√° estable y bien calibrado
        # - baja cuando hay inflaci√≥n fuerte (PredMedia >> Real)
        a = float(IA_SHRINK_ALPHA)
        try:
            rep = auditar_calibracion_seniales_reales(min_prob=float(IA_CALIB_THRESHOLD)) or {}
            n = int(rep.get("n", 0) or 0)
            infl_pp = float(rep.get("inflacion_pp", 0.0) or 0.0)
            pred_mean = float(rep.get("avg_pred", 0.0) or 0.0)
            win_rate = float(rep.get("win_rate", 0.0) or 0.0)

            if n < int(MIN_IA_SENIALES_CONF):
                a -= 0.10
            else:
                if infl_pp > float(SEM_CAL_INFL_WARN_PP) and pred_mean > win_rate:
                    a -= 0.12
                elif (abs(infl_pp) <= float(SEM_CAL_INFL_OK_PP)) and (n >= int(max(50, IA_CALIB_MIN_CLOSED // 2))):
                    a += 0.08
        except Exception:
            pass

        a = max(float(IA_SHRINK_ALPHA_MIN), min(float(IA_SHRINK_ALPHA_MAX), float(a)))
        p_adj = (a * p) + ((1.0 - a) * float(base_rate))
        return max(0.0, min(1.0, float(p_adj)))
    except Exception:
        return prob


def _ajustar_prob_por_evidencia_bot(bot: str, prob: float | None) -> float | None:
    """
    Ajuste leve por evidencia espec√≠fica del bot para mejorar discriminaci√≥n
    cuando el modelo queda plano entre varios bots.

    - Usa WR suavizado (Beta(1,1)) del bot (ganancias/p√©rdidas en memoria).
    - Si el input del bot fue marcado como redundante en el tick, reduce el efecto.
    - Ajuste acotado: m√°ximo ¬±2pp para no romper calibraci√≥n global.
    """
    try:
        if not isinstance(prob, (int, float)):
            return prob
        p = max(0.0, min(1.0, float(prob)))

        st = estado_bots.get(bot, {}) if isinstance(estado_bots, dict) else {}
        g = int(st.get("ganancias", 0) or 0)
        d = int(st.get("perdidas", 0) or 0)
        n = max(0, g + d)

        # WR suavizado para no sobre-reaccionar con n bajo.
        wr = float((g + 1.0) / (n + 2.0))
        edge = float(max(-0.20, min(0.20, wr - 0.50)))

        # Peso crece con muestra, saturando en n=120.
        w = min(1.0, float(n) / 120.0)
        delta = float(edge * w * 0.10)  # m√°x te√≥rico ¬±2pp

        # Si la entrada fue redundante este tick, hacemos el ajuste m√°s conservador.
        if bool(st.get("ia_input_redundante", False)):
            delta *= 0.35

        p2 = float(max(0.0, min(1.0, p + delta)))
        return p2
    except Exception:
        return prob


def _cap_prob_por_madurez(prob: float | None, bot: str | None = None) -> float | None:
    """
    Evita inflado irreal de Prob IA durante warmup (n bajo).
    Mientras el modelo no alcanza madurez, limita la probabilidad m√°xima
    con un techo progresivo entre IA_WARMUP_PROB_CAP_MIN y IA_WARMUP_PROB_CAP_MAX.
    """
    try:
        if not isinstance(prob, (int, float)):
            return prob
        p = max(0.0, min(1.0, float(prob)))

        meta = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
        n_samples = int(meta.get("n_samples", meta.get("n", 0)) or 0)
        warmup = bool(meta.get("warmup_mode", n_samples < int(TRAIN_WARMUP_MIN_ROWS)))
        if not warmup:
            return p

        ramp_rows = max(1, int(IA_WARMUP_CAP_RAMP_ROWS))
        ratio = max(0.0, min(1.0, float(n_samples) / float(ramp_rows)))
        cap = float(IA_WARMUP_PROB_CAP_MIN + (IA_WARMUP_PROB_CAP_MAX - IA_WARMUP_PROB_CAP_MIN) * ratio)

        # Si el bot a√∫n no tiene evidencia auditada m√≠nima, mantener cap m√°s conservador.
        if isinstance(bot, str) and bot:
            try:
                st = estado_bots.get(bot, {})
                cal_n = int(st.get("cal_n", 0) or 0)
                if cal_n < 20:
                    cap_low = float(IA_WARMUP_LOW_EVIDENCE_CAP_BASE)
                    if _todos_bots_con_n_minimo_real():
                        cap_low = max(cap_low, float(IA_WARMUP_LOW_EVIDENCE_CAP_POST_N15))
                    cap = min(cap, float(cap_low))
            except Exception:
                pass

        return float(min(p, cap))
    except Exception:
        return prob


def _ensure_ia_signals_log():
    """Crea el archivo con header si no existe."""
    if os.path.exists(IA_SIGNALS_LOG):
        return
    try:
        with open(IA_SIGNALS_LOG, "w", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow(["ts", "bot", "epoch", "prob", "thr", "modo", "y"])
            f.flush()
            os.fsync(f.fileno())
    except Exception:
        pass

def _leer_stats_canary_desde_log(ts_inicio: str | None) -> tuple[int, int]:
    """
    Devuelve (cerradas, ganadas) desde ia_signals_log.csv,
    opcionalmente filtrando por ts >= ts_inicio.
    """
    _ensure_ia_signals_log()
    dt_inicio = None
    try:
        if isinstance(ts_inicio, str) and ts_inicio.strip():
            dt_inicio = datetime.strptime(ts_inicio.strip(), "%Y-%m-%d %H:%M:%S")
    except Exception:
        dt_inicio = None

    cerradas = 0
    ganadas = 0
    try:
        with open(IA_SIGNALS_LOG, "r", newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for r in reader:
                yv = str(r.get("y", "")).strip()
                if yv not in ("0", "1"):
                    continue
                if dt_inicio is not None:
                    ts = str(r.get("ts", "")).strip()
                    try:
                        dt = datetime.strptime(ts, "%Y-%m-%d %H:%M:%S")
                    except Exception:
                        continue
                    if dt < dt_inicio:
                        continue
                cerradas += 1
                if yv == "1":
                    ganadas += 1
    except Exception:
        pass
    return int(cerradas), int(ganadas)


def resolver_canary_estado(meta: dict | None) -> dict:
    """
    Eval√∫a y resuelve canary autom√°ticamente cuando hay suficiente evidencia cerrada.
    - Si canary cumple target + hit-rate, promueve a champion_direct.
    - Si no cumple hit-rate, mantiene canary y ampl√≠a target (retry batch).
    """
    if not isinstance(meta, dict) or not bool(meta.get("canary_mode", False)):
        return meta if isinstance(meta, dict) else {}

    now = float(time.time())
    last_ts = float(CANARY_STATE_CACHE.get("ts", 0.0) or 0.0)
    cached_meta = CANARY_STATE_CACHE.get("meta")
    if (now - last_ts) < float(CANARY_EVAL_COOLDOWN_S) and isinstance(cached_meta, dict):
        return cached_meta

    out = dict(meta)
    ts_inicio = str(out.get("canary_started_at", "") or "").strip()
    target = int(out.get("canary_target_closed", CANARY_MIN_CLOSED_SIGNALS) or CANARY_MIN_CLOSED_SIGNALS)
    target = max(1, target)

    cerradas, ganadas = _leer_stats_canary_desde_log(ts_inicio)
    hit = (float(ganadas) / float(cerradas)) if cerradas > 0 else 0.0
    out["canary_closed_signals"] = int(cerradas)
    out["canary_hitrate"] = float(hit)

    changed = False
    if cerradas >= target:
        if hit >= float(CANARY_MIN_HITRATE):
            out["canary_mode"] = False
            out["refresh_policy"] = "champion_direct"
            out["reliable"] = bool(out.get("reliable_candidate", out.get("reliable", False)))
            out["canary_resolved_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            changed = True
            try:
                agregar_evento(f"‚úÖ IA CANARY resuelto: {ganadas}/{cerradas} ({hit*100:.1f}%). Se habilita champion_direct.")
            except Exception:
                pass
        else:
            out["canary_target_closed"] = int(cerradas + max(1, int(CANARY_RETRY_BATCH)))
            changed = True
            try:
                agregar_evento(
                    f"üü° IA CANARY extendido: hit-rate {hit*100:.1f}% ({ganadas}/{cerradas}) < {CANARY_MIN_HITRATE*100:.1f}%."
                )
            except Exception:
                pass

    if changed:
        try:
            if "guardar_model_meta" in globals() and callable(guardar_model_meta):
                guardar_model_meta(out)
        except Exception:
            pass

    CANARY_STATE_CACHE["ts"] = float(now)
    CANARY_STATE_CACHE["meta"] = dict(out)
    return out


def _atomic_write_text(path: str, text: str) -> bool:
    tmp = path + ".tmp"
    try:
        with open(tmp, "w", encoding="utf-8") as f:
            f.write(text)
            f.flush()
            os.fsync(f.fileno())
        os.replace(tmp, path)
        return True
    except Exception:
        try:
            if os.path.exists(tmp):
                os.remove(tmp)
        except Exception:
            pass
        return False

def _to_int_epoch(v) -> int | None:
    try:
        if v is None:
            return None
        if isinstance(v, str):
            v = v.strip()
            if v == "":
                return None
        x = float(v)
        if not math.isfinite(x):
            return None
        # epoch ms -> s
        if x > 1e12:
            x = x / 1000.0
        if x < 1e9:
            return None
        return int(x)
    except Exception:
        return None

def _tail_rows_dict(path: str, max_lines: int = 1200) -> list[dict]:
    """
    Lee SOLO el header + √∫ltimas N l√≠neas para no reventar rendimiento con CSV enormes.
    Devuelve lista de dicts (puede ser vac√≠a).
    """
    if not os.path.exists(path):
        return []
    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            from collections import deque as _dq
            with open(path, "r", encoding=enc, errors="replace", newline="") as f:
                header = f.readline()
                if not header:
                    return []
                dq = _dq(f, maxlen=int(max_lines))
            lines = [header] + list(dq)
            reader = csv.DictReader(lines)
            out = []
            for r in reader:
                if isinstance(r, dict) and r:
                    out.append(r)
            return out
        except Exception:
            continue
    return []

def ia_audit_get_last_pre_epoch(bot: str) -> int | None:
    """
    Intenta obtener epoch del √∫ltimo PRE_TRADE (incluye PENDING/OPEN/ABIERTO por normalizador).
    Si no existe trade_status, cae a la √∫ltima fila NO cierre.
    """
    ruta = f"registro_enriquecido_{bot}.csv"
    rows = _tail_rows_dict(ruta, max_lines=1400)
    if not rows:
        return None

    norm_fn = globals().get("normalizar_resultado", None)

    def _norm(x):
        try:
            if callable(norm_fn):
                return norm_fn(x)
        except Exception:
            pass
        s = str(x or "").upper()
        if "GAN" in s or "WIN" in s or "‚úì" in s:
            return "GANANCIA"
        if "PERD" in s or "LOSS" in s or "‚úó" in s:
            return "P√âRDIDA"
        return "INDEFINIDO"

    # ¬øExiste trade_status o trade_status_norm con contenido?
    def _has_key_nonempty(r, k):
        try:
            if k not in r:
                return False
            v = r.get(k, None)
            if v is None:
                return False
            return str(v).strip() != ""
        except Exception:
            return False

    has_ts = any((_has_key_nonempty(r, "trade_status") or _has_key_nonempty(r, "trade_status_norm")) for r in rows)

    # 1) Con trade_status: preferir PRE_TRADE real
    if has_ts:
        for r in reversed(rows):
            ts = normalizar_trade_status(r.get("trade_status_norm", None) or r.get("trade_status", None))
            if ts != "PRE_TRADE":
                continue

            # NO usar cierres como "pre"
            res = _norm(r.get("resultado", None))
            if res in ("GANANCIA", "P√âRDIDA"):
                continue

            ep = _to_int_epoch(r.get("epoch", None))
            if ep is not None:
                return ep

    # 2) Fallback: √∫ltima fila que NO sea cierre
    for r in reversed(rows):
        res = _norm(r.get("resultado", None))
        if res not in ("GANANCIA", "P√âRDIDA"):
            ep = _to_int_epoch(r.get("epoch", None))
            if ep is not None:
                return ep

    return None
def ia_audit_get_last_close(bot: str) -> tuple[int | None, int | None]:
    """
    Devuelve (epoch_close, y) donde y=1 GANANCIA, y=0 P√âRDIDA.
    Acepta CERRADO y tambi√©n CLOSED/SETTLED/etc. v√≠a normalizar_trade_status().
    """
    ruta = f"registro_enriquecido_{bot}.csv"
    rows = _tail_rows_dict(ruta, max_lines=1800)
    if not rows:
        return None, None

    norm_fn = globals().get("normalizar_resultado", None)
    def _norm(x):
        try:
            if callable(norm_fn):
                return norm_fn(x)
        except Exception:
            pass
        s = str(x or "").upper()
        if "GAN" in s or "WIN" in s or "‚úì" in s:
            return "GANANCIA"
        if "PERD" in s or "LOSS" in s or "‚úó" in s:
            return "P√âRDIDA"
        return "INDEFINIDO"

    has_ts = any(("trade_status" in r) or ("trade_status_norm" in r) for r in rows)

    for r in reversed(rows):
        res = _norm(r.get("resultado", None))
        if res not in ("GANANCIA", "P√âRDIDA"):
            continue

        if has_ts:
            ts_raw = r.get("trade_status_norm", None) or r.get("trade_status", None)
            ts = normalizar_trade_status(ts_raw)
            if ts and ts != "CERRADO":
                continue

        ep = _to_int_epoch(r.get("epoch", None))
        if ep is None:
            continue

        y = 1 if res == "GANANCIA" else 0
        return ep, y

    return None, None


def log_ia_open(bot: str, epoch: int, prob: float, thr: float, modo: str):
    """
    Registra una se√±al IA ABIERTA (y="") asociada al epoch PRE_TRADE.
    Blindaje: normaliza columna y para que quede SIEMPRE como "", "0" o "1" (no 0.0/1.0).
    Adem√°s, normaliza epoch para evitar duplicados por "123" vs "123.0".
    """
    try:
        _ensure_ia_signals_log()
        with IA_SIGNALS_LOCK:
            df = _safe_read_csv_any_encoding(IA_SIGNALS_LOG)
            if df is None or df.empty:
                df = pd.DataFrame(columns=["ts", "bot", "epoch", "prob", "thr", "modo", "y"])

            # Asegurar columnas base
            for c in ["ts", "bot", "epoch", "prob", "thr", "modo", "y"]:
                if c not in df.columns:
                    df[c] = ""

            def _norm_y(v):
                if v is None:
                    return ""
                s = str(v).strip()
                if s == "" or s.lower() == "nan":
                    return ""
                try:
                    return "1" if float(s) >= 0.5 else "0"
                except Exception:
                    su = s.upper()
                    if ("GAN" in su) or ("WIN" in su) or ("‚úì" in su):
                        return "1"
                    if ("PERD" in su) or ("P√âRD" in su) or ("LOSS" in su) or ("‚úó" in su):
                        return "0"
                    return ""

            df["y"] = df["y"].map(_norm_y)

            bot_s = _col_as_str_series(df, "bot").str.strip()
            y_s = _col_as_str_series(df, "y").str.strip()
            epoch_num = pd.to_numeric(_col_as_str_series(df, "epoch"), errors="coerce")

            # Evitar duplicado exacto (misma se√±al abierta)
            try:
                ep = float(int(epoch))
            except Exception:
                ep = None

            if ep is not None:
                m_same_open = (bot_s == str(bot)) & (epoch_num == ep) & (y_s == "")
                if m_same_open.any():
                    return False

            row = {
                "ts": f"{time.time():.6f}",
                "bot": str(bot),
                "epoch": str(int(epoch)),
                "prob": float(prob),
                "thr": float(thr),
                "modo": str(modo or ""),
                "y": ""
            }

            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
            _atomic_write_text(IA_SIGNALS_LOG, df.to_csv(index=False, lineterminator="\n"))
            return True
    except Exception:
        return False


def log_ia_close(
    bot: str,
    epoch: int,
    y: int,
    prob_override: float = None,
    thr_override: float = None,
    modo_override: str = None
):
    """
    Cierra la se√±al IA m√°s cercana (ABIERTA) para ese bot.
    Blindaje: reconoce cierres aunque el CSV tenga y como 0.0/1.0 o texto, y re-normaliza a "0"/"1".
    """
    try:
        _ensure_ia_signals_log()
        with IA_SIGNALS_LOCK:
            df = _safe_read_csv_any_encoding(IA_SIGNALS_LOG)
            if df is None or df.empty:
                return False

            for c in ["ts", "bot", "epoch", "prob", "thr", "modo", "y"]:
                if c not in df.columns:
                    df[c] = ""

            def _norm_y(v):
                if v is None:
                    return ""
                s = str(v).strip()
                if s == "" or s.lower() == "nan":
                    return ""
                try:
                    return "1" if float(s) >= 0.5 else "0"
                except Exception:
                    su = s.upper()
                    if ("GAN" in su) or ("WIN" in su) or ("‚úì" in su):
                        return "1"
                    if ("PERD" in su) or ("P√âRD" in su) or ("LOSS" in su) or ("‚úó" in su):
                        return "0"
                    return ""

            df["y"] = df["y"].map(_norm_y)

            bot_s = _col_as_str_series(df, "bot").str.strip()
            y_s = _col_as_str_series(df, "y").str.strip()
            epoch_num = pd.to_numeric(_col_as_str_series(df, "epoch"), errors="coerce")

            is_open = (y_s == "")
            yv = 1 if int(y) == 1 else 0
            close_n = int(epoch)

            # 1) Match exacto a se√±al abierta por epoch
            m_exact_open = (bot_s == str(bot)) & is_open & (epoch_num == float(close_n))
            if m_exact_open.any():
                for idx in df.index[m_exact_open]:
                    df.at[idx, "y"] = str(yv)
                    if prob_override is not None:
                        df.at[idx, "prob"] = float(prob_override)
                    if thr_override is not None:
                        df.at[idx, "thr"] = float(thr_override)
                    if modo_override is not None:
                        df.at[idx, "modo"] = str(modo_override)

                _atomic_write_text(IA_SIGNALS_LOG, df.to_csv(index=False, lineterminator="\n"))
                return True

            # 2) Si no hay exact match, cerrar la ABIERTA m√°s reciente con epoch <= epoch_close
            cand = df[(bot_s == str(bot)) & is_open].copy()
            if cand.empty:
                return False

            cand_epoch = pd.to_numeric(cand["epoch"], errors="coerce")
            cand = cand[cand_epoch.notna()].copy()
            cand["epoch_num"] = cand_epoch[cand_epoch.notna()].astype(float)

            cand = cand[cand["epoch_num"] <= float(close_n)]
            if cand.empty:
                return False

            pick_idx = cand["epoch_num"].idxmax()
            df.at[pick_idx, "y"] = str(yv)
            if prob_override is not None:
                df.at[pick_idx, "prob"] = float(prob_override)
            if thr_override is not None:
                df.at[pick_idx, "thr"] = float(thr_override)
            if modo_override is not None:
                df.at[pick_idx, "modo"] = str(modo_override)

            _atomic_write_text(IA_SIGNALS_LOG, df.to_csv(index=False, lineterminator="\n"))
            return True
    except Exception:
        return False

IA_AUDIT_LAST_CLOSE_EPOCH = {b: None for b in BOT_NAMES}

def ia_audit_scan_close(bot: str, tail_lines: int = 2000, max_events: int = 6):
    """
    Detecta CIERRES reales nuevos en registro_enriquecido_{bot}.csv y cierra se√±ales en ia_signals_log.csv.
    - Procesa hasta `max_events` cierres por tick para no sobrecargar.
    - Procesa en ORDEN ASCENDENTE para NO saltarse cierres antiguos (catch-up real).
    - Usa IA_AUDIT_LAST_CLOSE_EPOCH para avanzar incrementalmente.
    """
    try:
        last = IA_AUDIT_LAST_CLOSE_EPOCH.get(bot)
    except Exception:
        last = None

    ruta = f"registro_enriquecido_{bot}.csv"
    rows = _tail_rows_dict(ruta, max_lines=int(tail_lines))
    if not rows:
        return

    # ¬øExiste trade_status (raw o norm) en alguna fila?
    try:
        has_ts = any(("trade_status" in (r or {})) or ("trade_status_norm" in (r or {})) for r in rows)
    except Exception:
        has_ts = False

    # Recolectar cierres > last
    cierres = []
    seen = set()

    for r in rows:
        try:
            rr = (r or {})
            ep = None
            for k in ("epoch", "fecha", "timestamp", "ts"):
                ep = _to_int_epoch(rr.get(k))
                if ep is not None:
                    break
        except Exception:
            ep = None

        if ep is None:
            continue


        if last is not None:
            try:
                if int(ep) <= int(last):
                    continue
            except Exception:
                continue

        if has_ts:
            try:
                ts_raw = (r or {}).get("trade_status_norm") or (r or {}).get("trade_status")
                tsn = normalizar_trade_status(ts_raw)
                if tsn and tsn != "CERRADO":
                    continue
            except Exception:
                pass

        try:
            resn = normalizar_resultado((r or {}).get("resultado"))
        except Exception:
            resn = ""
        if resn not in ("GANANCIA", "P√âRDIDA"):
            continue

        y = 1 if resn == "GANANCIA" else 0

        # Dedup por epoch en este tick (nos quedamos con el √∫ltimo y del epoch)
        if int(ep) in seen:
            for i in range(len(cierres) - 1, -1, -1):
                if cierres[i][0] == int(ep):
                    cierres[i] = (int(ep), int(y))
                    break
        else:
            cierres.append((int(ep), int(y)))
            seen.add(int(ep))

    if not cierres:
        return

    cierres.sort(key=lambda t: t[0])  # ASC

    # Limitar: tomamos LOS PRIMEROS para catch-up real (no saltar viejos)
    if max_events and len(cierres) > int(max_events):
        cierres = cierres[:int(max_events)]

    for ep, y in cierres:
        try:
            _ = bool(log_ia_close(bot, ep, y))
        except Exception:
            pass
        # Avanzamos el puntero siempre: si no hab√≠a se√±al abierta (trade sin se√±al IA), no queremos trabarnos.
        IA_AUDIT_LAST_CLOSE_EPOCH[bot] = int(ep)

def semaforo_calibracion(n: int, infl_pp: float | None):
    """Devuelve (emoji, etiqueta, detalle) para lectura r√°pida de calibraci√≥n."""
    try:
        n = int(n or 0)
    except Exception:
        n = 0

    try:
        infl = abs(float(infl_pp)) if infl_pp is not None else None
    except Exception:
        infl = None

    if n < SEM_CAL_N_ROJO:
        return "üî¥", "CR√çTICO", f"n={n}<{SEM_CAL_N_ROJO}"

    if infl is None:
        if n < SEM_CAL_N_AMARILLO:
            return "üü°", "PRECAUCI√ìN", f"n={n}<{SEM_CAL_N_AMARILLO}"
        return "üü¢", "CONFIABLE", f"n={n} (sin inflaci√≥n calculable)"

    if infl > SEM_CAL_INFL_WARN_PP:
        return "üî¥", "CR√çTICO", f"|infl|={infl:.1f}pp>{SEM_CAL_INFL_WARN_PP:.0f}pp"

    if (n < SEM_CAL_N_AMARILLO) or (infl > SEM_CAL_INFL_OK_PP):
        return "üü°", "PRECAUCI√ìN", f"n={n}, |infl|={infl:.1f}pp"

    return "üü¢", "CONFIABLE", f"n={n}, |infl|={infl:.1f}pp"

def diagnostico_calibracion(n: int, pred_mean: float, win_rate: float, infl_pp: float | None):
    """Mensaje corto para saber si la calibraci√≥n va por buen camino."""
    try:
        n = int(n or 0)
    except Exception:
        n = 0

    try:
        infl_abs = abs(float(infl_pp)) if infl_pp is not None else None
    except Exception:
        infl_abs = None

    if n < SEM_CAL_N_ROJO:
        return "Todav√≠a no se puede concluir (muestra muy chica): sigue juntando cierres reales."

    if infl_abs is None:
        return "Hay cierres, pero a√∫n no alcanza para medir la brecha Pred vs Real con confianza."

    if infl_abs <= SEM_CAL_INFL_OK_PP:
        return "Vas por buen camino: la probabilidad predicha est√° cerca del resultado real."

    if infl_abs <= SEM_CAL_INFL_WARN_PP:
        sesgo = "sobreestima" if pred_mean >= win_rate else "subestima"
        return f"Hay avance, pero la IA a√∫n {sesgo} el resultado real; conviene m√°s muestra."

    sesgo = "sobreestimando" if pred_mean >= win_rate else "subestimando"
    return f"Se detecta descalibraci√≥n fuerte ({sesgo}); no usar la probabilidad sola para decidir."

def auditar_calibracion_seniales_reales(min_prob: float = 0.70, max_rows: int = 20000, n_bins: int = 10):
    """
    Auditor√≠a REAL vs PRED (se√±ales cerradas en ia_signals_log.csv).

    Devuelve:
      - n
      - win_rate (real)
      - avg_pred (promedio de prob del modelo)
      - inflacion_pp = (avg_pred - win_rate)*100
      - factor = win_rate/avg_pred (clamp) si hay data suficiente
      - brier = mean((prob - y)^2)
      - ece = Expected Calibration Error (bins 0..1)
      - por_bot: m√©tricas por bot
    """
    try:
        _ensure_ia_signals_log()
        df = _safe_read_csv_any_encoding(IA_SIGNALS_LOG)
        if df is None or df.empty:
            return None

        if ("prob" not in df.columns) or ("y" not in df.columns) or ("bot" not in df.columns):
            return None

        d = df.copy()

        # y debe ser 0/1 para considerar "cerrada"
        # (soporta 0/1, 0.0/1.0, "0"/"1", y texto tipo GANANCIA/P√âRDIDA/‚úì/‚úó)
        y_raw = d["y"]

        y_num = pd.to_numeric(y_raw, errors="coerce")
        y_txt = y_raw.astype(str).str.strip().str.upper()

        # Fallback por texto si no pudo convertirse a n√∫mero
        y_num = y_num.where(
            ~y_num.isna(),
            np.where(
                y_txt.str.contains(r"GAN|WIN|‚úì"),
                1.0,
                np.where(y_txt.str.contains(r"PERD|P√âRD|LOSS|‚úó"), 0.0, np.nan)
            )
        )

        # Normalizar a 0/1 (todo lo >=0.5 se considera 1)
        d["y"] = np.where(pd.isna(y_num), np.nan, np.where(y_num >= 0.5, 1, 0))
        d = d[d["y"].isin([0, 1])].copy()
        if d.empty:
            return None

        # prob num√©rica (defensivo)
        d["prob"] = pd.to_numeric(d["prob"], errors="coerce").fillna(0.0).clip(0.0, 1.0)
        d["y"] = d["y"].astype(int)

        n_total_closed = int(len(d))

        # filtro por umbral
        d = d[d["prob"] >= float(min_prob)].copy()
        if d.empty:
            return {
                "n": 0,
                "n_total_closed": n_total_closed,
                "n_after_threshold": 0,
                "min_prob": float(min_prob),
                "win_rate": None,
                "avg_pred": None,
                "inflacion_pp": None,
                "factor": 1.0,
                "brier": None,
                "ece": None,
                "por_bot": {},
            }

        # limitar tama√±o para no castigar IO/cpu
        try:
            if max_rows and len(d) > int(max_rows):
                d = d.iloc[-int(max_rows):].copy()
        except Exception:
            pass

        y = d["y"].to_numpy(dtype=float)
        p = d["prob"].to_numpy(dtype=float)

        def _ece(_y, _p, bins: int = 10) -> float:
            _y = np.asarray(_y, dtype=float)
            _p = np.asarray(_p, dtype=float)
            if _p.size == 0:
                return 0.0
            edges = np.linspace(0.0, 1.0, int(bins) + 1)
            ece = 0.0
            n = float(_p.size)
            for i in range(len(edges) - 1):
                lo, hi = edges[i], edges[i + 1]
                if i < len(edges) - 2:
                    m = (_p >= lo) & (_p < hi)
                else:
                    m = (_p >= lo) & (_p <= hi)
                cnt = int(m.sum())
                if cnt <= 0:
                    continue
                avg_p = float(_p[m].mean())
                avg_y = float(_y[m].mean())
                ece += abs(avg_p - avg_y) * (cnt / n)
            return float(ece)

        win_rate = float(np.mean(y))
        avg_pred = float(np.mean(p))
        infl_pp = (avg_pred - win_rate) * 100.0

        factor = 1.0
        if avg_pred > 1e-6 and len(d) >= 30:
            factor = win_rate / avg_pred
            factor = max(0.60, min(1.30, factor))  # clamp defensivo

        brier = float(np.mean((p - y) ** 2))
        ece = _ece(y, p, bins=n_bins)

        por_bot = {}
        try:
            for b, g in d.groupby("bot"):
                n = int(len(g))
                yb = g["y"].to_numpy(dtype=float)
                pb = g["prob"].to_numpy(dtype=float)

                wr = float(np.mean(yb)) if n else None
                ap = float(np.mean(pb)) if n else None
                inf = ((ap - wr) * 100.0) if (wr is not None and ap is not None) else None

                fb = 1.0
                if ap and ap > 1e-6 and n >= 20:
                    fb = wr / ap
                    fb = max(0.60, min(1.30, fb))

                por_bot[str(b)] = {
                    "n": n,
                    "win_rate": wr,
                    "avg_pred": ap,
                    "inflacion_pp": inf,
                    "factor": fb,
                    "brier": float(np.mean((pb - yb) ** 2)) if n else None,
                    "ece": _ece(yb, pb, bins=n_bins) if n else None,
                }
        except Exception:
            por_bot = {}

        stable_sample = bool(len(d) >= int(IA_CALIB_MIN_CLOSED))

        return {
            "n": int(len(d)),
            "n_total_closed": n_total_closed,
            "n_after_threshold": int(len(d)),
            "min_prob": float(min_prob),
            "win_rate": win_rate,
            "avg_pred": avg_pred,
            "inflacion_pp": infl_pp,
            "factor": factor,
            "brier": brier,
            "ece": ece,
            "stable_sample": stable_sample,
            "min_recommended_n": int(IA_CALIB_MIN_CLOSED),
            "por_bot": por_bot,
        }
    except Exception:
        return None

# === FIN BLOQUE 10A ===
# ==========================================================
        
# ==========================================================
# ‚úÖ HOTFIX IA: Prob IA REAL (no forzar a 0 si no hay se√±al)
# - Predice sobre la √∫ltima fila PRE_TRADE/PENDIENTE si existe
# - Si no existe, cae a la √∫ltima fila ‚Äúno cierre‚Äù antes del √∫ltimo cierre
# - Alinea features con features.pkl (si existe) o FEATURE_NAMES_DEFAULT
# - Si falla, deja ia_ready=False y ia_last_err con el motivo
# ==========================================================

_IA_ASSETS_CACHE = {"loaded": False, "model": None, "scaler": None, "features": None, "meta": None}

def _find_first_pickle(regex_list, exts=(".pkl", ".joblib")):
    try:
        files = os.listdir(".")
        for fn in files:
            low = fn.lower()
            if not low.endswith(exts):
                continue
            for rx in regex_list:
                try:
                    if re.search(rx, low):
                        return fn
                except Exception:
                    continue
    except Exception:
        pass
    return None

def _load_ia_assets_once(force: bool = False):
    """
    Carga assets desde globals si existen; si no, autodetecta en disco.
    IMPORTANTE: si al arrancar no hab√≠a modelo/scaler y luego aparecen (por entrenamiento),
    con force=True se recarga y no se queda ‚Äúpegado‚Äù.
    """
    # Si ya se carg√≥ y no pedimos fuerza, salimos
    if _IA_ASSETS_CACHE.get("loaded", False) and (not force):
        return

    g = globals()

    # 1) Preferir objetos en memoria (despu√©s de entrenar)
    model  = g.get("modelo_ia") or g.get("IA_MODELO") or g.get("modelo_oracle") or g.get("oracle_model") or None
    scaler = g.get("scaler_ia") or g.get("IA_SCALER") or g.get("oracle_scaler") or None
    feats  = g.get("feature_names_ia") or g.get("FEATURE_NAMES_USADAS") or g.get("FEATURE_NAMES_MODEL") or None
    meta   = g.get("meta_ia") or g.get("IA_META") or g.get("oracle_meta") or None

    # 2) Fallback: disco (tus ‚Äú4 artefactos‚Äù)
    if model is None:
        mfile = globals().get("_MODEL_PATH", "modelo_xgb.pkl")
        if not os.path.exists(mfile):
            mfile = _find_first_pickle([r"modelo", r"model", r"xgb"])
        if mfile:
            try:
                model = joblib.load(mfile)
            except Exception:
                model = None

    if scaler is None:
        sfile = globals().get("_SCALER_PATH", "scaler.pkl")
        if not os.path.exists(sfile):
            sfile = _find_first_pickle([r"scaler"])
        if sfile:
            try:
                scaler = joblib.load(sfile)
            except Exception:
                scaler = None

    if feats is None:
        ffile = globals().get("_FEATURES_PATH", "feature_names.pkl")
        if not os.path.exists(ffile):
            ffile = _find_first_pickle([r"features", r"feature_names"])
        if ffile:
            try:
                feats = joblib.load(ffile)
            except Exception:
                feats = None

    if meta is None:
        metafile = _find_first_pickle([r"meta"])
        if metafile:
            try:
                meta = joblib.load(metafile)
            except Exception:
                meta = None

    _IA_ASSETS_CACHE.update({
        "loaded": True,
        "model": model,
        "scaler": scaler,
        "features": feats,
        "meta": meta
    })

def _features_model_list():
    _load_ia_assets_once()
    feats = _IA_ASSETS_CACHE.get("features")
    # features.pkl puede venir como list o dict
    if isinstance(feats, list) and feats:
        return list(feats)
    if isinstance(feats, dict) and feats.get("features"):
        try:
            return list(feats["features"])
        except Exception:
            pass
    # fallback can√≥nico
    return list(FEATURE_NAMES_DEFAULT)

def _add_derived_for_model(d: dict):
    """Si el modelo espera features derivadas, cr√©alas aqu√≠."""
    try:
        racha = float(d.get("racha_actual", 0.0) or 0.0)
    except Exception:
        racha = 0.0

    d["racha_signo"] = 1.0 if racha > 0 else (-1.0 if racha < 0 else 0.0)
    d["racha_abs"] = abs(racha)
    d["rebote_fuerte"] = 1.0 if abs(racha) >= 6 else 0.0

    # Interacciones (si no existen, se arman igual)
    try:
        payout = float(d.get("payout", 0.0) or 0.0)
    except Exception:
        payout = 0.0
    try:
        pe = float(d.get("puntaje_estrategia", 0.0) or 0.0)
    except Exception:
        pe = 0.0
    try:
        vol = float(d.get("volatilidad", 0.0) or 0.0)
    except Exception:
        vol = 0.0
    try:
        brk = float(d.get("breakout", 0.0) or 0.0)
    except Exception:
        brk = 0.0
    try:
        hb = float(d.get("hora_bucket", 0.0) or 0.0)
    except Exception:
        hb = 0.0
    try:
        er = float(d.get("es_rebote", 0.0) or 0.0)
    except Exception:
        er = 0.0

    d["pay_x_puntaje"] = payout * pe
    d["vol_x_breakout"] = vol * brk
    d["hora_x_rebote"] = hb * er
    d["racha_x_rebote"] = racha * er
    try:
        rsi_rev = float(d.get("rsi_reversion", 0.0) or 0.0)
    except Exception:
        rsi_rev = 0.0
    d["rev_x_breakout"] = rsi_rev * brk

    return d

def leer_ultima_fila_features_para_pred(bot: str) -> dict | None:
    """
    Lee features para PREDICCI√ìN (sin label):
    - Prefiere trade_status PRE_TRADE/PENDIENTE/OPEN/ABIERTO
    - Fallback: √∫ltima fila ‚Äúno cierre‚Äù antes del √∫ltimo cierre
    - Anti-leakage: elimina campos de cierre (ganancia/profit/resultado) del dict final
    """
    ruta = f"registro_enriquecido_{bot}.csv"
    if not os.path.exists(ruta):
        return None

    df = None
    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            df = pd.read_csv(ruta, sep=",", encoding=enc, engine="python", on_bad_lines="skip")
            break
        except Exception:
            continue
    if df is None or df.empty:
        return None

    # Normalizar resultado si existe
    if "resultado" in df.columns:
        df["resultado_norm"] = df["resultado"].apply(normalizar_resultado)
    else:
        df["resultado_norm"] = "INDEFINIDO"

    # Normalizar trade_status de forma can√≥nica (evita CLOSED/SETTLED vs CERRADO)
    has_trade_status = (("trade_status" in df.columns) or ("trade_status_norm" in df.columns))

    if has_trade_status:
        if "trade_status_norm" in df.columns:
            df["trade_status_norm"] = df["trade_status_norm"].apply(normalizar_trade_status)
        else:
            df["trade_status_norm"] = df["trade_status"].apply(normalizar_trade_status)
    else:
        df["trade_status_norm"] = ""

    # 1) preferir PRE_TRADE/PENDIENTE
    pre = None
    pre_idx = None
    if has_trade_status:
        df_pre = df[df["trade_status_norm"].isin(["PENDIENTE", "PRE_TRADE", "OPEN", "ABIERTO"])].copy()
        # evitar ‚Äúfilas basura‚Äù: no usar cierres
        if "resultado_norm" in df_pre.columns:
            df_pre = df_pre[~df_pre["resultado_norm"].isin(["GANANCIA", "P√âRDIDA"])].copy()
        if not df_pre.empty:
            pre_idx = int(df_pre.index[-1])
            pre = df_pre.iloc[-1].to_dict()

    # 2) fallback: tomar √∫ltima fila antes del √∫ltimo cierre que no sea cierre
    if pre is None:
        df_cerr = df[df["resultado_norm"].isin(["GANANCIA", "P√âRDIDA"])].copy()
        if has_trade_status:
            df_cerr = df_cerr[df_cerr["trade_status_norm"].eq("CERRADO")].copy()
        if not df_cerr.empty:
            idx_close = df_cerr.index[-1]
            try:
                df_before = df.loc[df.index <= idx_close].copy()
            except Exception:
                df_before = df.copy()
        else:
            df_before = df.copy()

        cand = df_before[~df_before["resultado_norm"].isin(["GANANCIA", "P√âRDIDA"])].copy()
        if not cand.empty:
            pre_idx = int(cand.index[-1])
            pre = cand.iloc[-1].to_dict()
        else:
            pre_idx = int(df_before.index[-1])
            pre = df_before.iloc[-1].to_dict()

    if pre is None:
        return None

    row = dict(pre)

    # Se√±ales evento desde historial (sin futuro) para evitar cruce/breakout pegados.
    try:
        if pre_idx is None:
            pre_idx = int(df.index[-1])
        row = _calcular_eventos_pretrade_desde_historial(df, int(pre_idx), row_base=row)
    except Exception:
        pass

    # Meta trazable del origen (diagn√≥stico anti-clonado por bot/tick)
    try:
        row["__src_path"] = str(ruta)
        row["__src_epoch"] = row.get("epoch", None)
        row["__src_ts"] = row.get("ts", row.get("timestamp", row.get("fecha", None)))
        row["__src_symbol"] = row.get("symbol", row.get("activo", row.get("market", row.get("underlying", ""))))
    except Exception:
        pass

    # üîí Anti-leakage duro
    for k in ("ganancia_perdida", "profit", "resultado", "resultado_norm"):
        try:
            row.pop(k, None)
        except Exception:
            pass

    # Completar y normalizar base 13 features como haces en leer_ultima_fila_con_resultado
    # payout feature (ROI 0..1.5)
    try:
        roi = calcular_payout_feature(row)
    except Exception:
        roi = None
    if roi is None:
        return None
    row["payout"] = float(max(0.0, min(float(roi), 1.5)))

    # volatilidad / hora_bucket / es_rebote / puntaje_estrategia
    try:
        vol = _safe_float(row.get("volatilidad"))
        if vol is None:
            vol = calcular_volatilidad_simple(row)
        try:
            volf = float(vol)
        except Exception:
            volf = float("nan")
        if (not math.isfinite(volf)) or volf <= 0.0:
            vol_hist = calcular_volatilidad_por_bot(bot, lookback=50)
            if vol_hist is not None:
                volf = float(vol_hist)
        if (not math.isfinite(volf)):
            return None
        row["volatilidad"] = float(max(0.0, min(float(volf), 1.0)))
    except Exception:
        return None

    try:
        hb = _safe_float(row.get("hora_bucket"))
        if hb is None:
            hb, hm = calcular_hora_features(row)
            row["hora_missing"] = float(hm)
        row["hora_bucket"] = float(max(0.0, min(float(hb), 1.0)))
    except Exception:
        return None

    # enriquecer se√±ales evento (incluye es_rebote / cruce / breakout / rsi_reversion / puntaje)
    try:
        row = enriquecer_features_evento(row)
    except Exception:
        pass

    try:
        er = _safe_float(row.get("es_rebote"))
        if er is None:
            er = calcular_es_rebote(row)
        row["es_rebote"] = float(max(0.0, min(float(er), 1.0)))
    except Exception:
        return None

    try:
        pe = calcular_puntaje_estrategia_normalizado(row)
        row["puntaje_estrategia"] = float(max(0.0, min(float(pe), 1.0)))
    except Exception:
        # fallback a lo que exista
        pe_raw = _safe_float(row.get("puntaje_estrategia"))
        if pe_raw is None:
            return None
        row["puntaje_estrategia"] = float(max(0.0, min(float(pe_raw), 1.0)))

    # Derived extras (por si el modelo los espera)
    row = _add_derived_for_model(row)

    # Clip defensivo si existe tu helper
    try:
        # usa el set esperado por el modelo (solo recorta lo que exista)
        fnames = _features_model_list()
        row = clip_feature_values(row, fnames)
    except Exception:
        pass

    # Huella de fila para trazabilidad de lectura por bot
    try:
        core = ["rsi_9", "rsi_14", "sma_5", "sma_spread", "payout", "volatilidad", "hora_bucket"]
        parts = []
        for k in core:
            vv = row.get(k, None)
            try:
                vv = float(vv)
                if not math.isfinite(vv):
                    vv = 0.0
            except Exception:
                vv = 0.0
            parts.append(f"{k}={round(vv, 6)}")
        row["__src_row_hash"] = hashlib.sha1("|".join(parts).encode("utf-8", errors="ignore")).hexdigest()[:12]
    except Exception:
        row["__src_row_hash"] = ""

    return row

def _coerce_float_default(v, default=0.0) -> float:
    try:
        if v is None:
            return float(default)
        if isinstance(v, str):
            v = v.strip()
            if v == "":
                return float(default)
        x = float(v)
        if not np.isfinite(x):
            return float(default)
        return float(x)
    except Exception:
        return float(default)

def _predict_prob_low_data_from_row(row: dict) -> float:
    """Heur√≠stica estable para mostrar Prob IA en LOW_DATA cuando no hay modelo."""
    try:
        racha = float(row.get("racha_actual", 0.0) or 0.0)
    except Exception:
        racha = 0.0
    try:
        rsi9 = float(row.get("rsi_9", 50.0) or 50.0)
    except Exception:
        rsi9 = 50.0
    try:
        rev = float(row.get("rsi_reversion", 0.0) or 0.0)
    except Exception:
        rev = 0.0
    try:
        vol = float(row.get("volatilidad", 0.5) or 0.5)
    except Exception:
        vol = 0.5

    score = 0.50
    score += max(-0.08, min(0.10, 0.018 * racha))
    score += 0.06 if rev >= 0.5 else 0.0
    score += 0.04 if rsi9 <= 30 else (-0.03 if rsi9 >= 70 else 0.0)
    score += 0.02 if vol <= 0.35 else (-0.02 if vol >= 0.8 else 0.0)
    return float(max(0.20, min(0.80, score)))


def predecir_prob_ia_bot(bot: str) -> tuple[float | None, str | None]:
    """
    Retorna (prob, err). prob en 0..1.
    NO devuelve 0 "por defecto": si falla, devuelve (None, CODIGO_ERROR).
    """
    try:
        # 1) Cargar assets (y recargar si aparecieron luego del boot)
        _load_ia_assets_once()
        model = _IA_ASSETS_CACHE.get("model")
        scaler = _IA_ASSETS_CACHE.get("scaler")

        if model is None:
            _load_ia_assets_once(force=True)
            model = _IA_ASSETS_CACHE.get("model")
            scaler = _IA_ASSETS_CACHE.get("scaler")

        # 2) Leer fila de features para pred (sin label)
        row = leer_ultima_fila_features_para_pred(bot)
        if row is None:
            return None, "NO_FEATURE_ROW"

        if model is None:
            # Modo LOW_DATA: a√∫n sin modelo, pero entrega prob heur√≠stica para no quedar en OFF.
            try:
                global _IA_NO_MODEL_LOG_TS
                now_nm = time.time()
                if (now_nm - float(_IA_NO_MODEL_LOG_TS or 0.0)) >= float(IA_NO_MODEL_LOG_COOLDOWN_S):
                    _IA_NO_MODEL_LOG_TS = now_nm
                    agregar_evento("‚ÑπÔ∏è IA LOW_DATA activa: a√∫n sin modelo; mostrando prob heur√≠stica temporal.")
            except Exception:
                pass
            p0 = _predict_prob_low_data_from_row(row)
            return float(p0), "LOW_DATA"

        # 3) Lista de features esperadas por el modelo (features.pkl si existe)
        feats = _features_model_list()
        if not feats:
            return None, "NO_FEATS"

        # 4) Armar X con orden exacto + detectar faltantes reales (evitar vector plano silencioso)
        values = []
        missing_feats = []
        present_feats = 0
        for k in feats:
            v = row.get(k, None)
            is_missing = False
            if v is None:
                is_missing = True
            else:
                try:
                    if isinstance(v, float) and np.isnan(v):
                        is_missing = True
                except Exception:
                    pass
                if isinstance(v, str) and v.strip() in ("", "--", "None", "nan", "NaN"):
                    is_missing = True

            if is_missing:
                missing_feats.append(k)
            else:
                present_feats += 1

            values.append(_coerce_float_default(v, default=0.0))

        total_feats = max(1, len(feats))
        present_ratio = float(present_feats) / float(total_feats)

        # Guardar snapshot t√©cnico por bot para depuraci√≥n de pipeline
        try:
            estado_bots[bot]["ia_debug_src_path"] = str(row.get("__src_path", ""))
            estado_bots[bot]["ia_debug_src_epoch"] = str(row.get("__src_epoch", ""))
            estado_bots[bot]["ia_debug_src_ts"] = str(row.get("__src_ts", ""))
            estado_bots[bot]["ia_debug_row_hash"] = str(row.get("__src_row_hash", ""))
            estado_bots[bot]["ia_debug_missing_feats"] = int(len(missing_feats))
            estado_bots[bot]["ia_debug_present_ratio"] = float(present_ratio)
        except Exception:
            pass

        # Si faltan demasiadas features esperadas, no inventar probabilidad.
        if present_ratio < 0.60:
            return None, f"FEAT_MISMATCH:{present_feats}/{total_feats}"

        X = pd.DataFrame([values], columns=list(feats))

        # 5) Escalado (si existe)
        X_in = X
        if scaler is not None:
            try:
                # Si el scaler fue fit con nombres, intentamos alinear
                if hasattr(scaler, "feature_names_in_") and scaler.feature_names_in_ is not None:
                    need = list(scaler.feature_names_in_)
                    # reindexa (si falta algo -> 0.0)
                    X_in = X.reindex(columns=need, fill_value=0.0)
                else:
                    X_in = X

                # StandardScaler no acepta NaN: blindaje final
                X_in = X_in.replace([np.inf, -np.inf], 0.0).fillna(0.0)

                X_scaled = scaler.transform(X_in)
            except Exception as e:
                return None, f"SCALER_FAIL:{type(e).__name__}"

        else:
            # sin scaler, usamos valores crudos
            X_scaled = X_in.replace([np.inf, -np.inf], 0.0).fillna(0.0).values

        # 6) Predict proba
        try:
            proba = model.predict_proba(X_scaled)
            p = _extraer_probabilidad_clase_positiva(model, proba, default_idx=1)
            if p is None:
                return None, "PRED_FAIL:BAD_PROBA"
        except Exception as e:
            return None, f"PRED_FAIL:{type(e).__name__}"

        if not np.isfinite(p):
            return None, "PROB_NAN"

        # clamp
        p = max(0.0, min(1.0, p))
        try:
            estado_bots[bot]["ia_prob_raw_model"] = float(p)
        except Exception:
            pass
        return p, None

    except Exception as e:
        return None, f"IA_ERR:{type(e).__name__}"

def _extraer_probabilidad_clase_positiva(model, proba_arr, default_idx: int = 1) -> float | None:
    """Extrae P(y=1) respetando model.classes_ cuando exista."""
    try:
        arr = np.asarray(proba_arr, dtype=float)
        if arr.ndim == 1:
            arr = arr.reshape(1, -1)
        if arr.ndim != 2 or arr.shape[0] < 1 or arr.shape[1] < 1:
            return None

        idx = int(default_idx)
        try:
            classes = list(getattr(model, "classes_", []) or [])
            if classes:
                # Forzamos b√∫squeda de etiqueta positiva 1 (ganancia)
                if 1 in classes:
                    idx = int(classes.index(1))
                elif "1" in classes:
                    idx = int(classes.index("1"))
        except Exception:
            pass

        idx = max(0, min(int(idx), int(arr.shape[1]) - 1))
        p = float(arr[0][idx])
        if not np.isfinite(p):
            return None
        return float(max(0.0, min(1.0, p)))
    except Exception:
        return None


# --- Updater: NO fuerces prob_ia=0 cuando falla ---
IA_PRED_TTL_S = 180.0          # si falla por mucho tiempo, reci√©n se limpia a None
IA_PRED_MIN_INTERVAL_S = 2.0   # anti-spam de predicci√≥n
_last_pred_ts = {b: 0.0 for b in BOT_NAMES}
_IA_CLONED_PROB_TICKS = 0
_IA_INPUT_DUP_INFO = {"signature": "", "ts": 0.0, "bots": []}
_LAST_AUTO_RETRAIN_TICK = 0.0
_IA_TRAIN_CLEAN_LOG = {"ts": 0.0, "sig": ""}
_IA_NO_MODEL_LOG_TS = 0.0
_IA_TIEBREAK_LOG_TS = 0.0

def actualizar_prob_ia_bot(bot: str):
    """
    Actualiza estado_bots[bot]['prob_ia'] de forma segura:
    - Si hay prob v√°lida: la escribe, define modo_ia y marca ia_ready=True.
    - Si falla: NO pisa prob_ia a 0. Conserva √∫ltimo valor por TTL para no vaciar el HUD.
    """
    try:
        now = time.time()
        last = float(_last_pred_ts.get(bot, 0.0) or 0.0)
        if (now - last) < IA_PRED_MIN_INTERVAL_S:
            return
        _last_pred_ts[bot] = now

        # Guardrail duro: solo invalidar cuando se detecta CLON REAL de origen en este tick.
        if bool(estado_bots.get(bot, {}).get("ia_input_duplicado", False)):
            estado_bots[bot]["ia_ready"] = False
            estado_bots[bot]["ia_last_err"] = "INPUT_DUPLICADO"
            estado_bots[bot]["modo_ia"] = "input_dup"
            estado_bots[bot]["ia_senal_pendiente"] = False
            estado_bots[bot]["ia_prob_senal"] = None
            # Evita mostrar probabilidad stale (ej. 32.4% clonada) cuando la entrada es inv√°lida.
            estado_bots[bot]["prob_ia"] = None
            return

        p, err = predecir_prob_ia_bot(bot)

        if p is not None:
            p = _aplicar_orientacion_prob(float(p))
            p = _ajustar_prob_operativa(float(p))
            p = _ajustar_prob_por_evidencia_bot(bot, float(p))
            p = _cap_prob_por_madurez(float(p), bot=bot)
            estado_bots[bot]["prob_ia"] = float(p)
            estado_bots[bot]["ia_ready"] = True
            estado_bots[bot]["ia_last_err"] = None
            estado_bots[bot]["ia_last_prob_ts"] = now

            # FIX UI/AUTO: garantizar modo_ia distinto de OFF cuando hay predicci√≥n.
            try:
                if str(err or "").upper().startswith("LOW_DATA"):
                    estado_bots[bot]["modo_ia"] = "low_data"
                else:
                    meta_local = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
                    reliable = bool(meta_local.get("reliable", False))
                    n_samples = int(meta_local.get("n_samples", meta_local.get("n", 0)) or 0)
                    if reliable:
                        modo = "confiable"
                    elif n_samples >= int(MIN_FIT_ROWS_LOW):
                        modo = "modelo"
                    else:
                        modo = "low_data"
                    estado_bots[bot]["modo_ia"] = modo
            except Exception:
                estado_bots[bot]["modo_ia"] = "low_data" if str(err or "").upper().startswith("LOW_DATA") else "modelo"
            return

        # fallo: no mates la √∫ltima prob, solo marca error
        estado_bots[bot]["ia_last_err"] = err or "ERR"

        # si hace demasiado que no hay prob v√°lida, limpia a None
        last_ok = float(estado_bots[bot].get("ia_last_prob_ts", 0.0) or 0.0)
        age = (now - last_ok) if last_ok > 0 else 10**9

        err_txt = str(err or "")
        hard_invalid = err_txt.startswith("FEAT_MISMATCH") or err_txt.startswith("NO_FEATURE_ROW") or err_txt.startswith("SCALER_FAIL")

        if (not hard_invalid) and age <= IA_PRED_TTL_S and estado_bots[bot].get("prob_ia") is not None:
            # Mantener √∫ltimo dato √∫til para que la UI no quede en '--'.
            estado_bots[bot]["ia_ready"] = True
            if str(estado_bots[bot].get("modo_ia", "")).strip().lower() in ("", "off"):
                estado_bots[bot]["modo_ia"] = "stale"
        else:
            estado_bots[bot]["ia_ready"] = False
            estado_bots[bot]["prob_ia"] = None
            estado_bots[bot]["modo_ia"] = "off"

    except Exception:
        # ultra defensivo: no romper loop
        try:
            estado_bots[bot]["ia_ready"] = False
            estado_bots[bot]["ia_last_err"] = "UPD_ERR"
        except Exception:
            pass

def _desempatar_probs_ia_por_bot() -> None:
    """
    Si varias Prob IA quedan pr√°cticamente id√©nticas en un tick,
    aplica un micro-ajuste por evidencia reciente del bot para romper empates.

    Objetivo: evitar que todos los bots muestren exactamente el mismo valor (p. ej. 78.1%)
    cuando el modelo queda temporalmente poco discriminante.
    """
    global _IA_TIEBREAK_LOG_TS
    try:
        live = []
        for b in BOT_NAMES:
            st = estado_bots.get(b, {})
            p = st.get("prob_ia", None)
            if not bool(st.get("ia_ready", False)):
                continue
            if not isinstance(p, (int, float)):
                continue
            pf = float(p)
            if not np.isfinite(pf):
                continue
            live.append((b, pf))

        if len(live) < 2:
            return

        try:
            meta = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
            n_samples = int(meta.get("n_samples", meta.get("n", 0)) or 0)
            warmup = bool(meta.get("warmup_mode", n_samples < int(TRAIN_WARMUP_MIN_ROWS)))
            if warmup:
                return
        except Exception:
            pass

        probs = [x[1] for x in live]
        spread = max(probs) - min(probs)
        uniq4 = len({round(v, 4) for v in probs})

        # Solo actuar en empate/casi empate real.
        if spread >= 0.002 and uniq4 >= 3:
            return

        changed = []
        for b, pb in live:
            st = estado_bots.get(b, {})
            g = int(st.get("ganancias", 0) or 0)
            d = int(st.get("perdidas", 0) or 0)
            # WR suavizado (Beta(1,1)) para no sobrecastigar n bajo.
            wr = float((g + 1.0) / (g + d + 2.0))
            edge = float(max(-0.5, min(0.5, wr - 0.5)))
            # Micro-ajuste: m√°ximo ¬±1pp.
            delta = float(max(-0.01, min(0.01, edge * 0.02)))
            p_new = float(max(0.0, min(1.0, pb + delta)))
            estado_bots[b]["prob_ia"] = p_new
            changed.append((b, pb, p_new))

        now = time.time()
        if changed and ((now - float(_IA_TIEBREAK_LOG_TS or 0.0)) >= 20.0):
            _IA_TIEBREAK_LOG_TS = now
            top = sorted(changed, key=lambda x: x[2], reverse=True)[:3]
            txt = ", ".join([f"{b}:{o*100:.1f}‚Üí{n*100:.1f}%" for b, o, n in top])
            agregar_evento(f"üß≠ IA tiebreak: desempate leve por evidencia ({txt}).")
    except Exception:
        pass


def actualizar_prob_ia_todos():
    """
    Tick √∫nico para el panel:
      1) Cierra se√±ales en IA_SIGNALS_LOG (Real vs Ficci√≥n) usando los cierres del CSV del bot.
      2) Detecta input duplicado por fingerprint de features por bot.
      3) Actualiza Prob IA por bot (sin tocar la l√≥gica de trading).
    """
    global _IA_CLONED_PROB_TICKS, _IA_INPUT_DUP_INFO

    # 0) Estado default por tick
    for b in BOT_NAMES:
        try:
            estado_bots[b]["ia_input_duplicado"] = False
            estado_bots[b]["ia_input_redundante"] = False
            estado_bots[b]["ia_input_dup_group"] = ""
        except Exception:
            pass

    # 1) Backfill / cierre de se√±ales
    for b in BOT_NAMES:
        try:
            last = IA_AUDIT_LAST_CLOSE_EPOCH.get(b, None)
            tail_lines = 25000 if last is None else 6000
            max_events = 60 if last is None else 15
            ia_audit_scan_close(b, tail_lines=tail_lines, max_events=max_events)
        except Exception:
            pass

    # 2) Fingerprints por bot: detectar redundancia y SOLO invalidar si hay clon real de origen
    rows_by_bot = {}
    fp_map = {}
    try:
        for b in BOT_NAMES:
            row = leer_ultima_fila_features_para_pred(b)
            if row is None:
                continue
            rows_by_bot[b] = row
            fp = _fingerprint_features_row(row, feats=list(INCREMENTAL_FEATURES_V2))
            fp_map.setdefault(fp, []).append(b)

        dup_groups = [bots for bots in fp_map.values() if len(bots) >= 2]
        if dup_groups:
            now = time.time()
            for bots in dup_groups:
                sig = "+".join(sorted(bots))
                diag = _diagnosticar_inputs_duplicados(rows_by_bot, bots, feats=list(INCREMENTAL_FEATURES_V2))
                same_cols = diag.get("same_cols", [])
                expected = diag.get("expected_diff", [])
                src_info = diag.get("source_info", {}) if isinstance(diag, dict) else {}

                # Clon real SOLO si hay evidencia fuerte de misma lectura/fila (no por features iguales).
                clone_real = False
                source_keys_full = []
                source_keys_hash_ts_sym = []
                for bb in bots:
                    inf = src_info.get(bb, {}) if isinstance(src_info, dict) else {}
                    path = str(inf.get("path", "") or "")
                    hsh = str(inf.get("hash", "") or "")
                    tsv = str(inf.get("ts", "") or "")
                    sym = str(inf.get("symbol", "") or "")
                    source_keys_full.append((path, hsh, tsv))
                    source_keys_hash_ts_sym.append((hsh, tsv, sym))

                if source_keys_full:
                    ufull = set(source_keys_full)
                    uhash = set(source_keys_hash_ts_sym)
                    # Caso 1: misma fuente exacta (path/hash/ts) entre bots.
                    if len(ufull) == 1 and all(any(x for x in k) for k in ufull):
                        clone_real = True
                    # Caso 2: paths distintos pero misma fila/hash+timestamp+s√≠mbolo (clon probable por wiring).
                    elif len(uhash) == 1 and all(any(x for x in k) for k in uhash):
                        clone_real = True

                src_brief = []
                for bb in bots[:3]:
                    inf = src_info.get(bb, {}) if isinstance(src_info, dict) else {}
                    src_brief.append(f"{bb}:{inf.get('symbol','')}/{inf.get('hash','')}/{inf.get('ts','')}")

                msg_sig = f"{sig}|{','.join(same_cols[:6])}|clone={int(clone_real)}"
                should_emit = (
                    msg_sig != str(_IA_INPUT_DUP_INFO.get("signature", "")) or
                    (now - float(_IA_INPUT_DUP_INFO.get("ts", 0.0) or 0.0)) >= float(INPUT_DUP_DIAG_COOLDOWN_S)
                )

                for b in bots:
                    try:
                        estado_bots[b]["ia_input_duplicado"] = bool(clone_real)
                        estado_bots[b]["ia_input_dup_group"] = sig
                        estado_bots[b]["ia_input_redundante"] = not bool(clone_real)
                    except Exception:
                        pass

                if should_emit:
                    if clone_real:
                        agregar_evento(
                            "üõë IA inv√°lida por CLON REAL de input "
                            f"[{sig}] | cols_iguales={same_cols[:8]} | esperadas_diferir={expected} | src={src_brief}"
                        )
                    else:
                        agregar_evento(
                            "‚ö†Ô∏è IA redundante (NO invalida) "
                            f"[{sig}] | cols={same_cols[:4]}"
                        )
                    _IA_INPUT_DUP_INFO = {"signature": msg_sig, "ts": now, "bots": list(bots)}
    except Exception:
        pass

    # 3) Predicci√≥n / estado IA del bot
    for b in BOT_NAMES:
        try:
            actualizar_prob_ia_bot(b)
            p_live = estado_bots.get(b, {}).get("prob_ia", None)
            _actualizar_estado_suceso_bot(b, p_live if isinstance(p_live, (int, float)) else None)
        except Exception:
            pass

    # 3.5) Desempate leve cuando el modelo deja todas las probs casi id√©nticas.
    _desempatar_probs_ia_por_bot()

    # 4) Guardrail anti-clonado de probabilidades (s√≠ntoma downstream)
    try:
        div = _calcular_diversidad_prob_tick()
        if div.get("all_equal", False) and int(div.get("n_live", 0)) >= 2:
            _IA_CLONED_PROB_TICKS = int(_IA_CLONED_PROB_TICKS) + 1
        else:
            _IA_CLONED_PROB_TICKS = 0

        if int(_IA_CLONED_PROB_TICKS) >= int(CLONED_PROB_TICKS_ALERT):
            agregar_evento(
                f"üß™ DATA QUALITY: INPUT DUPLICADO (probs clonadas {div.get('n_live',0)}/{len(BOT_NAMES)} por {int(_IA_CLONED_PROB_TICKS)} ticks)."
            )
            _IA_CLONED_PROB_TICKS = 0
    except Exception:
        pass

def _sensor_plano_bot(bot: str, lookback: int = 80) -> tuple[bool, dict]:
    """Detecta si un bot tiene demasiadas features pegadas (dominancia alta)."""
    try:
        rep = _auditar_saturacion_features_bot(bot, lookback=int(lookback)) or {}
        dom = rep.get("dominance", {}) if isinstance(rep, dict) else {}
        n_rep = int(rep.get("n", 0) or 0) if isinstance(rep, dict) else 0
        hot = [k for k, v in dom.items() if isinstance(v, (int, float)) and float(v) >= float(IA_SENSOR_DOM_HOT)]
        if n_rep < int(IA_SENSOR_MIN_SAMPLE):
            return False, {"hot": hot, "dominance": dom, "n": n_rep, "warmup": True}
        return bool(len(hot) >= int(IA_SENSOR_MIN_HOT_FEATS)), {"hot": hot, "dominance": dom, "n": n_rep, "warmup": False}
    except Exception:
        return False, {"hot": [], "dominance": {}, "n": 0, "warmup": True}


def _calcular_indice_suceso_bot(bot: str, p_live: float | None = None, suceso_delta: float | None = None) -> float:
    """
    √çndice Suceso 0..100 (momentum+ruptura+r√©gimen+asimetr√≠a), robusto en warmup.
    """
    try:
        row = leer_ultima_fila_features_para_pred(bot) or {}

        def _f(k, d=0.0):
            try:
                return float(row.get(k, d) or d)
            except Exception:
                return float(d)

        breakout_strength = max(0.0, min(1.0, _f("breakout", 0.0)))
        rebote = max(0.0, min(1.0, _f("es_rebote", 0.0)))
        payout = max(0.0, min(1.5, _f("payout", 0.0))) / 1.5
        rsi14 = max(0.0, min(100.0, _f("rsi_14", 50.0)))
        momentum = abs(rsi14 - 50.0) / 50.0

        try:
            vol = max(0.0, min(1.0, _f("volatilidad", 0.0)))
        except Exception:
            vol = 0.0

        delta_term = 0.0
        if isinstance(suceso_delta, (int, float)):
            delta_term = max(0.0, min(1.0, float(suceso_delta) / max(1e-6, float(IA_SUCESO_DELTA_MIN))))

        p_term = 0.0
        if isinstance(p_live, (int, float)):
            p_term = max(0.0, min(1.0, (float(p_live) - 0.50) / 0.20))

        score = (
            0.26 * breakout_strength +
            0.20 * max(rebote, delta_term) +
            0.16 * momentum +
            0.14 * vol +
            0.14 * payout +
            0.10 * p_term
        )
        return float(max(0.0, min(100.0, score * 100.0)))
    except Exception:
        return 0.0


def _detectar_suceso_prob_bot(bot: str, p_now: float | None) -> tuple[bool, float]:
    """Detecta salto relativo de probabilidad vs su l√≠nea base reciente."""
    try:
        if not isinstance(p_now, (int, float)):
            return False, 0.0
        p = float(max(0.0, min(1.0, p_now)))
        st = estado_bots.get(bot, {})
        hist = st.get("ia_prob_hist_raw", None)
        if not isinstance(hist, list):
            hist = []
        hist.append(p)
        max_len = int(max(6, IA_SUCESO_LOOKBACK * 3))
        if len(hist) > max_len:
            hist = hist[-max_len:]
        st["ia_prob_hist_raw"] = hist
        estado_bots[bot] = st

        look = int(max(4, IA_SUCESO_LOOKBACK))
        prev = hist[:-1][-look:]
        if len(prev) < 4:
            return False, 0.0
        base = float(np.median(np.asarray(prev, dtype=float)))
        delta = float(p - base)
        return bool(delta >= float(IA_SUCESO_DELTA_MIN)), delta
    except Exception:
        return False, 0.0


def _evento_contexto_activo(bot: str) -> bool:
    """True si hay evento de mercado razonable para validar un suceso relativo."""
    try:
        row = leer_ultima_fila_features_para_pred(bot) or {}
        brk = float(row.get("breakout", 0.0) or 0.0)
        reb = float(row.get("es_rebote", 0.0) or 0.0)
        return bool(max(brk, reb) >= float(IA_SUCESO_EVENTO_MIN))
    except Exception:
        return False


def _actualizar_estado_suceso_bot(bot: str, prob_live: float | None) -> None:
    """Ruta can√≥nica √∫nica para actualizar telemetr√≠a/se√±al por suceso."""
    try:
        if prob_live is None or not isinstance(prob_live, (int, float)):
            estado_bots[bot]["ia_senal_pendiente"] = False
            estado_bots[bot]["ia_prob_senal"] = None
            estado_bots[bot]["ia_suceso_ok"] = False
            estado_bots[bot]["ia_suceso_delta"] = 0.0
            estado_bots[bot]["ia_suceso_idx"] = 0.0
            return

        p_live = float(prob_live)
        abs_gate = bool(p_live >= float(IA_VERDE_THR))
        suc_ok, suc_delta = _detectar_suceso_prob_bot(bot, p_live)
        evt_ok = _evento_contexto_activo(bot)
        redundante_tick = bool(estado_bots.get(bot, {}).get("ia_input_redundante", False))
        suceso_gate = bool(suc_ok and evt_ok)

        suceso_idx = _calcular_indice_suceso_bot(bot, p_live=p_live, suceso_delta=suc_delta)
        sensor_plano, sensor_meta = _sensor_plano_bot(bot, lookback=80)

        estado_bots[bot]["ia_suceso_delta"] = float(suc_delta)
        estado_bots[bot]["ia_suceso_ok"] = bool(suceso_gate)
        estado_bots[bot]["ia_suceso_idx"] = float(suceso_idx)
        estado_bots[bot]["ia_suceso_redundante"] = bool(redundante_tick)
        estado_bots[bot]["ia_sensor_plano"] = bool(sensor_plano)
        estado_bots[bot]["ia_sensor_hot_feats"] = list(sensor_meta.get("hot", []))
        estado_bots[bot]["ia_sensor_sample_n"] = int(sensor_meta.get("n", 0) or 0)
        estado_bots[bot]["ia_sensor_warmup"] = bool(sensor_meta.get("warmup", False))

        if abs_gate or suceso_gate:
            estado_bots[bot]["ia_senal_pendiente"] = True
            estado_bots[bot]["ia_prob_senal"] = float(p_live)
        else:
            estado_bots[bot]["ia_senal_pendiente"] = False
            estado_bots[bot]["ia_prob_senal"] = None
    except Exception:
        try:
            estado_bots[bot]["ia_senal_pendiente"] = False
            estado_bots[bot]["ia_prob_senal"] = None
        except Exception:
            pass


def actualizar_prob_ia_bots_tick():
    """Compat: ruta √∫nica de actualizaci√≥n IA (delegada)."""
    actualizar_prob_ia_todos()


def ia_prob_valida(bot: str, max_age_s: float = 10.0) -> bool:
    """
    True si:
    - ia_ready=True
    - prob_ia existe y es finita en [0..1]
    - timestamp reciente (<= max_age_s)
    """
    try:
        if bot not in estado_bots:
            return False

        if not bool(estado_bots[bot].get("ia_ready", False)):
            return False

        ts = float(estado_bots[bot].get("ia_last_prob_ts", 0.0) or 0.0)
        if ts <= 0:
            return False

        if (time.time() - ts) > float(max_age_s):
            return False

        p = estado_bots[bot].get("prob_ia", None)
        if p is None:
            return False

        p = float(p)
        if not np.isfinite(p):
            return False

        return (0.0 <= p <= 1.0)

    except Exception:
        return False
                                              
_AUTO_REAL_CACHE = {"ts": 0.0, "thr": float(IA_ACTIVACION_REAL_THR), "n": 0, "max": 0.0}


def _leer_probs_historicas_ia(max_rows: int = AUTO_REAL_LOG_MAX_ROWS) -> list[float]:
    """Lee probs hist√≥ricas del log de se√±ales IA cerradas para calibrar umbral REAL."""
    path = IA_SIGNALS_LOG
    if not os.path.exists(path):
        return []
    vals = []
    try:
        with open(path, "r", encoding="utf-8", newline="") as f:
            r = csv.DictReader(f)
            rows = list(r)
        if max_rows and len(rows) > int(max_rows):
            rows = rows[-int(max_rows):]
        for row in rows:
            try:
                p = float(str(row.get("prob", "")).replace(",", "."))
                if np.isfinite(p) and 0.0 <= p <= 1.0:
                    vals.append(p)
            except Exception:
                continue
    except Exception:
        return []
    return vals


def get_umbral_real_calibrado(force: bool = False) -> float:
    """
    Umbral adaptativo para activar REAL usando hist√≥ricos + probabilidad viva actual.
    Reglas:
    - Hist√≥rico: cuant√≠l alto de ia_signals_log.prob (estabilidad).
    - Vivo: mejor prob IA actual de bots (sensibilidad al r√©gimen actual).
    - Resultado: min(thr_hist, thr_live) acotado en [AUTO_REAL_THR_MIN .. AUTO_REAL_THR].
    """
    now = time.time()
    try:
        # En modo cl√°sico, el umbral REAL debe mantenerse fijo al operativo (85%).
        if bool(REAL_CLASSIC_GATE):
            thr_fixed = float(IA_ACTIVACION_REAL_THR)
            _AUTO_REAL_CACHE["ts"] = now
            _AUTO_REAL_CACHE["thr"] = thr_fixed
            return thr_fixed

        if (not force) and ((now - float(_AUTO_REAL_CACHE.get("ts", 0.0) or 0.0)) < 8.0):
            return float(_AUTO_REAL_CACHE.get("thr", AUTO_REAL_THR_MIN))

        # 1) Hist√≥rico
        probs = _leer_probs_historicas_ia(AUTO_REAL_LOG_MAX_ROWS)
        if len(probs) >= 12:
            q_hist = float(np.quantile(np.array(probs, dtype=float), float(AUTO_REAL_TOP_Q)))
            thr_hist = q_hist - float(AUTO_REAL_MARGIN)
            pmax_hist = float(max(probs))
        else:
            thr_hist = float(AUTO_REAL_THR_MIN)
            pmax_hist = float(max(probs)) if probs else 0.0

        # 2) Vivo (√∫ltimo tick): si el mercado/modelo se aplana, el gate tambi√©n baja
        live_probs = []
        for b in BOT_NAMES:
            try:
                if not ia_prob_valida(b, max_age_s=12.0):
                    continue
                p = float(estado_bots.get(b, {}).get("prob_ia", 0.0) or 0.0)
                if np.isfinite(p) and 0.0 <= p <= 1.0:
                    live_probs.append(p)
            except Exception:
                continue

        if len(live_probs) >= int(AUTO_REAL_LIVE_MIN_BOTS):
            pmax_live = float(max(live_probs))
            thr_live = pmax_live - float(AUTO_REAL_MARGIN)
        else:
            pmax_live = 0.0
            thr_live = float(AUTO_REAL_THR_MIN)

        thr_raw = min(float(thr_hist), float(thr_live))
        thr = max(float(AUTO_REAL_THR_MIN), min(float(AUTO_REAL_THR), float(thr_raw)))

        _AUTO_REAL_CACHE["ts"] = now
        _AUTO_REAL_CACHE["thr"] = float(thr)
        _AUTO_REAL_CACHE["n"] = int(len(probs))
        _AUTO_REAL_CACHE["max"] = float(max(pmax_hist, pmax_live))
        return float(thr)
    except Exception:
        return float(AUTO_REAL_THR_MIN)


def detectar_cierre_martingala(bot, min_fila=None, require_closed=True, require_real_token=False, expected_ciclo=None):
    """
    Devuelve: (resultado_norm, monto, ciclo, payout_total)
    - min_fila: solo acepta filas con n√∫mero > min_fila (evita cierres viejos)
              Nota: min_fila se interpreta como "cantidad de filas de datos" (sin header),
              y cuadra con contar_filas_csv().
    - require_closed: si existe trade_status, exige CERRADO/CLOSED.
    - require_real_token: si hay columna de token/cuenta, ignora cierres DEMO.
    - expected_ciclo: si existe columna de ciclo, exige coincidencia con ese ciclo.
    """
    path = f"registro_enriquecido_{bot}.csv"
    if not os.path.exists(path):
        return None

    rows = None
    header = None

    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            with open(path, "r", encoding=enc, errors="replace", newline="") as f:
                rows = list(csv.reader(f))
            if rows and len(rows) >= 2:
                header = rows[0]
                break
        except Exception:
            continue

    if not rows or not header or len(rows) < 2:
        return None

    # Mapa de columnas case-insensitive y con strip
    hmap = {}
    for i, h in enumerate(header):
        try:
            key = str(h).strip().lower()
            if key and key not in hmap:
                hmap[key] = i
        except Exception:
            pass

    def _col(*names):
        for n in names:
            k = str(n).strip().lower()
            if k in hmap:
                return hmap[k]
        return None

    i_res = _col("resultado", "result", "outcome")
    i_status = _col("trade_status", "status")
    i_monto = _col("monto", "stake", "buy_price", "amount")
    i_ciclo = _col("ciclo", "ciclo_martingala", "ciclo_actual", "marti_ciclo", "martingale_step")
    i_token = _col("token", "account", "account_type", "cuenta", "modo", "mode")
    # payout_total puede venir expl√≠cito o calculable
    # (extraer_payout_total ya se encarga, pero igual ayudamos con nombres)
    i_payout_total = _col("payout_total")
    i_payout_mult = _col("payout_multiplier")
    i_payout_dec = _col("payout_decimal_rounded")
    i_payout_legacy = _col("payout")  # legacy (ojo: a veces ROI feature, a veces ratio/total)

    if i_res is None:
        return None

    # Recorremos desde el final (√∫ltimo evento primero)
    for ridx in range(len(rows) - 1, 0, -1):
        row = rows[ridx]
        if not row:
            continue

        # ridx equivale a "n√∫mero de fila de datos" (header est√° en 0)
        fila_num = ridx  # 1..N
        if min_fila is not None:
            try:
                if int(fila_num) <= int(min_fila):
                    break  # todo lo que sigue es m√°s viejo todav√≠a
            except Exception:
                pass

        # trade_status si aplica
        if require_closed and (i_status is not None) and (i_status < len(row)):
            st = str(row[i_status]).strip().upper()
            if st not in ("CERRADO", "CLOSED"):
                continue

        # Si el CSV informa token/cuenta, en REAL ignoramos cierres expl√≠citos de DEMO.
        if require_real_token and (i_token is not None) and (i_token < len(row)):
            tok_raw = str(row[i_token] or "").strip().upper()
            if tok_raw:
                # Heur√≠stica robusta: DEMO en Deriv suele venir como VRTC*
                es_demo = ("DEMO" in tok_raw) or tok_raw.startswith("VRTC")
                es_real = ("REAL" in tok_raw) or tok_raw.startswith("CR")
                if es_demo and not es_real:
                    continue

        # resultado
        try:
            raw_res = row[i_res] if i_res < len(row) else ""
        except Exception:
            raw_res = ""
        res_norm = normalizar_resultado(raw_res)
        if res_norm not in ("GANANCIA", "P√âRDIDA"):
            continue

        # Armamos dict de fila para reutilizar tus extractores robustos
        row_dict_full = {}
        try:
            for j, h in enumerate(header):
                if j < len(row):
                    row_dict_full[str(h).strip()] = row[j]
        except Exception:
            row_dict_full = {}

        # Monto
        monto = None
        try:
            if i_monto is not None and i_monto < len(row):
                monto = _safe_float_local(row[i_monto])
        except Exception:
            monto = None

        # Ciclo
        ciclo = None
        try:
            if i_ciclo is not None and i_ciclo < len(row):
                ciclo = _safe_float_local(row[i_ciclo])
                ciclo = int(float(ciclo)) if ciclo is not None else None
        except Exception:
            ciclo = None

        # Si esperamos un ciclo concreto, exige que exista y coincida.
        if expected_ciclo is not None:
            try:
                if ciclo is None:
                    continue
                if int(ciclo) != int(expected_ciclo):
                    continue
            except Exception:
                continue

        # payout_total: preferimos extractor (maneja legacy y ratio)
        payout_total = None
        try:
            # Si el CSV trae expl√≠cito, dale prioridad
            if i_payout_total is not None and i_payout_total < len(row):
                payout_total = _safe_float_local(row[i_payout_total])
        except Exception:
            payout_total = None

        if payout_total is None:
            # Asegurar que el dict tenga keys √∫tiles si existen en el CSV
            try:
                if i_payout_mult is not None and i_payout_mult < len(row):
                    row_dict_full["payout_multiplier"] = row[i_payout_mult]
                if i_payout_dec is not None and i_payout_dec < len(row):
                    row_dict_full["payout_decimal_rounded"] = row[i_payout_dec]
                if i_payout_legacy is not None and i_payout_legacy < len(row):
                    row_dict_full["payout"] = row[i_payout_legacy]
                if monto is not None:
                    row_dict_full["monto"] = monto
            except Exception:
                pass

            try:
                payout_total = extraer_payout_total(row_dict_full)
            except Exception:
                payout_total = None

        # Devolver lo encontrado (payout_total puede ser None si no hay info suficiente)
        try:
            monto_out = float(monto) if monto is not None else None
        except Exception:
            monto_out = None

        return (res_norm, monto_out, ciclo, payout_total)

    return None

def detectar_martingala_perdida_completa(bot):
    """
    Detecta si se perdi√≥ una Martingala completa:
    √∫ltimos MAX_CICLOS resultados definitivos son todos P√âRDIDA
    (con normalizaci√≥n robusta del resultado).
    """
    path = f"registro_enriquecido_{bot}.csv"
    if not os.path.exists(path):
        return False

    rows = None
    header = None
    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            with open(path, "r", encoding=enc, errors="replace", newline="") as f:
                rows = list(csv.reader(f))
            if rows and len(rows) >= 2:
                header = rows[0]
                break
        except Exception:
            continue

    if not rows or not header or len(rows) < 2:
        return False

    def idx(col):
        return header.index(col) if col in header else None

    res_idx = idx("resultado")
    trade_idx = idx("trade_status")  # <- ahora s√≠ existe siempre

    if res_idx is None:
        return False

    ult = []
    for row in reversed(rows[1:]):
        if not row or len(row) <= res_idx:
            continue

        # Si existe trade_status, exigir CERRADO para contar en rachas
        if trade_idx is not None:
            if len(row) <= trade_idx:
                continue
            ts = (row[trade_idx] or "").strip().upper()
            if ts != "CERRADO":
                continue

        res_norm = normalizar_resultado((row[res_idx] or "").strip())
        if res_norm not in ("GANANCIA", "P√âRDIDA"):
            continue

        ult.append(res_norm)
        if len(ult) >= MAX_CICLOS:
            break

    if len(ult) < MAX_CICLOS:
        return False

    return all(x == "P√âRDIDA" for x in ult)

# Reinicio completo - Corregido para no resetear m√©tricas en modo suave
def reiniciar_completo(borrar_csv=False, limpiar_visual_segundos=15, modo_suave=True):
    global LIMPIEZA_PANEL_HASTA, marti_paso, marti_activa, marti_ciclos_perdidos, ultimo_bot_real, bots_usados_en_esta_marti, REAL_OWNER_LOCK
    with file_lock():
        write_token_atomic(TOKEN_FILE, "REAL:none")
    
    if borrar_csv and os.path.exists("dataset_incremental.csv"):
        os.remove("dataset_incremental.csv")

    for bot in BOT_NAMES:
        if borrar_csv:
            archivo = f"registro_enriquecido_{bot}.csv"
            if os.path.exists(archivo):
                os.remove(archivo)
            estado_bots[bot]["resultados"] = []
            huellas_usadas[bot] = set()
            estado_bots[bot]["ganancias"] = 0
            estado_bots[bot]["perdidas"] = 0
            estado_bots[bot]["porcentaje_exito"] = None
            estado_bots[bot]["tamano_muestra"] = 0
        elif not modo_suave:
            estado_bots[bot]["resultados"] = []
            estado_bots[bot]["ganancias"] = 0
            estado_bots[bot]["perdidas"] = 0
            estado_bots[bot]["porcentaje_exito"] = None
            estado_bots[bot]["tamano_muestra"] = 0
        estado_bots[bot].update({
            "token": "DEMO",
            "trigger_real": False,
            "prob_ia": 0.0,
            "ia_ready": False,
            "ciclo_actual": 1,
            "modo_real_anunciado": False,
            "ultimo_resultado": None,
            "reintentar_ciclo": False,
            "remate_active": False,
            "remate_start": None,
            "remate_reason": "",
            "fuente": None,
            "real_activado_en": 0.0,  
            "ignore_cierres_hasta": 0.0,
            "real_timeout_first_warn": 0.0,
            "modo_ia": "off",
            "ia_seniales": 0,
            "ia_aciertos": 0,
            "ia_fallos": 0,
            "ia_senal_pendiente": False,
            "ia_prob_senal": None
        })
        SNAPSHOT_FILAS[bot] = contar_filas_csv(bot)
        OCULTAR_HASTA_NUEVO[bot] = False  # Cambiado para no ocultar
        IA53_TRIGGERED[bot] = False
        IA90_stats[bot] = {"n": 0, "ok": 0, "pct": 0.0, "pct_raw": 0.0, "pct_smooth": 50.0}
        if not isinstance(huellas_usadas.get(bot), set):
            huellas_usadas[bot] = set()
    eventos_recentes.clear()
    for b in BOT_NAMES:
        LAST_REAL_CLOSE_SIG[b] = None
    marti_paso = 0
    marti_activa = False
    marti_ciclos_perdidos = 0
    ultimo_bot_real = None
    bots_usados_en_esta_marti = []
    REAL_OWNER_LOCK = None
    LIMPIEZA_PANEL_HASTA = time.time() + limpiar_visual_segundos

# Reinicio de bot individual - Corregido similar
def reiniciar_bot(bot, borrar_csv=False):
    # Nunca reiniciar duro al owner REAL activo: durante una operaci√≥n puede no
    # escribir filas por varios segundos y eso NO significa que deba volver a DEMO.
    owner_activo = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None
    if owner_activo == bot or estado_bots.get(bot, {}).get("token") == "REAL":
        try:
            agregar_evento(f"üõ°Ô∏è Reinicio omitido para {bot.upper()}: operaci√≥n REAL en curso.")
        except Exception:
            pass
        return

    if borrar_csv:
        archivo = f"registro_enriquecido_{bot}.csv"
        if os.path.exists(archivo):
            os.remove(archivo)
        estado_bots[bot]["resultados"] = []
        huellas_usadas[bot] = set()
        estado_bots[bot]["ganancias"] = 0
        estado_bots[bot]["perdidas"] = 0
        estado_bots[bot]["porcentaje_exito"] = None
        estado_bots[bot]["tamano_muestra"] = 0
    estado_bots[bot].update({
        "token": "DEMO", 
        "trigger_real": False,
        "prob_ia": 0.0,
        "ia_ready": False,
        "ciclo_actual": 1,
        "modo_real_anunciado": False,
        "ultimo_resultado": None,
        "reintentar_ciclo": False,
        "remate_active": False,
        "remate_start": None,
        "remate_reason": "",
        "fuente": None,
        "real_activado_en": 0.0,  
        "ignore_cierres_hasta": 0.0,
        "real_timeout_first_warn": 0.0,
        "modo_ia": "off",
        "ia_seniales": 0,
        "ia_aciertos": 0,
        "ia_fallos": 0,
        "ia_senal_pendiente": False,
        "ia_prob_senal": None
    })
    SNAPSHOT_FILAS[bot] = contar_filas_csv(bot)
    OCULTAR_HASTA_NUEVO[bot] = False  # Cambiado para no ocultar
    IA90_stats[bot] = {"n": 0, "ok": 0, "pct": 0.0, "pct_raw": 0.0, "pct_smooth": 50.0}
    LAST_REAL_CLOSE_SIG[bot] = None
    if not isinstance(huellas_usadas.get(bot), set):
        huellas_usadas[bot] = set()

def cerrar_por_fin_de_ciclo(bot: str, reason: str):
    global REAL_OWNER_LOCK, REAL_COOLDOWN_UNTIL_TS
    # Limpieza total de ‚Äúestado REAL‚Äù para evitar HUD/estado fantasma
    try:
        estado_bots[bot]["token"] = "DEMO"
        estado_bots[bot]["trigger_real"] = False
        estado_bots[bot]["ciclo_actual"] = 1
        estado_bots[bot]["modo_real_anunciado"] = False
        estado_bots[bot]["fuente"] = None

        # ‚úÖ Extra blindaje (evita ‚Äúescudos‚Äù de cierre pegados en DEMO)
        estado_bots[bot]["real_activado_en"] = 0.0
        estado_bots[bot]["ignore_cierres_hasta"] = 0.0
        estado_bots[bot]["real_timeout_first_warn"] = 0.0

        # Flags IA/pending (si qued√≥ algo colgado)
        estado_bots[bot]["ia_senal_pendiente"] = False
        estado_bots[bot]["ia_prob_senal"] = None

        # Remate limpio
        estado_bots[bot]["remate_active"] = False
        estado_bots[bot]["remate_start"] = None
        estado_bots[bot]["remate_reason"] = ""

    except Exception:
        pass

    # Liberar token global REAL
    REAL_OWNER_LOCK = None
    REAL_COOLDOWN_UNTIL_TS = time.time() + float(_cooldown_post_trade_s())
    try:
        with file_lock():
            write_token_atomic(TOKEN_FILE, "REAL:none")
    except Exception:
        pass

    # Limpiar orden REAL para evitar re-entradas fantasma (igual que cerrar_por_win)
    try:
        limpiar_orden_real(bot)
    except Exception:
        pass

    # Sync inmediato del HUD/token para evitar ‚ÄúREAL fantasma‚Äù
    try:
        _set_ui_token_holder(None)
    except Exception:
        pass

   
    # Actualizar snapshots para que no relea la misma fila
    try:
        REAL_ENTRY_BASELINE[bot] = 0
        SNAPSHOT_FILAS[bot] = contar_filas_csv(bot)
    except Exception:
        pass

    try:
        OCULTAR_HASTA_NUEVO[bot] = False
    except Exception:
        pass

    # Forzar refresco del loop principal
    try:
        reinicio_forzado.set()
    except Exception:
        pass

    # Log visual
    try:
        agregar_evento(f"üîì Cuenta REAL liberada para {bot.upper()} ({reason})")
    except Exception:
        pass

def _marti_audit_record(kind: str, ciclo: int | None = None, bot: str | None = None, detalle: str = ""):
    """Guarda rastro compacto de la secuencia C1..C{MAX_CICLOS} para diagn√≥stico."""
    global marti_audit_historial
    try:
        c = int(ciclo) if ciclo is not None else None
    except Exception:
        c = None
    run = int(globals().get("marti_audit_run_id", 1) or 1)
    item = {
        "ts": time.strftime("%H:%M:%S"),
        "run": run,
        "kind": str(kind),
        "ciclo": c,
        "bot": str(bot) if bot else None,
        "detalle": str(detalle or ""),
    }
    try:
        marti_audit_historial.append(item)
    except Exception:
        pass


def _marti_audit_log_orden(ciclo: int, bot: str | None = None, origen: str = ""):
    """
    Verifica orden esperado C1->C6 por corrida y deja eventos expl√≠citos.
    No bloquea operaci√≥n; solo audita y alerta desviaciones.
    """
    global marti_audit_run_id, marti_audit_desviaciones, marti_audit_ultimo_ciclo_ordenado
    try:
        c = max(1, min(int(MAX_CICLOS), int(ciclo)))
    except Exception:
        c = 1
    last = marti_audit_ultimo_ciclo_ordenado
    exp = 1 if last is None else (1 if int(last) >= int(MAX_CICLOS) else int(last) + 1)
    if int(c) != int(exp):
        marti_audit_desviaciones = int(marti_audit_desviaciones) + 1
        agregar_evento(
            f"üö® MARTI-AUDIT run#{int(marti_audit_run_id)}: orden fuera de secuencia (esperado C{int(exp)}, lleg√≥ C{int(c)})."
        )
        _marti_audit_record("desvio", ciclo=c, bot=bot, detalle=f"esperado=C{exp} origen={origen}")
    else:
        _marti_audit_record("orden", ciclo=c, bot=bot, detalle=f"origen={origen}")
    marti_audit_ultimo_ciclo_ordenado = int(c)


def marti_audit_resumen_linea() -> str:
    """L√≠nea compacta para HUD/eventos con estado de auditor√≠a."""
    try:
        run = int(marti_audit_run_id)
        dv = int(marti_audit_desviaciones)
        ult = marti_audit_ultimo_ciclo_ordenado
        ult_txt = f"C{int(ult)}" if isinstance(ult, int) and ult > 0 else "--"
        return f"Audit run#{run} desv√≠os={dv} √∫ltimo={ult_txt}"
    except Exception:
        return "Audit run#? desv√≠os=? √∫ltimo=--"


def registrar_resultado_real(resultado: str, bot: str | None = None, ciclo_operado: int | None = None):
    """
    Actualiza el contador global de ciclos martingala para el HUD y la pr√≥xima
    autoasignaci√≥n REAL.

    Reglas:
    - GANANCIA: resetea a ciclo #1 (contador de p√©rdidas = 0).
    - P√âRDIDA: incrementa ciclo hasta MAX_CICLOS (tope de blindaje).
    """
    global marti_ciclos_perdidos, marti_paso, ultimo_bot_real, bots_usados_en_esta_marti
    global marti_audit_run_id, marti_audit_ultimo_ciclo_ordenado

    res = normalizar_resultado(resultado)
    if bot in BOT_NAMES:
        ultimo_bot_real = bot

    if res == "GANANCIA":
        marti_ciclos_perdidos = 0
        marti_paso = 0
        bots_usados_en_esta_marti = []
        _marti_audit_record("cierre_ganancia", ciclo=ciclo_operado, bot=bot, detalle="reinicio_a_C1")
        marti_audit_run_id = int(marti_audit_run_id) + 1
        marti_audit_ultimo_ciclo_ordenado = None
        agregar_evento(f"‚úÖ Martingala reiniciada en C1 por GANANCIA ({marti_audit_resumen_linea()}).")
    elif res == "P√âRDIDA":
        # Registrar el bot operado en la corrida activa para forzar rotaci√≥n C2..C{MAX_CICLOS}.
        if bot in BOT_NAMES and bot not in bots_usados_en_esta_marti:
            bots_usados_en_esta_marti.append(bot)

        # Robustez anti-desincronizaci√≥n:
        # si conocemos el ciclo realmente operado, el pr√≥ximo estado de p√©rdidas
        # debe ser al menos ese ciclo (p.ej. perder en C2 => p√©rdidas=2 => pr√≥ximo C3).
        try:
            ciclo_ref = int(ciclo_operado) if ciclo_operado is not None else 0
        except Exception:
            ciclo_ref = 0
        marti_ciclos_perdidos = min(
            MAX_CICLOS,
            max(int(marti_ciclos_perdidos) + 1, max(0, ciclo_ref))
        )
        # Si ya culmin√≥ C{MAX_CICLOS}, reinicia a C1 para el siguiente turno.
        if int(marti_ciclos_perdidos) >= int(MAX_CICLOS):
            marti_ciclos_perdidos = 0
            marti_paso = 0
            bots_usados_en_esta_marti = []
            _marti_audit_record("cierre_tope", ciclo=ciclo_operado, bot=bot, detalle=f"tope=C{int(MAX_CICLOS)}")
            marti_audit_run_id = int(marti_audit_run_id) + 1
            marti_audit_ultimo_ciclo_ordenado = None
            try:
                agregar_evento(
                    f"üßØ Martingala C{int(MAX_CICLOS)}/C{int(MAX_CICLOS)} completada: reinicio autom√°tico a C1 ({marti_audit_resumen_linea()})."
                )
            except Exception:
                pass
        else:
            marti_paso = min(MAX_CICLOS - 1, int(marti_ciclos_perdidos))
    else:
        return

    ciclo_sig = int(marti_paso) + 1
    bot_msg = f" [{bot}]" if bot else ""
    if res == "P√âRDIDA" and bots_usados_en_esta_marti:
        try:
            usados = ",".join(bots_usados_en_esta_marti)
            agregar_evento(f"üîÅ Rotaci√≥n martingala activa: usados={usados} | pr√≥ximo ciclo=C{ciclo_sig}")
        except Exception:
            pass
    agregar_evento(
        f"üîÅ Martingala{bot_msg}: resultado={res} | p√©rdidas seguidas={marti_ciclos_perdidos}/{MAX_CICLOS} | pr√≥ximo ciclo={ciclo_sig}"
    )
    agregar_evento(f"üßæ MARTI-AUDIT: {marti_audit_resumen_linea()}")

def ciclo_martingala_siguiente() -> int:
    """
    Fuente can√≥nica del ciclo a abrir en REAL:
    - ciclo = p√©rdidas_consecutivas + 1, con l√≠mites [1..MAX_CICLOS]
    """
    try:
        return max(1, min(int(MAX_CICLOS), int(marti_ciclos_perdidos) + 1))
    except Exception:
        return 1



def reset_martingala_por_saldo(ciclo_objetivo: int, saldo_actual: float | None) -> bool:
    """
    Si no alcanza el saldo para el ciclo objetivo (C2..C{MAX_CICLOS}),
    reinicia la martingala en C1.
    """
    global marti_ciclos_perdidos, marti_paso, bots_usados_en_esta_marti

    try:
        ciclo = int(ciclo_objetivo)
    except Exception:
        ciclo = 1

    if ciclo <= 1:
        return False

    idx = max(0, min(len(MARTI_ESCALADO) - 1, ciclo - 1))
    monto_necesario = float(MARTI_ESCALADO[idx])

    try:
        saldo = float(saldo_actual) if saldo_actual is not None else None
    except Exception:
        saldo = None

    if saldo is not None and saldo >= monto_necesario:
        return False

    marti_ciclos_perdidos = 0
    marti_paso = 0
    bots_usados_en_esta_marti = []
    _marti_audit_record("reset_saldo", ciclo=ciclo_objetivo, detalle="reinicio_forzado")
    falta_msg = "saldo no disponible"
    if saldo is not None:
        falta_msg = f"faltan {(monto_necesario - saldo):.2f} USD"
    agregar_evento(
        f"üßØ Saldo insuficiente para C{ciclo} ({monto_necesario:.2f} USD): {falta_msg}. Reinicio autom√°tico a C1."
    )
    return True
def elegir_candidato_rotacion_marti(candidatos: list, ciclo_objetivo: int):
    """
    Rotaci√≥n estricta para REAL en C2..C{MAX_CICLOS}:
    - Excluye bots ya usados en la corrida activa (bots_usados_en_esta_marti).
    - Si no hay elegibles nuevos, retorna None (NO repetir bot en la misma martingala).
    """
    try:
        ciclo = int(ciclo_objetivo)
    except Exception:
        ciclo = 1

    if ciclo <= 1 or not candidatos:
        return candidatos[0] if candidatos else None

    usados = [b for b in bots_usados_en_esta_marti if b in BOT_NAMES]
    usados_set = set(usados)
    candidatos_nuevos = [c for c in candidatos if c[1] not in usados_set]
    if candidatos_nuevos:
        return candidatos_nuevos[0]

    # Regla de seguridad solicitada: nunca repetir bot en C2..C{MAX_CICLOS}.
    return None

# === FIN BLOQUE 9 ===

# === BLOQUE 10 ‚Äî IA: DATASET, MODELO Y PREDICCI√ìN ===
# Cach√© y hot-reload de activos del or√°culo
_MODEL_PATH = "modelo_xgb.pkl"  # Actualizado para XGBoost
_SCALER_PATH = "scaler.pkl"
_FEATURES_PATH = "feature_names.pkl"
_META_PATH = "model_meta.json"

_ORACLE_CACHE = {
    "model": None,
    "scaler": None,
    "features": None,
    "meta": None,
    "mtimes": {}  # {path: mtime}
}
# ============================
# PATCH IA (FIX): Label can√≥nico + builder X/y ultra-robusto
# - NO asume columna 'y'
# - Filtra y a {0,1} (incluye GANANCIA/P√âRDIDA/‚úì/‚úó)
# - X por reindex => nunca KeyError
# - NaN/inf => 0.0
# ============================

# ============================
# IA ‚Äî Label can√≥nico (una sola vez)
# ============================
# ============================
# IA ‚Äî Label can√≥nico (FIX) + builder X/y ultra-robusto
# - NO asume columna 'y'
# - Filtra y a {0,1} (incluye GANANCIA/P√âRDIDA/‚úì/‚úó)
# - X por reindex => nunca KeyError
# - NaN/inf => 0.0
# ============================

LABEL_CANON = "result_bin"
LABEL_CANDIDATES = (
    "result_bin", "y", "label", "target", "resultado_bin", "result",
    "resultado", "win", "outcome"
)

def _pick_label_col_incremental(df: pd.DataFrame) -> str:
    """
    Devuelve el nombre REAL de la columna label dentro del DF (respetando el nombre original),
    aunque haya espacios/casos raros. Evita KeyError por "limpieza" de strings.
    """
    try:
        if df is None or df.empty or getattr(df, "columns", None) is None:
            return LABEL_CANON
    except Exception:
        return LABEL_CANON

    # mapa: "limpio_lower" -> "original"
    try:
        colmap = {str(c).strip().lower(): c for c in df.columns}
    except Exception:
        return LABEL_CANON

    for cand in LABEL_CANDIDATES:
        key = str(cand).strip().lower()
        if key in colmap:
            return colmap[key]

    # fallback defensivo: √∫ltima columna real del DF
    try:
        return df.columns[-1]
    except Exception:
        return LABEL_CANON

def _y_to_bin(v) -> int | None:
    """
    Normaliza cualquier cosa a {0,1}. Si no se puede interpretar, devuelve None.
    Acepta: 0/1, "0"/"1", GANANCIA/P√âRDIDA, WIN/LOSS, ‚úì/‚úó, etc.
    """
    try:
        if v is None:
            return None
        # pandas NaN
        try:
            if pd.isna(v):
                return None
        except Exception:
            pass

        # num√©rico directo
        if isinstance(v, (int, np.integer)):
            return int(v) if int(v) in (0, 1) else None
        if isinstance(v, (float, np.floating)):
            if not math.isfinite(float(v)):
                return None
            iv = int(round(float(v)))
            return iv if iv in (0, 1) else None

        s = str(v).strip()
        if s == "":
            return None

        # "0"/"1"
        if s in ("0", "1"):
            return int(s)

        # s√≠mbolos / texto (reutiliza tu normalizador)
        rn = normalizar_resultado(s)
        if rn == "GANANCIA":
            return 1
        if rn == "P√âRDIDA":
            return 0

        # extra fallback simple por si llega raro
        up = s.upper()
        if "WIN" in up or "GAN" in up:
            return 1
        if "LOSS" in up or "PERD" in up:
            return 0

        return None
    except Exception:
        return None

def construir_Xy_incremental(
    df: pd.DataFrame,
    feature_names: list | None = None
) -> tuple[pd.DataFrame, np.ndarray, str, list]:
    """
    Construye X/y sin reventar:
    - y se infiere desde la mejor columna label detectada.
    - X se reindexa a feature_names => columnas faltantes se crean (NaN->0.0).
    - NaN/inf => 0.0
    Retorna: (X_df, y_np, label_col_real, features_usadas)
    """
    feats = list(feature_names) if feature_names else list(INCREMENTAL_FEATURES_V2)

    if df is None or df.empty:
        return pd.DataFrame(columns=feats), np.array([], dtype=int), LABEL_CANON, feats

    label_col = _pick_label_col_incremental(df)

    if label_col not in df.columns:
        # fallback brutal si algo raro pas√≥
        label_col = df.columns[-1] if len(df.columns) else LABEL_CANON

    y_series = df[label_col].apply(_y_to_bin)
    mask = y_series.notna()

    if not mask.any():
        return pd.DataFrame(columns=feats), np.array([], dtype=int), label_col, feats

    df2 = df.loc[mask].copy()
    y = y_series.loc[mask].astype(int).to_numpy()

    # X por reindex => nunca KeyError
    X = df2.reindex(columns=feats)

    # numeric coercion + limpieza
    for c in feats:
        try:
            X[c] = pd.to_numeric(X[c], errors="coerce")
        except Exception:
            X[c] = np.nan

    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(float)
    return X, y, label_col, feats

def cargar_incremental_Xy(
    ruta: str = "dataset_incremental.csv",
    feature_names: list | None = None
) -> tuple[pd.DataFrame, np.ndarray, str, list]:
    """
    Loader robusto:
    - Si el incremental est√° "mutante", intenta repararlo.
    - Lee con encodings fallback.
    - Devuelve X/y listos para entrenar.
    """
    if not os.path.exists(ruta):
        feats = list(feature_names) if feature_names else list(INCREMENTAL_FEATURES_V2)
        return pd.DataFrame(columns=feats), np.array([], dtype=int), LABEL_CANON, feats

    # Reparaci√≥n preventiva (si qued√≥ mutante)
    try:
        cols = _canonical_incremental_cols(feature_names if feature_names else INCREMENTAL_FEATURES_V2)
        reparar_dataset_incremental_mutante(ruta=ruta, cols=cols)
    except Exception:
        pass

    df = None
    for enc in ("utf-8", "latin-1", "windows-1252"):
        try:
            df = pd.read_csv(ruta, sep=",", encoding=enc, engine="python", on_bad_lines="skip")
            break
        except Exception:
            continue

    if df is None or df.empty:
        feats = list(feature_names) if feature_names else list(INCREMENTAL_FEATURES_V2)
        return pd.DataFrame(columns=feats), np.array([], dtype=int), LABEL_CANON, feats

    return construir_Xy_incremental(df, feature_names=feature_names)
# === FIN PATCH IA (FIX) ===

def _coerce_label_to_01(series: pd.Series) -> pd.Series:
    """
    Convierte etiquetas a 0/1:
    - acepta 0/1 num√©rico
    - acepta strings tipo 'GANANCIA', 'P√âRDIDA', 'WIN', 'LOSS', '‚úì', '‚úó'
    - lo dem√°s => NaN
    """
    out = pd.Series(np.nan, index=series.index, dtype="float64")

    # 1) num√©rico directo (incluye "0", "1", 0.0, 1.0, True/False)
    y_num = pd.to_numeric(series, errors="coerce")
    ok01 = y_num.isin([0, 1])
    if ok01.any():
        out.loc[ok01] = y_num.loc[ok01].astype(float)

    # 2) strings/s√≠mbolos
    try:
        s = series.astype(str)
    except Exception:
        s = pd.Series([""] * len(series), index=series.index)

    def _map_one(x: str):
        try:
            raw = (x or "").strip()
            if raw == "" or raw.lower() == "nan":
                return np.nan

            # s√≠mbolos primero
            if any(sym in raw for sym in ("‚úì", "‚úî", "‚úÖ", "üü¢")):
                return 1.0
            if any(sym in raw for sym in ("‚úó", "‚ùå", "üî¥", "üü•")):
                return 0.0

            t = raw.upper()
            if "GAN" in t or "WIN" in t:
                return 1.0
            if "PERD" in t or "LOSS" in t:
                return 0.0

            # admitir "1.0" / "0.0" como texto
            try:
                v = float(raw.replace(",", "."))
                if v in (0.0, 1.0):
                    return float(int(v))
            except Exception:
                pass

            return np.nan
        except Exception:
            return np.nan

    mapped = s.map(_map_one)
    out = out.fillna(mapped)
    return out


def _enriquecer_df_con_derivadas(df: pd.DataFrame, feats: list[str]) -> pd.DataFrame:
    """Genera columnas derivadas solo si el modelo las pide."""
    try:
        out = df.copy()

        def _col_num(name, default=0.0):
            if name in out.columns:
                return pd.to_numeric(out[name], errors="coerce").fillna(default)
            return pd.Series([default] * len(out), index=out.index, dtype="float64")

        if "pay_x_puntaje" in feats:
            out["pay_x_puntaje"] = _col_num("payout", 0.0) * _col_num("puntaje_estrategia", 0.0)
        if "vol_x_breakout" in feats:
            out["vol_x_breakout"] = _col_num("volatilidad", 0.0) * _col_num("breakout", 0.0)
        if "hora_x_rebote" in feats:
            out["hora_x_rebote"] = _col_num("hora_bucket", 0.0) * _col_num("es_rebote", 0.0)
        if "racha_x_rebote" in feats:
            out["racha_x_rebote"] = _col_num("racha_actual", 0.0) * _col_num("es_rebote", 0.0)
        if "rev_x_breakout" in feats:
            out["rev_x_breakout"] = _col_num("rsi_reversion", 0.0) * _col_num("breakout", 0.0)

        if "sma_spread" in feats:
            sma5 = _col_num("sma_5", 0.0)
            sma20 = _col_num("sma_20", 0.0)
            base = sma20.abs().clip(lower=1e-9)
            out["sma_spread"] = ((sma5 - sma20).abs() / base).clip(lower=0.0, upper=5.0)

        return out
    except Exception:
        return df


def build_xy_from_incremental(df: pd.DataFrame, feature_names: list | None = None):
    """
    Builder robusto con limpieza de calidad:
    - label col can√≥nica (o fallback a √∫ltima)
    - y a {0,1} con coerci√≥n
    - anti-duplicados exactos (features+label)
    - filtro de filas con features cr√≠ticas vac√≠as (cuando hay suficiente muestra)
    - X con reindex => jam√°s KeyError
    - NaN/inf => 0.0
    Devuelve: X, y, label_col
    """
    if df is None or getattr(df, "empty", True):
        return None, None, None

    feats = list(feature_names) if feature_names else list(INCREMENTAL_FEATURES_V2)
    df = _enriquecer_df_con_derivadas(df, feats)
    label_col = _pick_label_col_incremental(df)

    # y
    try:
        y01 = _coerce_label_to_01(df[label_col])
    except Exception:
        return None, None, label_col

    mask = y01.isin([0.0, 1.0])
    if int(mask.sum()) <= 0:
        return None, None, label_col

    # Filtro de calidad para features cr√≠ticas (volatilidad/hora_bucket)
    # Solo se aplica si deja muestra suficiente para no bloquear entrenamiento.
    quality_mask = pd.Series(True, index=df.index)
    for crit in ("volatilidad", "hora_bucket"):
        if crit in df.columns:
            vv = pd.to_numeric(df[crit], errors="coerce")
            quality_mask &= vv.notna()

    if int((mask & quality_mask).sum()) >= int(max(60, 0.50 * int(mask.sum()))):
        mask = mask & quality_mask

    if int(mask.sum()) <= 0:
        return None, None, label_col

    # X (reindex = blindaje)
    X = df.reindex(columns=feats, fill_value=0.0).loc[mask].copy()
    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)

    # y final
    y = y01.loc[mask].astype(int)

    # Anti-duplicados exactos (features+label) para reducir sobreconfianza artificial
    # keep='last' favorece estado m√°s reciente cuando hay repeticiones.
    before_n = int(len(X))
    try:
        sig = X.round(6).astype(str).agg("|".join, axis=1) + "|" + y.astype(int).astype(str)
        keep = ~sig.duplicated(keep="last")
        X = X.loc[keep].copy()
        y = y.loc[keep].copy()
    except Exception:
        pass

    try:
        globals()["_LAST_XY_QUALITY"] = {
            "rows_before": before_n,
            "rows_after": int(len(X)),
            "duplicates_removed": max(0, before_n - int(len(X))),
            "used_quality_mask": bool(int((quality_mask & y01.isin([0.0, 1.0])).sum()) >= int(max(60, 0.50 * int(y01.isin([0.0, 1.0]).sum())))),
        }
    except Exception:
        pass

    return X, y, label_col

def _clean_X_df(X: pd.DataFrame) -> pd.DataFrame:
    # a num√©rico, NaN/inf => 0.0, float
    try:
        for c in X.columns:
            X[c] = pd.to_numeric(X[c], errors="coerce")
    except Exception:
        pass

    try:
        X = X.replace([np.inf, -np.inf], np.nan)
    except Exception:
        pass

    try:
        X = X.fillna(0.0)
    except Exception:
        pass

    try:
        X = X.astype("float64")
    except Exception:
        pass

    return X
    
def _build_Xy_incremental(df: pd.DataFrame, feature_names: list | None = None):
    """
    Wrapper can√≥nico (compat):
    Devuelve: X_df, y_arr, feature_names_usadas, label_col_real

    Regla:
    - Internamente usa build_xy_from_incremental (√∫nica fuente de verdad).
    - Evita entrenar si queda 1 sola clase.
    """
    feats = list(feature_names) if feature_names else list(INCREMENTAL_FEATURES_V2)

    X, y, label_col = build_xy_from_incremental(df, feats)
    if X is None or y is None:
        return None, None, feats, (label_col or LABEL_CANON)

    # Evitar entrenos falsos con una sola clase
    try:
        if len(set(np.unique(y.to_numpy()))) < 2:
            return None, None, feats, (label_col or LABEL_CANON)
    except Exception:
        pass

    X = _clean_X_df(X)
    try:
        y_arr = y.astype(int).to_numpy()
    except Exception:
        y_arr = np.asarray(y, dtype=int)

    return X, y_arr, feats, (label_col or LABEL_CANON)

# Duplicado eliminado: se usa la versi√≥n can√≥nica de _build_Xy_incremental definida arriba.
# Esto evita inconsistencias silenciosas en features/label durante entrenamiento y predicci√≥n.


# ============================================================
# COMPAT: FEATURES legacy (evita NameError en entreno)
# - Si existe dataset_incremental.csv, usa su header real
# - Si no existe, cae a FEATURE_NAMES_DEFAULT
# ============================================================
def _infer_features_from_incremental(path: str = "dataset_incremental.csv", fallback=None):
    try:
        if fallback is None:
            fallback = globals().get("FEATURE_NAMES_DEFAULT", None)

        if not os.path.exists(path):
            return list(fallback) if fallback else None

        for enc in ("utf-8", "utf-8-sig", "latin-1", "windows-1252"):
            try:
                with open(path, "r", newline="", encoding=enc, errors="replace") as f:
                    reader = csv.reader(f)
                    header = next(reader, [])
                header = [str(c).strip() for c in header if str(c).strip()]
                header = [c for c in header if c != "result_bin"]  # label fuera
                if header:
                    return header
            except Exception:
                continue

        return list(fallback) if fallback else None
    except Exception:
        return list(fallback) if fallback else None

# Si el c√≥digo viejo usa FEATURES, aqu√≠ lo blindamos:
if "FEATURES" not in globals() or not globals().get("FEATURES"):
    FEATURES = _infer_features_from_incremental(fallback=globals().get("FEATURE_NAMES_DEFAULT", None))

# √öltimo fallback ultra-defensivo
if not FEATURES:
    FEATURES = list(globals().get("FEATURE_NAMES_DEFAULT", []))

_META_CORRUPT_FLAG = False  # Nueva bandera para evitar reintentos en meta corrupto

def _safe_mtime(path):
    try:
        return os.path.getmtime(path)
    except Exception:
        return -1
def _as_list_feature_names(x):
    """Convierte feature names a list[str] de forma segura."""
    if x is None:
        return []
    if isinstance(x, list):
        return [str(a) for a in x]
    if isinstance(x, tuple):
        return [str(a) for a in list(x)]
    if isinstance(x, set):
        return [str(a) for a in list(x)]
    # string (ej: "['a','b']") no lo evaluamos; lo tratamos como 1 feature
    return [str(x)]


def _normalize_model_meta(meta: dict) -> dict:
    """
    Compatibilidad de meta:
    - rows_total -> n_samples
    - pos+neg -> n_samples (fallback)
    - crea alias n -> n_samples
    - normaliza tipos b√°sicos
    """
    if not isinstance(meta, dict):
        return {}

    m = dict(meta)

    def _to_int(v):
        try:
            return int(float(v))
        except Exception:
            return 0

    def _to_float(v):
        try:
            return float(v)
        except Exception:
            return v

    # 1) n_samples
    ns = _to_int(m.get("n_samples"))
    if ns <= 0:
        ns = _to_int(m.get("rows_total"))
    if ns <= 0:
        ns = _to_int(m.get("pos")) + _to_int(m.get("neg"))
    m["n_samples"] = ns

    # 2) alias legacy
    if _to_int(m.get("n")) <= 0:
        m["n"] = ns

    # 3) floats √∫tiles si existen
    for k in ("auc", "cv_auc", "f1", "threshold"):
        if k in m:
            m[k] = _to_float(m[k])

    # 4) reliable como bool
    m["reliable"] = bool(m.get("reliable", False))

    # 5) calibration string
    if "calibration" in m and m["calibration"] is None:
        m["calibration"] = "none"

    return m


def _resolve_oracle_feature_names(model, scaler, features, meta):
    """
    Prioridad EXACTA:
      1) scaler.feature_names_in_
      2) features (features.pkl)
      3) meta['feature_names']
      4) model.feature_names_in_ (fallback raro)
      5) None
    """
    # 1) scaler.feature_names_in_
    try:
        if scaler is not None and hasattr(scaler, "feature_names_in_"):
            fn = _as_list_feature_names(getattr(scaler, "feature_names_in_", None))
            if fn:
                return fn
    except Exception:
        pass

    # 2) features.pkl
    fn = _as_list_feature_names(features)
    if fn:
        return fn

    # 3) meta['feature_names']
    try:
        if meta and isinstance(meta, dict):
            fn = _as_list_feature_names(meta.get("feature_names"))
            if fn:
                return fn
    except Exception:
        pass

    # 4) model.feature_names_in_ (por si entrenaste con DataFrame directo al modelo)
    try:
        if model is not None and hasattr(model, "feature_names_in_"):
            fn = _as_list_feature_names(getattr(model, "feature_names_in_", None))
            if fn:
                return fn
    except Exception:
        pass

    return None


def get_oracle_assets():
    """
    Devuelve SIEMPRE: (model, scaler, features, meta)
    - model: modelo calibrado o None
    - scaler: StandardScaler o None
    - features: lista de nombres de features o None
    - meta: dict o None

    Blindaje:
    - Cache por mtime
    - Si meta se corrompe: renombra .corrupt y sigue con meta=None
    """
    changed = False
    for path in (_MODEL_PATH, _SCALER_PATH, _FEATURES_PATH, _META_PATH):
        mt = _safe_mtime(path)
        if _ORACLE_CACHE["mtimes"].get(path) != mt:
            _ORACLE_CACHE["mtimes"][path] = mt
            changed = True

    if _ORACLE_CACHE["model"] is None or changed:
        # Modelo
        try:
            _ORACLE_CACHE["model"] = joblib.load(_MODEL_PATH) if os.path.exists(_MODEL_PATH) else None
        except Exception as e:
            print(f"‚ö†Ô∏è IA: Error cargando modelo: {e}")
            _ORACLE_CACHE["model"] = None

        # Scaler
        try:
            _ORACLE_CACHE["scaler"] = joblib.load(_SCALER_PATH) if os.path.exists(_SCALER_PATH) else None
        except Exception as e:
            print(f"‚ö†Ô∏è IA: Error cargando scaler: {e}")
            _ORACLE_CACHE["scaler"] = None

        # Features
        try:
            _ORACLE_CACHE["features"] = joblib.load(_FEATURES_PATH) if os.path.exists(_FEATURES_PATH) else None
        except Exception as e:
            print(f"‚ö†Ô∏è IA: Error cargando features: {e}")
            _ORACLE_CACHE["features"] = None

        # Meta
        try:
            if os.path.exists(_META_PATH):
                with open(_META_PATH, "r", encoding="utf-8") as f:
                    _ORACLE_CACHE["meta"] = json.load(f)
            else:
                _ORACLE_CACHE["meta"] = None
        except Exception as e:
            print(f"‚ö†Ô∏è IA: Error cargando meta (archivo corrupto): {e}. Renombrando a .corrupt.")
            try:
                os.rename(_META_PATH, _META_PATH + ".corrupt")
            except Exception:
                pass
            _ORACLE_CACHE["meta"] = None

    # Normalizaci√≥n suave de features/meta (para evitar cosas raras)
    try:
        _ORACLE_CACHE["features"] = _as_list_feature_names(_ORACLE_CACHE.get("features"))
    except Exception:
        pass

    try:
        if isinstance(_ORACLE_CACHE.get("meta"), dict):
            _ORACLE_CACHE["meta"] = _normalize_model_meta(_ORACLE_CACHE["meta"])
        else:
            _ORACLE_CACHE["meta"] = None
    except Exception:
        _ORACLE_CACHE["meta"] = None

    return _ORACLE_CACHE["model"], _ORACLE_CACHE["scaler"], _ORACLE_CACHE["features"], _ORACLE_CACHE["meta"]

def oraculo_predict_visible(fila_dict):
    """
    Predicci√≥n para HUD:
    - Si hay modelo: usa oraculo_predict(modelo+scaler+meta/features)
    - Si no hay modelo y LOW_DATA_MODE: usa prob_exploratoria
    - Si no: 0.0
    """
    try:
        model, scaler, features, meta = get_oracle_assets()

        if model is not None:
            meta_local = dict(meta or {})
            fn = _resolve_oracle_feature_names(model, scaler, features, meta_local)
            if fn:
                meta_local["feature_names"] = fn
                prob = oraculo_predict(fila_dict, model, scaler, meta_local, bot_name="HUD")
                return prob, "modelo"

        # Sin modelo: fallback visual (NO opera, solo pinta)
        if LOW_DATA_MODE and contar_filas_incremental() >= MIN_FIT_ROWS_LOW:
            prob = prob_exploratoria(fila_dict)
            return prob, "low_data"

        # Modo exploraci√≥n visual si existe la bandera
        if globals().get("MODO_EXPLORACION_IA", False):
            prob = prob_exploratoria(fila_dict)
            return prob, "exp"

        return 0.0, "off"

    except Exception as e:
        print(f"‚ö†Ô∏è IA: Error en predict visible: {e}")
        return 0.0, "off"

def get_threshold_sugerido(default_=0.60):
    global _META_CORRUPT_FLAG
    try:
        meta = _ORACLE_CACHE.get("meta")
        if meta is None and not _META_CORRUPT_FLAG:
            if os.path.exists(_META_PATH):
                with open(_META_PATH, "r", encoding="utf-8") as f:
                    meta = json.load(f)
                    _ORACLE_CACHE["meta"] = meta
        thr = meta.get("threshold") if meta else None
        if isinstance(thr, (int, float)):
            return float(thr)
    except Exception as e:
        if not _META_CORRUPT_FLAG:
            print(f"‚ö†Ô∏è IA: Error en threshold sugerido (meta corrupto): {e}. Renombrando archivo y usando default.")
            try:
                os.rename(_META_PATH, _META_PATH + ".corrupt")
            except Exception:
                pass
            _META_CORRUPT_FLAG = True  # Evita reintentos
    return float(default_)

def modelo_es_reliable(default=False):
    """
    Usa meta['reliable'] si existe; respalda en default si falta el meta.
    """
    try:
        meta = _ORACLE_CACHE.get("meta")
        if not meta and os.path.exists(_META_PATH):
            with open(_META_PATH, "r", encoding="utf-8") as f:
                meta = json.load(f)
                _ORACLE_CACHE["meta"] = meta
        return bool(meta and meta.get("reliable"))
    except Exception:
        return bool(default)


# Or√°culo robusto
def oraculo_predict(fila_dict, modelo, scaler, meta, bot_name=""):
    """
    Predicci√≥n IA robusta.
    payout se trata como ROI [0..1.5].
    """
    try:
        if fila_dict is None:
            return 0.0

        feature_names = _resolve_oracle_feature_names(modelo, scaler, (meta or {}).get("feature_names"), meta or {})
        if not feature_names:
            # √∫ltimo fallback: si meta tra√≠a feature_names directo como lista
            feature_names = _as_list_feature_names((meta or {}).get("feature_names"))
        if not feature_names:
            return 0.0

        # =========================================================
        # Completar features derivados si el modelo los requiere
        # (para que inferencia = entrenamiento)
        # =========================================================
        ra = fila_dict.get("racha_actual", 0.0)
        try:
            ra = float(ra)
        except Exception:
            ra = 0.0

        if "racha_signo" in feature_names and "racha_signo" not in fila_dict:
            fila_dict["racha_signo"] = float(np.sign(ra))

        if "racha_abs" in feature_names and "racha_abs" not in fila_dict:
            fila_dict["racha_abs"] = float(abs(ra))

        if "rebote_fuerte" in feature_names and "rebote_fuerte" not in fila_dict:
            esr = fila_dict.get("es_rebote", 0.0)
            try:
                esr = float(esr)
            except Exception:
                esr = 0.0
            fila_dict["rebote_fuerte"] = 1.0 if (esr >= 0.5 and ra <= -4) else 0.0

        if "pay_x_puntaje" in feature_names and "pay_x_puntaje" not in fila_dict:
            fila_dict["pay_x_puntaje"] = float(fila_dict.get("payout", 0.0) or 0.0) * float(fila_dict.get("puntaje_estrategia", 0.0) or 0.0)

        if "vol_x_breakout" in feature_names and "vol_x_breakout" not in fila_dict:
            fila_dict["vol_x_breakout"] = float(fila_dict.get("volatilidad", 0.0) or 0.0) * float(fila_dict.get("breakout", 0.0) or 0.0)

        if "hora_x_rebote" in feature_names and "hora_x_rebote" not in fila_dict:
            fila_dict["hora_x_rebote"] = float(fila_dict.get("hora_bucket", 0.0) or 0.0) * float(fila_dict.get("es_rebote", 0.0) or 0.0)
        if "sma_spread" in feature_names and "sma_spread" not in fila_dict:
            try:
                sma5 = float(fila_dict.get("sma_5", 0.0) or 0.0)
                sma20 = float(fila_dict.get("sma_20", 0.0) or 0.0)
                sp = _calcular_sma_spread_robusto({"sma_5": sma5, "sma_20": sma20, "close": fila_dict.get("close", None)})
                fila_dict["sma_spread"] = float(sp) if sp is not None else 0.0
            except Exception:
                fila_dict["sma_spread"] = 0.0
        if "racha_x_rebote" in feature_names and "racha_x_rebote" not in fila_dict:
            fila_dict["racha_x_rebote"] = float(fila_dict.get("racha_actual", 0.0) or 0.0) * float(fila_dict.get("es_rebote", 0.0) or 0.0)
        if "rev_x_breakout" in feature_names and "rev_x_breakout" not in fila_dict:
            fila_dict["rev_x_breakout"] = float(fila_dict.get("rsi_reversion", 0.0) or 0.0) * float(fila_dict.get("breakout", 0.0) or 0.0)

        if not feature_names:
            return 0.0

        # Asegurar payout como ROI [0..1.5] (si falta, derivarlo)
        if "payout" in feature_names:
            if "payout" not in fila_dict or fila_dict.get("payout") in (None, "", 0, 0.0):
                roi_tmp = calcular_payout_feature(fila_dict)
                if roi_tmp is not None:
                    fila_dict["payout"] = roi_tmp

        # Clamp final por seguridad
        if "payout" in fila_dict:
            try:
                p = float(fila_dict["payout"])
            except Exception:
                p = 0.0
            if not math.isfinite(p):
                p = 0.0
            fila_dict["payout"] = max(0.0, min(p, 1.5))
        # Normalizar features faltantes (TRAIN vs INFER): volatilidad + hora_bucket
        try:
            fila_dict["volatilidad"] = float(calcular_volatilidad_simple(fila_dict))
        except Exception:
            fila_dict["volatilidad"] = 0.0

        try:
            hb, hm = calcular_hora_features(fila_dict)
            fila_dict["hora_bucket"] = float(hb)
            fila_dict["hora_missing"] = float(hm)
        except Exception:
            fila_dict["hora_bucket"] = 0.0
            fila_dict["hora_missing"] = 1.0

        # Armar X en orden del modelo
        X = []
        for col in feature_names:
            v = fila_dict.get(col, 0.0)
            try:
                v = float(v)
            except Exception:
                v = 0.0
            if not math.isfinite(v):
                v = 0.0
            X.append(v)

        X = np.array(X, dtype=float).reshape(1, -1)

        # Escalar si existe scaler
        if scaler is not None:
            try:
                X = scaler.transform(X)
            except Exception:
                pass

        # Predecir proba
        if hasattr(modelo, "predict_proba"):
            proba = modelo.predict_proba(X)[0][1]
        else:
            # fallback
            proba = float(modelo.predict(X)[0])

        try:
            proba = float(proba)
        except Exception:
            proba = 0.0

        if not math.isfinite(proba):
            proba = 0.0
        return max(0.0, min(proba, 1.0))

    except Exception:
        return 0.0
def prob_exploratoria(fila):
    """
    Probabilidad simple (heur√≠stica) solo para VISUAL / fallback.
    payout = ROI [0..1.5]
    """
    try:
        # payout = ROI [0..1.5] (solo visual)
        pay = calcular_payout_feature(fila)
        try:
            pay = float(pay) if pay is not None else 0.0
        except Exception:
            pay = 0.0
        if not math.isfinite(pay):
            pay = 0.0
        pay = max(0.0, min(pay, 1.5))

        def _as01_cont(v):
            try:
                x = float(v)
            except Exception:
                s = str(v).strip().lower()
                if s in ("1", "true", "yes", "y"):
                    x = 1.0
                else:
                    x = 0.0
            if not math.isfinite(x):
                x = 0.0
            return max(0.0, min(1.0, x))

        # score b√°sico (conservar simple pero continuo)
        score = 0.50
        score += 0.05 * _as01_cont(fila.get("breakout", 0.0))
        score += 0.05 * _as01_cont(fila.get("cruce_sma", 0.0))
        score += 0.04 * _as01_cont(fila.get("rsi_reversion", 0.0))

        # ROI alto ayuda un poco (sin convertir a %)
        score += (pay / 1.5) * 0.10

        if not math.isfinite(score):
            score = 0.0
        return max(0.0, min(score, 1.0))
    except Exception:
        return 0.0

# --- Nueva: leer_model_meta (blindado) ---
def leer_model_meta():
    global _META_CORRUPT_FLAG
    try:
        if _META_CORRUPT_FLAG:
            return {}

        if os.path.exists(_META_PATH):
            with open(_META_PATH, "r", encoding="utf-8") as f:
                meta = json.load(f) or {}
            if not isinstance(meta, dict):
                return {}
            return _normalize_model_meta(meta)

        return {}
    except Exception as e:
        try:
            corrupt = f"{_META_PATH}.corrupt_{int(time.time())}"
            if os.path.exists(_META_PATH):
                os.replace(_META_PATH, corrupt)
                agregar_evento(f"‚ö†Ô∏è META corrupta. Renombrada a {corrupt} ({e})")
        except Exception:
            pass
        _META_CORRUPT_FLAG = True
        return {}

# --- Nueva: guardar_model_meta (at√≥mico) ---
def guardar_model_meta(meta: dict):
    try:
        tmp = _META_PATH + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=4)
            f.flush(); os.fsync(f.fileno())
        os.replace(tmp, _META_PATH)
        _ORACLE_CACHE["meta"] = meta
    except Exception as e:
        print(f"‚ö†Ô∏è IA: Fall√≥ guardar meta: {e}")
# =========================================================
# GUARDADO AT√ìMICO DE ARTEFACTOS IA (modelo/scaler/features/meta)
# Evita corrupci√≥n y "archivos fantasma" al reiniciar.
# =========================================================
def _joblib_dump_atomic(obj, path: str):
    tmp = path + ".tmp"
    try:
        joblib.dump(obj, tmp)
        os.replace(tmp, path)
        return True
    except Exception:
        try:
            if os.path.exists(tmp):
                os.remove(tmp)
        except Exception:
            pass
        return False

def _json_dump_atomic(data: dict, path: str):
    tmp = path + ".tmp"
    try:
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
            f.flush()
            os.fsync(f.fileno())
        os.replace(tmp, path)
        return True
    except Exception:
        try:
            if os.path.exists(tmp):
                os.remove(tmp)
        except Exception:
            pass
        return False

def guardar_oracle_assets_atomico(modelo, scaler, feature_names, meta: dict | None):
    """
    Escribe de forma at√≥mica:
      - modelo_xgb.pkl   (_MODEL_PATH)
      - scaler.pkl       (_SCALER_PATH)
      - feature_names.pkl(_FEATURES_PATH)
      - model_meta.json  (_META_PATH)
    """
    def _ensure_parent(path: str):
        try:
            d = os.path.dirname(path)
            if d:
                os.makedirs(d, exist_ok=True)
        except Exception:
            pass

    def _dump_atomic(obj, path: str):
        _ensure_parent(path)
        tmp = path + ".tmp"
        joblib.dump(obj, tmp)
        os.replace(tmp, path)

    def _json_atomic(obj, path: str):
        _ensure_parent(path)
        tmp = path + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())
        os.replace(tmp, path)

    try:
        if meta is None or not isinstance(meta, dict):
            meta = {}

        # asegurar feature_names dentro de meta
        try:
            meta["feature_names"] = list(feature_names) if feature_names else []
        except Exception:
            meta["feature_names"] = []

        # compat: asegurar n_samples/n y tipos b√°sicos
        try:
            meta = _normalize_model_meta(meta)
        except Exception:
            pass

        _dump_atomic(modelo, _MODEL_PATH)
        _dump_atomic(scaler, _SCALER_PATH)
        _dump_atomic(list(feature_names) if feature_names else [], _FEATURES_PATH)
        _json_atomic(meta, _META_PATH)

        try:
            agregar_evento("üíæ IA: artefactos guardados (modelo+scaler+features+meta)")
        except Exception:
            pass

        return True

    except Exception as e:
        # limpieza best-effort de temporales si quedaron
        for p in (_MODEL_PATH, _SCALER_PATH, _FEATURES_PATH, _META_PATH):
            try:
                tmp = p + ".tmp"
                if os.path.exists(tmp):
                    os.remove(tmp)
            except Exception:
                pass

        try:
            agregar_evento(f"‚ö†Ô∏è IA: fallo guardando artefactos: {e}")
        except Exception:
            pass
        return False
     
# --- Nueva: get_prob_ia_historica (estable) ---
def get_prob_ia_historica(bot: str) -> float:
    try:
        sig = estado_bots[bot]["ia_seniales"]
        acc = estado_bots[bot]["ia_aciertos"]
        if sig >= MIN_IA_SENIALES_CONF:
            return acc / sig
        return 0.0
    except Exception:
        return 0.0

# --- Nueva: calcular_confianza_ia (para HUD) ---
def calcular_confianza_ia(bot: str, meta: dict) -> float:
    try:
        auc = float(meta.get("auc", 0.0))
        n = int(meta.get("n_samples", 0))
        reliable = bool(meta.get("reliable", False))
        sig = estado_bots[bot]["ia_seniales"]
        acc = estado_bots[bot]["ia_aciertos"]
        pct = acc / sig if sig > 0 else 0.0
        conf = (auc * 0.4) + (pct * 0.3) + (0.2 if reliable else 0.0) + (0.1 if n >= MIN_FIT_ROWS_PROD else 0.0)
        return min(1.0, max(0.0, conf))
    except Exception:
        return 0.0

# --- Nueva: get_umbral_dinamico (para audio/HUD) ---
def get_umbral_dinamico(meta: dict, base_thr: float) -> float:
    try:
        auc = float(meta.get("auc", 0.0))
        delta = max(0.0, min(0.15, (auc - 0.75) * 0.2))
        return max(0.5, base_thr - delta)
    except Exception:
        return base_thr
def get_umbral_operativo(meta: dict | None = None) -> float:
    """
    Umbral √∫nico de operaci√≥n IA (HUD, audio, selecci√≥n).

    Regla dura:
    - Si el modelo NO es confiable, si el AUC es bajo, o si hay pocos samples,
      se bloquea cualquier se√±al (umbral ~ imposible).
    """
    base_thr = get_threshold_sugerido(IA_METRIC_THRESHOLD)
    if base_thr < IA_METRIC_THRESHOLD:
        base_thr = IA_METRIC_THRESHOLD
    if base_thr < ORACULO_THR_MIN:
        base_thr = ORACULO_THR_MIN

    if meta is None:
        try:
            meta = leer_model_meta()
        except Exception:
            meta = {}

    # Meta robusta
    try:
        auc = float((meta or {}).get("auc", 0.0) or 0.0)
    except Exception:
        auc = 0.0

    try:
        reliable = bool((meta or {}).get("reliable", False))
    except Exception:
        reliable = False

    try:
        n_samples = int((meta or {}).get("n_samples", (meta or {}).get("n", 0)) or 0)
    except Exception:
        n_samples = 0

    thr = get_umbral_dinamico(meta or {}, base_thr)

    # Endurecer umbral temporal si la muestra fuerte (>=70%) a√∫n es baja.
    try:
        _, n70 = _leer_base_rate_y_n70(ttl_s=30.0)
        if int(n70) < int(IA_MIN_CLOSED_70_FOR_STRUCT):
            thr = max(float(thr), float(IA_TEMP_THR_HIGH))
    except Exception:
        pass

    # üîí BLOQUEO DE SE√ëALES CUANDO ES EXPERIMENTAL / BAJO DATOS
    MIN_AUC_GREEN = 0.55  # ‚Äúal menos no somos un dado‚Äù
    if (not reliable) or (n_samples < MIN_FIT_ROWS_PROD) or (auc < MIN_AUC_GREEN):
        return 0.99

    return thr
# =========================================================
# DISPARADOR √öNICO DE ALERTA IA (AUDIO + FLAG)
# Regla dura pedida:
#   - SOLO dispara si prob >= umbral operativo (85% m√≠nimo)
#   - Blindado contra prob en % (53) vs fracci√≥n (0.53)
#   - Cooldown + rearme por hist√©resis
# =========================================================
def _umbral_alerta_ia(meta: dict | None = None) -> float:
    """
    Umbral del aviso de audio IA (fijo, como definiste en config).
    Devuelve un float en [0..1].
    """
    try:
        thr = float(AUDIO_IA53_THR)
    except Exception:
        thr = IA_ACTIVACION_REAL_THR
    if thr < 0.0:
        thr = 0.0
    if thr > 1.0:
        thr = 1.0
    return thr

def evaluar_alerta_ia_y_disparar(bot: str, prob_ia: float, meta: dict | None = None, dentro_gatewin: bool = True):
    try:
        p = _norm_prob(prob_ia)
        thr = _umbral_alerta_ia(meta or {})

        now = time.time()

        # Rearme: si cae por debajo del umbral - hyst, se permite volver a disparar luego
        if p <= (thr - float(AUDIO_IA53_RESET_HYST)):
            IA53_TRIGGERED[bot] = False
            # limpiamos flag de se√±al pendiente si ya no califica
            estado_bots[bot]["ia_senal_pendiente"] = False
            estado_bots[bot]["ia_prob_senal"] = None
            return

        # Disparo: solo si cruza y no est√° ya disparado + respeta cooldown
        if (p >= thr) and (not IA53_TRIGGERED[bot]) and ((now - IA53_LAST_TS[bot]) >= float(AUDIO_IA53_COOLDOWN_S)):
            reproducir_evento("ia_53", es_demo=False, dentro_gatewin=dentro_gatewin)
            IA53_TRIGGERED[bot] = True
            IA53_LAST_TS[bot] = now

            # Flags para tu UI/decisi√≥n
            estado_bots[bot]["ia_senal_pendiente"] = True
            estado_bots[bot]["ia_prob_senal"] = float(p)

            # Evento claro (sin "53% suerte")
            agregar_evento(f"üîî IA: {bot} {p*100:.0f}% >= {thr*100:.0f}% | ‚úÖ ES HORA DE INVERTIR")
    except Exception:
        pass
# =========================================================
# UMBRAL VISUAL (HUD) ‚Äî usa umbral operativo (85% por configuraci√≥n)
# No depende de AUC/reliable/n_samples (eso solo bloquea "operar", no pintar).
# Evita fallos por redondeo: 0.699999 -> lo tratamos como 0.70.
# =========================================================
def _thr_visual_verde() -> float:
    try:
        return float(IA_VERDE_THR)
    except Exception:
        return IA_ACTIVACION_REAL_THR

def _thr_visual_amarillo() -> float:
    # Amarillo: zona previa (verde - 5pp)
    try:
        return max(0.0, float(_thr_visual_verde()) - 0.05)
    except Exception:
        return IA_ACTIVACION_REAL_THR

# =========================================================
# NORMALIZADOR √öNICO DE PROBABILIDAD
# Acepta: 0.53, "0.53", 53, "53", 53.0
# Devuelve SIEMPRE en rango [0..1]
# =========================================================
def _norm_prob(p) -> float:
    try:
        if p is None:
            return 0.0
        if isinstance(p, str):
            p = p.strip().replace("%", "")
            if p == "" or p.lower() == "nan":
                return 0.0
        v = float(p)
        if not math.isfinite(v):
            return 0.0

        # Si viene en "porcentaje" (ej 53), convertirlo a 0.53
        if v > 1.0:
            if v <= 100.0:
                v = v / 100.0
            else:
                v = 1.0

        if v < 0.0:
            v = 0.0
        if v > 1.0:
            v = 1.0
        return v
    except Exception:
        return 0.0

def color_prob_ia(prob: float) -> str:
    """
    Colores SOLO para HUD:
      - VERDE si prob >= 0.70
      - AMARILLO si prob >= umbral operativo
      - ROJO si menor
    Blindado: si llega 53, lo convierte a 0.53.
    """
    p = _norm_prob(prob)

    # EPS anti-borde por flotantes (0.6999999)
    EPS = 1e-9
    tv = _thr_visual_verde()
    ty = _thr_visual_amarillo()

    if p + EPS >= tv:
        return Fore.GREEN
    if p + EPS >= ty:
        return Fore.YELLOW
    return Fore.RED


def icono_prob_ia(prob: float) -> str:
    """Icono SOLO para HUD (no altera l√≥gica). Blindado a 53 vs 0.53."""
    p = _norm_prob(prob)
    EPS = 1e-9
    if p + EPS >= _thr_visual_verde():
        return "üü¢"
    if p + EPS >= _thr_visual_amarillo():
        return "üü°"
    return "üî¥"

# --- Nueva: anexar_incremental_desde_bot (completa 3 features + anti-duplicados) ---
def anexar_incremental_desde_bot(bot: str):
    """
    Anexa 1 fila al dataset incremental usando:
    - label (GANANCIA/P√âRDIDA) del √∫ltimo trade CERRADO
    - features del PRE_TRADE emparejado por epoch (evita leakage)
    Con lock cross-proceso y anti-duplicados por firma.
    """
    try:
        fila_dict, label = leer_ultima_fila_con_resultado(bot)
        if fila_dict is None or label is None:
            return

        try:
            label = int(label)
        except Exception:
            return
        if label not in (0, 1):
            return

        feature_names = list(INCREMENTAL_FEATURES_V2)
        cols = feature_names + ["result_bin"]
        ruta_inc = "dataset_incremental.csv"

        # Construir row completo + features derivadas (volatilidad/hora_bucket)
        row_dict_full = dict(fila_dict)
        row_dict_full["result_bin"] = label

        # 1) Volatilidad: prioriza valor ya enriquecido; recalcula solo si falta/inv√°lido.
        vol_calc = None
        try:
            v0 = row_dict_full.get("volatilidad", None)
            if v0 not in (None, ""):
                v0 = float(v0)
                if math.isfinite(v0) and v0 >= 0.0:
                    vol_calc = float(v0)
        except Exception:
            vol_calc = None

        if vol_calc is None:
            try:
                v1 = float(calcular_volatilidad_simple(row_dict_full))
                if math.isfinite(v1) and v1 >= 0.0:
                    vol_calc = float(v1)
            except Exception:
                vol_calc = None

        if vol_calc is None or vol_calc <= 0.0:
            try:
                vol_hist = calcular_volatilidad_por_bot(bot, lookback=50)
                if vol_hist is not None and math.isfinite(float(vol_hist)) and float(vol_hist) >= 0.0:
                    vol_calc = float(vol_hist)
            except Exception:
                pass

        # No matar incremental por vol no disponible: conservar fila y dejar traza.
        if (vol_calc is None) or (not math.isfinite(float(vol_calc))):
            vol_calc = 0.0
            agregar_evento(f"‚ö†Ô∏è Incremental: volatilidad no disponible ({bot}); se guarda fila con vol=0.0")
        row_dict_full["volatilidad"] = float(max(0.0, min(float(vol_calc), 1.0)))

        # 2) Hora bucket: prioriza valor ya enriquecido; fallback a parseo y luego hora actual.
        hb = None
        hm = 0.0
        try:
            hb0 = row_dict_full.get("hora_bucket", None)
            if hb0 not in (None, ""):
                hb0 = float(hb0)
                if math.isfinite(hb0):
                    hb = float(max(0.0, min(1.0, hb0)))
                    hm = 0.0
        except Exception:
            hb = None

        if hb is None:
            try:
                hb1, hm1 = calcular_hora_features(row_dict_full)
                hb1 = float(hb1)
                hm1 = float(hm1)
                if math.isfinite(hb1) and hm1 < 1.0:
                    hb = float(max(0.0, min(1.0, hb1)))
                    hm = float(hm1)
            except Exception:
                hb = None

        if hb is None:
            # fallback final: hora local actual (no descartar fila por timestamp faltante)
            lt = time.localtime()
            idx48 = int(lt.tm_hour * 2 + (1 if lt.tm_min >= 30 else 0))
            hb = float(max(0, min(47, idx48))) / 47.0
            hm = 1.0
            agregar_evento(f"‚ö†Ô∏è Incremental: hora no parseable ({bot}); fallback hora actual aplicado")

        row_dict_full["hora_bucket"] = float(max(0.0, min(1.0, float(hb))))
        row_dict_full["hora_missing"] = float(hm)

        # Clip + validar
        row_dict_full = clip_feature_values(row_dict_full, feature_names)
        ok, reason = validar_fila_incremental(row_dict_full, feature_names)
        if not ok:
            agregar_evento(f"‚ö†Ô∏è Incremental: fila descartada ({bot}) => {reason}")
            return

        # Firma anti-dup
        row_vals_sig = []
        for k in feature_names:
            v = row_dict_full.get(k, 0.0)
            try:
                v = float(v)
            except Exception:
                v = 0.0
            row_vals_sig.append(str(round(v, 6)))
        sig = "|".join(row_vals_sig) + "|" + str(label)

        last_sig = _load_last_sig(bot)
        if last_sig == sig:
            return

        try:
            huellas_usadas.setdefault(bot, set())
            if sig in huellas_usadas[bot]:
                return
        except Exception:
            pass

        max_retries = 8
        for attempt in range(max_retries):
            try:
                # LOCK √öNICO: mismo que maybe_retrain/backfill
                with file_lock("inc.lock"):
                    # Repara incremental mutante antes de escribir
                    try:
                        repaired = reparar_dataset_incremental_mutante(ruta=ruta_inc, cols=cols)
                        if repaired:
                            agregar_evento("üßπ IA: dataset_incremental reparado (mutante).")
                    except Exception:
                        pass

                    need_header = (not os.path.exists(ruta_inc)) or (os.path.getsize(ruta_inc) == 0)

                    with open(ruta_inc, "a", newline="", encoding="utf-8") as f:
                        writer = csv.DictWriter(f, fieldnames=cols, extrasaction="ignore")
                        if need_header:
                            writer.writeheader()
                        writer.writerow(row_dict_full)
                        f.flush()
                        os.fsync(f.fileno())

                # Marcar firma solo si escribimos OK
                try:
                    huellas_usadas.setdefault(bot, set()).add(sig)
                except Exception:
                    pass
                _save_last_sig(bot, sig)

                # Log con throttle (1/min por bot) para que lo VEAS sin spamear
                try:
                    d = globals().setdefault("_INC_LAST_LOG_TS", {})
                    now = time.time()
                    if now - float(d.get(bot, 0.0)) >= 60.0:
                        d[bot] = now
                        agregar_evento(f"‚úÖ Incremental: +1 fila desde {bot} ({'G' if label == 1 else 'P'}).")
                except Exception:
                    pass

                return

            except PermissionError:
                time.sleep(0.15 + 0.10 * attempt)
                continue
            except Exception as e:
                agregar_evento(f"‚ö†Ô∏è Incremental: excepci√≥n anexar ({bot}) => {type(e).__name__}: {e}")
                return

    except Exception as e:
        agregar_evento(f"‚ö†Ô∏è Incremental: excepci√≥n outer ({bot}) => {type(e).__name__}: {e}")
        return

# --- Nueva: maybe_retrain (con validaciones) ---
def _seleccionar_features_utiles_train(X_df: pd.DataFrame, feats: list[str]):
    """
    Reduce ruido de variables casi constantes/redundantes antes del fit.
    Mantiene al menos 6 columnas para evitar colapsar el modelo.
    """
    try:
        X = X_df.copy()
        keep = []
        dropped = []
        n = max(1, len(X))

        for c in feats:
            if c not in X.columns:
                dropped.append((c, "missing"))
                continue
            s = pd.to_numeric(X[c], errors="coerce").fillna(0.0)
            vc = s.value_counts(dropna=False)
            top_ratio = (float(vc.iloc[0]) / float(n)) if len(vc) else 1.0
            nun = int(s.nunique(dropna=False))
            if nun <= 1:
                dropped.append((c, f"ROTA:nunique={nun}"))
            elif top_ratio > float(FEATURE_MAX_DOMINANCE):
                dropped.append((c, f"CASI_CONSTANTE:dom={top_ratio:.3f}"))
            else:
                keep.append(c)

        # Evitar colinealidad extrema en SMA
        if ("sma_5" in keep) and ("sma_spread" in keep):
            try:
                corr = abs(pd.to_numeric(X["sma_5"], errors="coerce").fillna(0.0).corr(
                    pd.to_numeric(X["sma_spread"], errors="coerce").fillna(0.0)
                ))
                if pd.notna(corr) and float(corr) >= 0.9999:
                    keep.remove("sma_spread")
                    dropped.append(("sma_spread", f"collinear({corr:.5f})"))
            except Exception:
                pass

        if len(keep) < 1:
            keep = list(feats)
            dropped = []

        return X[keep].copy(), list(keep), dropped
    except Exception:
        return X_df, list(feats), []


def _seleccionar_features_calidad(X_df: pd.DataFrame, y_arr: np.ndarray, feats: list[str]):
    """
    Selecci√≥n calidad-first (sin fuga temporal):
    - Conserva siempre FEATURE_ALWAYS_KEEP si existen.
    - Eval√∫a dominancia + AUC univariado SOLO en la ventana de entrenamiento.
    - Exige estabilidad temporal b√°sica (mitad temprana vs mitad reciente del train).
    - Limita el set productivo para reducir ruido y sobreajuste.
    """
    try:
        if X_df is None or X_df.empty:
            return list(feats), []

        y = np.asarray(y_arr).astype(int)
        selected = []
        report = []
        scored = []

        n_all = len(X_df)
        cut = max(1, n_all // 2)

        for c in feats:
            if c not in X_df.columns:
                report.append((c, "missing"))
                continue

            s = pd.to_numeric(X_df[c], errors="coerce").fillna(0.0)
            nun = int(s.nunique(dropna=False))
            vc = s.value_counts(dropna=False)
            dom = float(vc.iloc[0]) / float(max(1, len(s))) if len(vc) else 1.0

            auc_uni = 0.5
            auc_delta = 0.0
            auc_early = 0.5
            auc_late = 0.5
            stable = False
            ok_auc = False
            try:
                if nun > 1 and len(np.unique(y)) == 2:
                    auc_uni = float(roc_auc_score(y, s.values))
                    auc_uni = max(min(auc_uni, 1.0), 0.0)
                    auc_delta = abs(auc_uni - 0.5)
                    ok_auc = True

                    y_early = y[:cut]
                    x_early = s.values[:cut]
                    y_late = y[cut:]
                    x_late = s.values[cut:]

                    early_has_2c = bool(len(y_early) >= 20 and len(np.unique(y_early)) == 2)
                    late_has_2c = bool(len(y_late) >= 20 and len(np.unique(y_late)) == 2)

                    if early_has_2c:
                        auc_early = float(roc_auc_score(y_early, x_early))
                    if late_has_2c:
                        auc_late = float(roc_auc_score(y_late, x_late))

                    d1 = abs(auc_early - 0.5)
                    d2 = abs(auc_late - 0.5)

                    # Regla anti-colapso: si una mitad no tiene ambas clases,
                    # no penalizar estabilidad por ese lado (muestra insuficiente).
                    if early_has_2c and late_has_2c:
                        stable = (d1 >= float(FEATURE_MIN_AUC_DELTA) * 0.60 and d2 >= float(FEATURE_MIN_AUC_DELTA) * 0.60)
                    elif early_has_2c or late_has_2c:
                        stable = (auc_delta >= float(FEATURE_MIN_AUC_DELTA))
                    else:
                        stable = True
            except Exception:
                pass

            if c in FEATURE_ALWAYS_KEEP:
                selected.append(c)
                report.append((c, f"KEEP_CORE dom={dom:.3f} auc={auc_uni:.4f}"))
                continue

            if nun <= 1:
                report.append((c, f"DROP nunique={nun}"))
                continue
            if dom > float(FEATURE_MAX_DOMINANCE_GATE):
                report.append((c, f"DROP dom={dom:.3f}"))
                continue

            if ok_auc and auc_delta >= float(FEATURE_MIN_AUC_DELTA) and stable:
                scored.append((auc_delta, c, dom, auc_uni, auc_early, auc_late))
            else:
                report.append((c, f"SHADOW auc_delta={auc_delta:.4f} early={auc_early:.4f} late={auc_late:.4f} dom={dom:.3f}"))

        scored.sort(reverse=True, key=lambda t: t[0])
        max_extra = max(0, int(FEATURE_MAX_PROD) - len(selected))
        for auc_delta, c, dom, auc_uni, auc_early, auc_late in scored[:max_extra]:
            selected.append(c)
            report.append((c, f"KEEP auc_delta={auc_delta:.4f} early={auc_early:.4f} late={auc_late:.4f} dom={dom:.3f} auc={auc_uni:.4f}"))

        if not selected:
            fallback = [f for f in FEATURE_ALWAYS_KEEP if f in X_df.columns]
            if not fallback and feats:
                fallback = [feats[0]]
            selected = fallback

        return selected, report
    except Exception:
        return list(feats), []


def _auditar_salud_features(X_df: pd.DataFrame, feats: list[str]):
    """Audita variaci√≥n/dominancia por feature para decidir si entrena o se congela."""
    out = {}
    try:
        n = max(1, len(X_df))
        for c in feats:
            if c not in X_df.columns:
                out[c] = {"nunique": 0, "dominance": 1.0, "status": "MISSING"}
                continue
            s = pd.to_numeric(X_df[c], errors="coerce").fillna(0.0)
            nun = int(s.nunique(dropna=False))
            vc = s.value_counts(dropna=False)
            dom = (float(vc.iloc[0]) / float(n)) if len(vc) else 1.0
            if nun <= 1:
                status = "ROTA"
            elif dom > float(FEATURE_MAX_DOMINANCE):
                status = "CASI_CONSTANTE"
            else:
                status = "OK"
            out[c] = {"nunique": nun, "dominance": float(dom), "status": status}
    except Exception:
        return {}
    return out


def _dataset_quality_gate_for_training(X_df: pd.DataFrame, feats: list[str]):
    """
    Gate de calidad m√≠nimo para entrenamiento IA.
    Retorna: (ok: bool, reasons: list[str], health: dict)
    """
    reasons = []
    health = {}
    try:
        if X_df is None or X_df.empty:
            return False, ["dataset_vacio"], {}

        n_rows = int(len(X_df))
        min_rows = int(max(4, MIN_FIT_ROWS_LOW))
        if n_rows < min_rows:
            reasons.append(f"filas_insuficientes:{n_rows}<{min_rows}")

        health = _auditar_salud_features(X_df, feats)
        if not isinstance(health, dict) or not health:
            reasons.append("health_unavailable")
            return (len(reasons) == 0), reasons, (health if isinstance(health, dict) else {})

        n_ok = 0
        n_bad = 0
        dom_hot = 0
        for c in feats:
            rep = health.get(c, {}) if isinstance(health.get(c, {}), dict) else {}
            st = str(rep.get("status", "")).upper()
            dom = float(rep.get("dominance", 1.0) or 1.0)
            if st == "OK":
                n_ok += 1
            else:
                n_bad += 1
            if dom >= float(FEATURE_MAX_DOMINANCE):
                dom_hot += 1

        # Exigimos al menos una base de columnas √∫tiles para entrenar sin colapsar.
        min_ok = max(3, min(6, len(feats)))
        if n_ok < min_ok:
            reasons.append(f"features_ok_bajas:{n_ok}<{min_ok}")

        # Si casi todo est√° casi-constante, bloqueamos para evitar entrenos basura.
        if len(feats) > 0 and dom_hot >= max(1, int(len(feats) * 0.8)):
            reasons.append(f"dominancia_alta:{dom_hot}/{len(feats)}")

        return len(reasons) == 0, reasons, health
    except Exception as e:
        reasons.append(f"dq_gate_error:{type(e).__name__}")
        return False, reasons, (health if isinstance(health, dict) else {})


def _fingerprint_features_row(row: dict, feats: list[str] | None = None, decimals: int = INPUT_DUP_FINGERPRINT_DECIMALS) -> str:
    """Huella estable por bot/tick para detectar inputs duplicados entre bots."""
    base_feats = list(feats) if feats else list(INCREMENTAL_FEATURES_V2)
    base_feats = _features_vivas_para_redundancia(base_feats)
    parts = []
    for k in base_feats:
        v = (row or {}).get(k, 0.0)
        try:
            vf = float(v)
            if not np.isfinite(vf):
                vf = 0.0
        except Exception:
            vf = 0.0
        parts.append(f"{k}={round(vf, int(decimals))}")
    return "|".join(parts)


def _features_vivas_para_redundancia(base_feats: list[str]) -> list[str]:
    """Usa features activas del modelo, evitando filtrar de m√°s por metadatos viejos."""
    try:
        base = list(base_feats)

        # 1) Priorizar feature_names.pkl (estado real m√°s reciente del modelo)
        model_feats = None
        try:
            fpath = globals().get("_FEATURES_PATH", "feature_names.pkl")
            if os.path.exists(fpath):
                raw = joblib.load(fpath)
                if isinstance(raw, (list, tuple)):
                    mf = [str(x) for x in raw if str(x).strip()]
                    if len(mf) >= 4:
                        model_feats = mf
        except Exception:
            model_feats = None

        # 2) Fallback a meta
        if not model_feats:
            meta = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
            mf = meta.get("feature_names", []) if isinstance(meta, dict) else []
            if isinstance(mf, list) and len(mf) >= 4:
                model_feats = [str(x) for x in mf if str(x).strip()]

        if not model_feats:
            return base

        # 3) Excluir solo features expl√≠citamente rotas
        health = {}
        try:
            meta2 = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
            health = meta2.get("feature_health", {}) if isinstance(meta2, dict) else {}
        except Exception:
            health = {}

        out = []
        for c in base:
            if c not in model_feats:
                continue
            st = str((health.get(c, {}) if isinstance(health, dict) else {}).get("status", "OK") or "OK").upper()
            if st == "ROTA":
                continue
            out.append(c)

        # Anti-colapso: no degradar redundancia a 1-2 columnas por metadata stale.
        return out if len(out) >= 4 else base
    except Exception:
        return list(base_feats)


def _diagnosticar_inputs_duplicados(rows_by_bot: dict, dup_bots: list[str], feats: list[str] | None = None) -> dict:
    """Diagn√≥stico compacto de columnas id√©nticas/variables en grupos duplicados."""
    base_feats = list(feats) if feats else list(INCREMENTAL_FEATURES_V2)
    base_feats = _features_vivas_para_redundancia(base_feats)
    same_cols, diff_cols = [], []

    for c in base_feats:
        vals = []
        for b in dup_bots:
            rv = rows_by_bot.get(b, {}) or {}
            try:
                vals.append(round(float(rv.get(c, 0.0) or 0.0), int(INPUT_DUP_FINGERPRINT_DECIMALS)))
            except Exception:
                vals.append(0.0)
        if len(set(vals)) <= 1:
            same_cols.append(c)
        else:
            diff_cols.append(c)

    expected_pref = ["payout", "rsi_9", "rsi_14", "sma_5", "sma_spread", "volatilidad", "hora_bucket"]
    expected_diff = [c for c in expected_pref if c in base_feats]
    source_info = {}
    for b in dup_bots:
        rv = rows_by_bot.get(b, {}) or {}
        source_info[b] = {
            "path": str(rv.get("__src_path", "")),
            "ts": str(rv.get("__src_ts", rv.get("__src_epoch", ""))),
            "hash": str(rv.get("__src_row_hash", "")),
            "symbol": str(rv.get("__src_symbol", "")),
        }
    return {
        "same_cols": same_cols,
        "diff_cols": diff_cols,
        "expected_diff": expected_diff,
        "source_info": source_info,
    }


def _hay_modelo_ia_disponible() -> bool:
    """Chequea si hay modelo utilizable en cache o disco."""
    try:
        _load_ia_assets_once(force=False)
        if _IA_ASSETS_CACHE.get("model") is not None:
            return True
    except Exception:
        pass
    try:
        mfile = globals().get("_MODEL_PATH", "modelo_xgb.pkl")
        return bool(os.path.exists(mfile))
    except Exception:
        return False


def _maybe_retrain_fallback_sklearn(force: bool = False):
    """Fallback cuando XGBoost no est√° disponible: entrena LogisticRegression calibrada."""
    try:
        ruta = "dataset_incremental.csv"
        if not os.path.exists(ruta):
            agregar_evento("‚ö†Ô∏è IA fallback: dataset_incremental.csv no existe a√∫n.")
            return False
        df = pd.read_csv(ruta, sep=",", encoding="utf-8", engine="python", on_bad_lines="skip")
        if df is None or df.empty:
            agregar_evento("‚ö†Ô∏è IA fallback: dataset incremental vac√≠o.")
            return False

        if "result_bin" not in df.columns:
            agregar_evento("‚ö†Ô∏è IA fallback: falta result_bin en incremental.")
            return False

        y = pd.to_numeric(df["result_bin"], errors="coerce")
        mask = y.isin([0, 1])
        if int(mask.sum()) < int(MIN_FIT_ROWS_LOW):
            agregar_evento(f"‚ö†Ô∏è IA fallback: poca data √∫til ({int(mask.sum())}).")
            return False

        feats = [f for f in FEATURE_NAMES_DEFAULT if f in df.columns]
        if not feats:
            feats = [f for f in INCREMENTAL_FEATURES_V2 if f in df.columns]
        if not feats:
            reserved = {"result_bin", "resultado", "resultado_norm", "trade_status", "trade_status_norm"}
            cand = []
            for c in df.columns:
                if c in reserved:
                    continue
                try:
                    sc = pd.to_numeric(df[c], errors="coerce")
                    if int(sc.notna().sum()) >= max(6, int(len(df) * 0.20)):
                        cand.append(c)
                except Exception:
                    continue
            feats = cand[:20]
        if not feats:
            agregar_evento("‚ö†Ô∏è IA fallback: no hay features num√©ricas utilizables en incremental.")
            return False

        X = df.loc[mask, feats].copy()
        yb = y.loc[mask].astype(int).values
        X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)

        # Si solo hay una clase, no se puede entrenar
        if len(set(list(yb))) < 2:
            agregar_evento("‚ö†Ô∏è IA fallback: una sola clase √∫til; esperando m√°s cierres.")
            return False

        scaler = StandardScaler()
        Xs = scaler.fit_transform(X)

        clf = LogisticRegression(max_iter=800, class_weight="balanced")
        clf.fit(Xs, yb)

        try:
            p = clf.predict_proba(Xs)[:, 1]
            auc = float(roc_auc_score(yb, p)) if len(set(yb)) > 1 else 0.0
            brier = float(brier_score_loss(yb, p))
        except Exception:
            auc = 0.0
            brier = 0.0

        meta = {
            "trained_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "n_samples": int(len(X)),
            "pos": int(np.sum(yb == 1)),
            "neg": int(np.sum(yb == 0)),
            "auc": float(auc),
            "brier": float(brier),
            "threshold": float(THR_DEFAULT),
            "reliable": bool(len(X) >= int(MIN_FIT_ROWS_PROD)),
            "warmup_mode": bool(len(X) < int(TRAIN_WARMUP_MIN_ROWS)),
            "feature_names": list(feats),
            "model_family": "sklearn_logreg_fallback",
        }

        ok_save = False
        if "guardar_oracle_assets_atomico" in globals() and callable(guardar_oracle_assets_atomico):
            ok_save = bool(guardar_oracle_assets_atomico(clf, scaler, list(feats), meta))
        else:
            model_path = globals().get("_MODEL_PATH", "modelo_xgb.pkl")
            scaler_path = globals().get("_SCALER_PATH", "scaler.pkl")
            feats_path = globals().get("_FEATURES_PATH", "feature_names.pkl")
            meta_path = globals().get("_META_PATH", "model_meta.json")
            joblib.dump(clf, model_path)
            joblib.dump(scaler, scaler_path)
            joblib.dump(list(feats), feats_path)
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, ensure_ascii=False, indent=2)
            ok_save = True

        if ok_save:
            _IA_ASSETS_CACHE["loaded"] = False
            agregar_evento(f"‚úÖ IA fallback entrenada (LogReg) n={len(X)} AUC={auc:.3f}")
            return True
        return False
    except Exception as e:
        agregar_evento(f"‚ö†Ô∏è IA fallback fall√≥: {type(e).__name__}")
        return False


def maybe_retrain(force: bool = False):
    """
    Reentreno IA HONESTO (sin fuga temporal) + uso REAL de TimeSeriesSplit.

    - Split temporal: TRAIN_BASE (pasado) / CALIB (m√°s reciente) / TEST (√∫ltimo)
    - StandardScaler FIT SOLO en TRAIN_BASE
    - Calibraci√≥n SIN reentrenar base (sigmoid/isotonic) usando ModeloXGBCalibrado
    - TimeSeriesSplit sobre TRAIN_BASE para CV AUC (diagn√≥stico, no toca el split final)
    - Guardado at√≥mico: modelo_xgb.pkl, scaler.pkl, feature_names.pkl, model_meta.json
    """
    global last_retrain_count, last_retrain_ts, _ORACLE_CACHE, LAST_RETRAIN_ERROR

    LAST_RETRAIN_ERROR = ""

    # 0) XGBoost disponible
    if not _XGBOOST_OK or xgb is None:
        try:
            agregar_evento("‚ö†Ô∏è IA: xgboost no disponible. Activando fallback sklearn.")
        except Exception:
            pass
        return _maybe_retrain_fallback_sklearn(force=force)

    # 1) Anti re-entrada
    if not _entrenando_lock.acquire(blocking=False):
        return False

    try:
        now = time.time()

        # 2) Gatillos por filas/tiempo
        filas = contar_filas_incremental()

        if not force:
            new_rows = max(0, int(filas) - int(last_retrain_count or 0))
            mins = (now - float(last_retrain_ts or 0.0)) / 60.0
            modelo_presente = _hay_modelo_ia_disponible()

            # Si no hay modelo a√∫n, reintentar entrenamiento aunque no se cumplan gatillos de filas/tiempo.
            if modelo_presente:
                if new_rows >= int(RETRAIN_INTERVAL_ROWS):
                    pass
                else:
                    if mins >= float(RETRAIN_INTERVAL_MIN) and new_rows >= int(MIN_NEW_ROWS_FOR_TIME):
                        pass
                    else:
                        return False

        # 3) Reparar incremental si qued√≥ ‚Äúmutante‚Äù + leer incremental (con LOCK)
        ruta_inc = "dataset_incremental.csv"
        if not os.path.exists(ruta_inc):
            try:
                agregar_evento("‚ö†Ô∏è IA: dataset_incremental.csv no existe a√∫n. Esperando backfill incremental.")
            except Exception:
                pass
            return False
        try:
            with file_lock("inc.lock"):
                try:
                    reparar_dataset_incremental_mutante(
                        ruta=ruta_inc,
                        cols=_canonical_incremental_cols(INCREMENTAL_FEATURES_V2)
                    )
                except Exception:
                    pass

                df = None
                for enc in ("utf-8", "utf-8-sig", "latin-1", "windows-1252"):
                    try:
                        df = pd.read_csv(ruta_inc, encoding=enc, engine="python", on_bad_lines="skip")
                        break
                    except Exception:
                        continue
        except Exception:
            df = None

        if df is None or df.empty:
            return False

        # 4) Construir X/y robusto (usa tus builders)
        feats_pref = list(INCREMENTAL_FEATURES_V2)

        X, y, feats_used, label_col = _build_Xy_incremental(df, feature_names=feats_pref)
        if X is None or y is None or feats_used is None:
            return False

        # Telemetr√≠a de limpieza (dedup + calidad m√≠nima) para diagn√≥stico en vivo.
        try:
            q = globals().get("_LAST_XY_QUALITY", {}) or {}
            dup_rm = int(q.get("duplicates_removed", 0) or 0)
            rb = int(q.get("rows_before", len(X)) or len(X))
            ra = int(q.get("rows_after", len(X)) or len(X))
            if dup_rm > 0:
                sig_clean = f"{dup_rm}:{rb}->{ra}"
                last_clean = globals().get("_IA_TRAIN_CLEAN_LOG", {}) or {}
                now_clean = time.time()
                should_clean_log = (
                    sig_clean != str(last_clean.get("sig", "")) or
                    (now_clean - float(last_clean.get("ts", 0.0) or 0.0)) >= 25.0
                )
                if should_clean_log:
                    agregar_evento(f"üßπ IA train-clean: dedup {dup_rm} filas ({rb}->{ra}).")
                    globals()["_IA_TRAIN_CLEAN_LOG"] = {"sig": sig_clean, "ts": now_clean}
        except Exception:
            pass

        # 4.1) Auditor√≠a de salud (variaci√≥n + dominancia) y descarte temporal
        health_before = _auditar_salud_features(X, feats_used)

        # 4.1.b) Data quality gate (si dataset no respira, no entrenar)
        dq_ok, dq_reasons, dq_health = _dataset_quality_gate_for_training(X, feats_used)
        health_before = dq_health if isinstance(dq_health, dict) and dq_health else health_before
        if not dq_ok:
            try:
                agregar_evento(f"üõë IA DATA QUALITY: entrenamiento bloqueado ({'; '.join(dq_reasons)}).")
            except Exception:
                pass
            # Si no existe ning√∫n modelo, intentar fallback simple para salir de OFF.
            if not _hay_modelo_ia_disponible():
                return _maybe_retrain_fallback_sklearn(force=True)
            return False

        # 4.2) Reducir features casi constantes/redundantes para subir eficiencia real
        X, feats_used, dropped_feats = _seleccionar_features_utiles_train(X, feats_used)
        if dropped_feats:
            try:
                txt = ", ".join([f"{k}:{r}" for k, r in dropped_feats[:8]])
                agregar_evento(f"üß™ IA: features filtradas pre-fit ({len(dropped_feats)}): {txt}")
            except Exception:
                pass

        # 4.3) Selecci√≥n din√°mica de calidad (features_prod vs shadow)
        freeze_core_warmup = bool(FEATURE_FREEZE_CORE_DURING_WARMUP) and (len(X) < int(FEATURE_FREEZE_CORE_MIN_ROWS))
        if FEATURE_DYNAMIC_SELECTION and (not freeze_core_warmup):
            try:
                feats_quality, quality_report = _seleccionar_features_calidad(X, y, feats_used)
                feats_quality = [c for c in feats_quality if c in X.columns]
                if feats_quality:
                    X = X[feats_quality].copy()
                    feats_used = list(feats_quality)

                    globals()["FEATURE_NAMES_PROD"] = list(feats_used)
                    globals()["FEATURE_NAMES_SHADOW"] = [f for f in FEATURE_NAMES_CORE_13 if f not in feats_used]

                    if quality_report:
                        txt = ", ".join([f"{k}:{r}" for k, r in quality_report[:8]])
                        agregar_evento(f"üéØ IA quality-gate: prod={feats_used} | {txt}")
            except Exception:
                pass
        elif freeze_core_warmup:
            try:
                keep_core = [f for f in FEATURE_NAMES_CORE_13 if f in X.columns]
                if keep_core:
                    X = X[keep_core].copy()
                    feats_used = list(keep_core)
                    globals()["FEATURE_NAMES_PROD"] = list(feats_used)
                    globals()["FEATURE_NAMES_SHADOW"] = [f for f in FEATURE_NAMES_CORE_13 if f not in feats_used]
                    agregar_evento(f"üß± IA warmup: freeze CORE ({len(feats_used)} feats) hasta n>={int(FEATURE_FREEZE_CORE_MIN_ROWS)}.")
            except Exception:
                pass

        # 4.4) Capa de madurez: evitar colapso a 1 feature durante warmup.
        try:
            n_rows_cur = int(len(X))
            if n_rows_cur < int(FEATURE_SET_CORE_EXT_MIN_ROWS):
                pref = [f for f in FEATURE_SET_PROD_WARMUP if f in X.columns]
                if len(pref) >= 3:
                    X = X[pref].copy()
                    feats_used = list(pref)
                    globals()["FEATURE_NAMES_PROD"] = list(feats_used)
                    globals()["FEATURE_NAMES_SHADOW"] = [f for f in FEATURE_NAMES_CORE_13 if f not in feats_used]
                    agregar_evento(f"üß© IA capa warmup: prod={feats_used} (n={n_rows_cur}).")
            else:
                pref_ext = [f for f in FEATURE_SET_CORE_EXT if f in X.columns]
                if len(pref_ext) >= 5:
                    X = X[pref_ext].copy()
                    feats_used = list(pref_ext)
                    globals()["FEATURE_NAMES_PROD"] = list(feats_used)
                    globals()["FEATURE_NAMES_SHADOW"] = [f for f in FEATURE_NAMES_CORE_13 if f not in feats_used]
        except Exception:
            pass

        # 5) Recorte a MAX_DATASET_ROWS (manteniendo orden temporal)
        try:
            if int(MAX_DATASET_ROWS) > 0 and len(X) > int(MAX_DATASET_ROWS):
                X = X.iloc[-int(MAX_DATASET_ROWS):].copy()
                y = np.asarray(y)[-int(MAX_DATASET_ROWS):]
        except Exception:
            pass

        n_total = len(X)
        if n_total < int(MIN_FIT_ROWS_LOW):
            try:
                agregar_evento(f"‚ö†Ô∏è IA: muy poca data ({n_total}). M√≠nimo={MIN_FIT_ROWS_LOW}.")
            except Exception:
                pass
            return False

        # 5.1) Guardia anti-colapso de dataset:
        # evita machacar un modelo sano cuando el incremental se resetea/parcializa
        # y moment√°neamente quedan muy pocas filas √∫tiles (p.ej. n=6).
        if not force:
            try:
                meta_prev = leer_model_meta() or {}
                prev_n = int(meta_prev.get("n_samples", meta_prev.get("rows_total", meta_prev.get("n", 0))) or 0)
                prev_reliable = bool(meta_prev.get("reliable", False))
                drop_floor = int(max(MIN_FIT_ROWS_PROD, round(float(prev_n) * float(TRAIN_ROWS_DROP_GUARD_RATIO))))
                collapse_guard_on = bool((prev_n >= int(TRAIN_ROWS_DROP_GUARD_MIN_PREV)) or prev_reliable)

                if collapse_guard_on and (int(n_total) < int(drop_floor)):
                    try:
                        agregar_evento(
                            f"üõ°Ô∏è IA: NO actualizo (muestra cay√≥ {prev_n}->{n_total}; m√≠nimo guard={drop_floor})."
                        )
                    except Exception:
                        pass
                    return False
            except Exception:
                pass

        # 6) Corte duro: una sola clase -> no entrenar
        try:
            pos = int(np.sum(np.asarray(y) == 1))
            neg = int(np.sum(np.asarray(y) == 0))
            if pos == 0 or neg == 0:
                try:
                    agregar_evento(f"‚ö†Ô∏è IA: solo una clase (pos={pos}, neg={neg}). Skip.")
                except Exception:
                    pass
                return False
        except Exception:
            pass

        # 7) Balance de clases (evita entrenar con 99% de una clase)
        try:
            pos = int(np.sum(y == 1))
            neg = int(np.sum(y == 0))
            if (pos + neg) > 0:
                frac = max(pos, neg) / float(pos + neg)
                if frac >= float(MAX_CLASS_IMBALANCE) and n_total >= int(MIN_FIT_ROWS_PROD):
                    try:
                        agregar_evento(f"‚ö†Ô∏è IA: clase desbalanceada (pos={pos}, neg={neg}). Skip.")
                    except Exception:
                        pass
                    return False
        except Exception:
            pass

        # 8) Split temporal TRAIN/CALIB/TEST
        def _calc_sizes(n):
            min_train_req = int(max(
                MIN_FIT_ROWS_LOW,
                MIN_TRAIN_ROWS_ADAPTIVE,
                int(round(float(n) * float(MIN_TRAIN_SHARE_ADAPTIVE))),
            ))
            n_test = int(max(MIN_TEST_ROWS, int(round(n * float(TEST_SIZE_FRAC)))))
            n_cal  = int(max(MIN_CALIB_ROWS, int(round(n * float(CALIB_SIZE_FRAC)))))

            if n < (MIN_TEST_ROWS + MIN_CALIB_ROWS + MIN_FIT_ROWS_LOW):
                n_test = max(5, int(round(n * 0.20)))
                n_cal  = max(0, int(round(n * 0.15)))

            n_train = n - n_cal - n_test
            if n_train < int(min_train_req):
                falta = int(min_train_req) - n_train
                if n_cal > 0:
                    cut = min(n_cal, falta)
                    n_cal -= cut
                    falta -= cut
                if falta > 0 and n_test > 5:
                    cut = min(n_test - 5, falta)
                    n_test -= cut
                    falta -= cut
                n_train = n - n_cal - n_test

            if n_train < int(min_train_req):
                return None

            return n_train, n_cal, n_test, min_train_req

        def _expand_test_hasta_doble_clase(y_all, n_train, n_cal, n_test, min_train_req):
            """
            Evita TEST degenerado de una sola clase cuando s√≠ existe diversidad
            en hist√≥rico total. Conserva orden temporal moviendo frontera
            train/calib -> test (sin mezclar ni barajar).
            """
            try:
                y_np = np.asarray(y_all)
                if y_np.size <= 0:
                    return n_train, n_cal, n_test
                if len(np.unique(y_np)) < 2:
                    return n_train, n_cal, n_test

                min_test_floor = max(5, int(min(MIN_TEST_ROWS, max(5, y_np.size // 3))))
                n_test = max(int(n_test), int(min_test_floor))

                if len(np.unique(y_np[-n_test:])) >= 2:
                    return n_train, n_cal, n_test

                min_cal_keep = 0
                max_shift_from_cal = max(0, int(n_cal) - int(min_cal_keep))
                max_shift_from_train = max(0, int(n_train) - int(min_train_req))
                max_shift = max_shift_from_cal + max_shift_from_train

                while max_shift > 0 and len(np.unique(y_np[-n_test:])) < 2:
                    if n_cal > min_cal_keep:
                        n_cal -= 1
                    elif n_train > int(min_train_req):
                        n_train -= 1
                    else:
                        break
                    n_test += 1
                    max_shift -= 1

                return int(n_train), int(n_cal), int(n_test)
            except Exception:
                return n_train, n_cal, n_test

        sizes = _calc_sizes(n_total)
        if sizes is None:
            return False
        n_train, n_cal, n_test, min_train_req = sizes
        n_train, n_cal, n_test = _expand_test_hasta_doble_clase(y, n_train, n_cal, n_test, min_train_req)

        i0 = 0
        i1 = n_train
        i2 = n_train + n_cal
        i3 = n_total

        X_train = X.iloc[i0:i1].copy()
        y_train = np.asarray(y)[i0:i1]

        X_calib = X.iloc[i1:i2].copy() if n_cal > 0 else None
        y_calib = np.asarray(y)[i1:i2] if n_cal > 0 else None

        X_test  = X.iloc[i2:i3].copy()
        y_test  = np.asarray(y)[i2:i3]

        # 8.1) Selecci√≥n din√°mica de calidad (SIN fuga: solo con TRAIN_BASE)
        freeze_core_warmup_train = bool(FEATURE_FREEZE_CORE_DURING_WARMUP) and (n_total < int(FEATURE_FREEZE_CORE_MIN_ROWS))
        if FEATURE_DYNAMIC_SELECTION and (not freeze_core_warmup_train):
            try:
                feats_quality, quality_report = _seleccionar_features_calidad(X_train, y_train, feats_used)
                feats_quality = [c for c in feats_quality if c in X_train.columns]
                if feats_quality:
                    X_train = X_train[feats_quality].copy()
                    if X_calib is not None and len(X_calib) > 0:
                        X_calib = X_calib[feats_quality].copy()
                    X_test = X_test[feats_quality].copy()
                    feats_used = list(feats_quality)

                    globals()["FEATURE_NAMES_PROD"] = list(feats_used)
                    globals()["FEATURE_NAMES_SHADOW"] = [f for f in FEATURE_NAMES_CORE_13 if f not in feats_used]

                    if quality_report:
                        txt = ", ".join([f"{k}:{r}" for k, r in quality_report[:8]])
                        agregar_evento(f"üéØ IA quality-gate(train): prod={feats_used} | {txt}")
            except Exception:
                pass
        elif freeze_core_warmup_train:
            try:
                keep_core = [f for f in FEATURE_NAMES_CORE_13 if f in X_train.columns]
                if keep_core:
                    X_train = X_train[keep_core].copy()
                    if X_calib is not None and len(X_calib) > 0:
                        X_calib = X_calib[keep_core].copy()
                    X_test = X_test[keep_core].copy()
                    feats_used = list(keep_core)
                    globals()["FEATURE_NAMES_PROD"] = list(feats_used)
                    globals()["FEATURE_NAMES_SHADOW"] = [f for f in FEATURE_NAMES_CORE_13 if f not in feats_used]
            except Exception:
                pass

        # 9) Escalado SOLO con TRAIN_BASE
        scaler = StandardScaler()
        Xtr_s = scaler.fit_transform(X_train)
        Xte_s = scaler.transform(X_test)
        Xcal_s = scaler.transform(X_calib) if X_calib is not None and len(X_calib) > 0 else None

        # 10) Entrenar modelo base
        pos_tr = int(np.sum(np.asarray(y_train) == 1))
        neg_tr = int(np.sum(np.asarray(y_train) == 0))
        if pos_tr > 0 and neg_tr > 0:
            scale_pos_weight = float(max(0.5, min(5.0, neg_tr / float(pos_tr))))
        else:
            scale_pos_weight = 1.0

        modelo_base = xgb.XGBClassifier(
            n_estimators=400,
            max_depth=4,
            learning_rate=0.05,
            subsample=0.9,
            colsample_bytree=0.9,
            reg_lambda=1.0,
            random_state=42,
            n_jobs=4,
            eval_metric="logloss",
            scale_pos_weight=scale_pos_weight,
        )
        modelo_base.fit(Xtr_s, y_train)

        # 11) Calibraci√≥n (si hay calib y hay 2 clases)
        modelo_final = modelo_base
        calib_kind = "none"

        if Xcal_s is not None and y_calib is not None and len(y_calib) >= 10:
            try:
                if len(np.unique(y_calib)) == 2:
                    p_cal = modelo_base.predict_proba(Xcal_s)[:, 1]
                    p_cal = np.clip(np.asarray(p_cal, dtype=float), 1e-6, 1.0 - 1e-6)

                    if len(y_calib) >= 200:
                        calib_kind = "isotonic"
                        iso = IsotonicRegression(out_of_bounds="clip")
                        iso.fit(p_cal, y_calib)
                        modelo_final = ModeloXGBCalibrado(modelo_base, "isotonic", iso)
                    else:
                        calib_kind = "sigmoid"
                        z = np.log(p_cal / (1.0 - p_cal)).reshape(-1, 1)
                        lr = LogisticRegression(max_iter=200)
                        lr.fit(z, y_calib)
                        modelo_final = ModeloXGBCalibrado(modelo_base, "sigmoid", lr)
            except Exception:
                calib_kind = "none"
                modelo_final = modelo_base

        # 12) Threshold sugerido en CALIB (calidad > cantidad).
        # 1) Intentar cumplir precisi√≥n objetivo en zona alta (>=70%).
        # 2) Si no alcanza muestra m√≠nima, fallback a F-beta (beta=0.5).
        thr = float(THR_DEFAULT)
        calib_prec_at_thr = None
        calib_n_at_thr = 0
        try:
            if Xcal_s is not None and y_calib is not None and len(y_calib) >= 20 and len(np.unique(y_calib)) == 2:
                p = modelo_final.predict_proba(Xcal_s)[:, 1]

                best_target_thr = None
                best_target_n = -1
                best_target_prec = 0.0

                best_fb_thr, best_fb = thr, -1.0
                for t in np.linspace(0.50, 0.90, 81):
                    yp = (p >= t).astype(int)
                    mask = (yp == 1)
                    n_sig = int(np.sum(mask))
                    if n_sig > 0:
                        prec = float(np.mean(np.asarray(y_calib)[mask] == 1))
                    else:
                        prec = 0.0

                    # Candidato por objetivo de precisi√≥n
                    if n_sig >= int(IA_TARGET_MIN_SIGNALS) and prec >= float(IA_TARGET_PRECISION):
                        if n_sig > best_target_n:
                            best_target_thr = float(t)
                            best_target_n = int(n_sig)
                            best_target_prec = float(prec)

                    fb = fbeta_score(y_calib, yp, beta=0.5, zero_division=0)
                    if fb > best_fb:
                        best_fb = fb
                        best_fb_thr = float(t)

                if best_target_thr is not None:
                    thr = float(best_target_thr)
                    calib_prec_at_thr = float(best_target_prec)
                    calib_n_at_thr = int(best_target_n)
                else:
                    thr = float(best_fb_thr)
                    mask_fb = (p >= thr)
                    calib_n_at_thr = int(np.sum(mask_fb))
                    if calib_n_at_thr > 0:
                        calib_prec_at_thr = float(np.mean(np.asarray(y_calib)[mask_fb] == 1))
        except Exception:
            thr = float(THR_DEFAULT)

        # 13) M√©tricas en TEST (√∫ltimo bloque, honesto)
        try:
            p_test = modelo_final.predict_proba(Xte_s)[:, 1]
            p_test = np.clip(np.asarray(p_test, dtype=float), 1e-6, 1.0 - 1e-6)
        except Exception:
            p_test = None

        auc = 0.0
        auc_applicable = False
        f1t = 0.0
        brier = 1.0
        try:
            if p_test is not None and len(np.unique(y_test)) == 2:
                auc = float(roc_auc_score(y_test, p_test))
                auc_applicable = True
            else:
                auc = 0.0
                auc_applicable = False
        except Exception:
            auc = 0.0
            auc_applicable = False

        try:
            if p_test is not None:
                yhat = (p_test >= float(thr)).astype(int)
                f1t = float(f1_score(y_test, yhat, zero_division=0))
                brier = float(brier_score_loss(y_test, p_test))
        except Exception:
            pass

        # 14) TimeSeriesSplit REAL (CV AUC) sobre TRAIN_BASE (diagn√≥stico)
        cv_auc = None
        try:
            if len(X_train) >= 200 and len(np.unique(y_train)) == 2:
                tscv = TimeSeriesSplit(n_splits=4)
                aucs = []

                cv_params = dict(
                    n_estimators=200,
                    max_depth=4,
                    learning_rate=0.05,
                    subsample=0.9,
                    colsample_bytree=0.9,
                    reg_lambda=1.0,
                    random_state=42,
                    n_jobs=4,
                    eval_metric="logloss",
                    scale_pos_weight=scale_pos_weight,
                )

                for tr_idx, va_idx in tscv.split(X_train):
                    Xtr = X_train.iloc[tr_idx]
                    ytr = y_train[tr_idx]
                    Xva = X_train.iloc[va_idx]
                    yva = y_train[va_idx]

                    if len(np.unique(ytr)) < 2 or len(np.unique(yva)) < 2:
                        continue

                    sc = StandardScaler()
                    Xtr_s2 = sc.fit_transform(Xtr)
                    Xva_s2 = sc.transform(Xva)

                    m = xgb.XGBClassifier(**cv_params)
                    m.fit(Xtr_s2, ytr)
                    pp = m.predict_proba(Xva_s2)[:, 1]
                    aucs.append(float(roc_auc_score(yva, pp)))

                if aucs:
                    cv_auc = float(np.mean(aucs))
        except Exception:
            cv_auc = None

        # 15) Reliable (criterio ‚Äúproducci√≥n‚Äù)
        # Adem√°s de AUC/base, exigimos que la zona de alta probabilidad no est√© inflada.
        test_prec_at_thr = 0.0
        test_n_at_thr = 0
        try:
            if p_test is not None:
                mask_t = (p_test >= float(thr))
                test_n_at_thr = int(np.sum(mask_t))
                if test_n_at_thr > 0:
                    test_prec_at_thr = float(np.mean(np.asarray(y_test)[mask_t] == 1))
        except Exception:
            test_prec_at_thr = 0.0
            test_n_at_thr = 0

        try:
            pos_all = int(np.sum(y == 1))
            neg_all = int(np.sum(y == 0))
            precision_gate_ok = (
                (test_n_at_thr < int(IA_TARGET_MIN_SIGNALS)) or
                (test_prec_at_thr >= float(IA_TARGET_PRECISION_FLOOR))
            )
            reliable = (
                (n_total >= int(MIN_FIT_ROWS_PROD)) and
                (n_total >= int(TRAIN_WARMUP_MIN_ROWS)) and
                (pos_all >= int(RELIABLE_POS_MIN)) and
                (neg_all >= int(RELIABLE_NEG_MIN)) and
                (auc >= float(MIN_AUC_CONF)) and
                precision_gate_ok
            )
        except Exception:
            reliable = False

        # 16) Pol√≠tica robusta Champion vs Challenger (anti-congelamiento por AUC ruidoso)
        prev_auc = None
        prev_brier = None
        prev_f1 = None
        prev_n_samples = 0
        prev_feat_count = 0
        prev_trained_at = None
        try:
            meta_path = globals().get("_META_PATH", "model_meta.json")
            if os.path.exists(meta_path):
                with open(meta_path, "r", encoding="utf-8") as f:
                    meta_old = json.load(f)
                if isinstance(meta_old, dict):
                    v_auc = meta_old.get("auc", None)
                    prev_auc = float(v_auc) if isinstance(v_auc, (int, float)) else None
                    v_brier = meta_old.get("brier", None)
                    prev_brier = float(v_brier) if isinstance(v_brier, (int, float)) else None
                    v_f1 = meta_old.get("f1", None)
                    prev_f1 = float(v_f1) if isinstance(v_f1, (int, float)) else None
                    prev_n_samples = int(meta_old.get("n_samples", meta_old.get("rows_total", meta_old.get("n", 0))) or 0)
                    prev_feats = meta_old.get("feature_names", meta_old.get("FEATURE_NAMES_USADAS", []))
                    if isinstance(prev_feats, list):
                        prev_feat_count = int(len(prev_feats))
                    ts_old = str(meta_old.get("trained_at", "") or "").strip()
                    if ts_old:
                        try:
                            prev_trained_at = datetime.strptime(ts_old, "%Y-%m-%d %H:%M:%S")
                        except Exception:
                            prev_trained_at = None
        except Exception:
            prev_auc = None
            prev_brier = None
            prev_f1 = None
            prev_n_samples = 0
            prev_feat_count = 0
            prev_trained_at = None

        allow_replace_collapsed = (
            (prev_feat_count > 0)
            and (prev_feat_count < int(FEATURE_MIN_ACCEPTED_COUNT))
            and (len(feats_used) >= int(FEATURE_MIN_ACCEPTED_COUNT))
        )

        # staleness override: evita quedarse pegado al campe√≥n antiguo cuando crece la data
        min_abs_growth = int(TRAIN_REFRESH_MIN_ABS_ROWS)
        try:
            if int(prev_n_samples) <= int(TRAIN_REFRESH_LOWN_CUTOFF):
                min_abs_growth = int(TRAIN_REFRESH_MIN_ABS_ROWS_LOWN)
        except Exception:
            min_abs_growth = int(TRAIN_REFRESH_MIN_ABS_ROWS)

        stale_by_rows = bool(
            prev_n_samples > 0
            and (n_total >= int(prev_n_samples + min_abs_growth))
            and (n_total >= int(round(prev_n_samples * (1.0 + TRAIN_REFRESH_MIN_GROWTH))))
        )
        stale_by_time = False
        try:
            if prev_trained_at is not None:
                stale_by_time = (datetime.now() - prev_trained_at).total_seconds() >= float(TRAIN_REFRESH_STALE_MIN)
        except Exception:
            stale_by_time = False
        stale_override = bool(stale_by_rows or stale_by_time)

        # Score compuesto: bajar dependencia de AUC sola en tests peque√±os/ruidosos
        auc_drop = (prev_auc is not None) and (auc < (prev_auc - float(AUC_DROP_TOL)))
        brier_not_worse = (prev_brier is None) or (brier <= (prev_brier + 0.01))
        f1_not_worse = (prev_f1 is None) or (f1t >= (prev_f1 - 0.03))
        small_test = int(n_test) < int(max(40, MIN_TEST_ROWS * 2))

        reject_hard = bool(
            (not force)
            and auc_drop
            and (not allow_replace_collapsed)
            and (not stale_override)
            and (not (small_test and brier_not_worse and f1_not_worse))
        )

        canary_mode = False
        if reject_hard:
            try:
                agregar_evento(f"üõ°Ô∏è IA: NO actualizo (AUC baj√≥ {prev_auc:.3f}‚Üí{auc:.3f}, sin evidencia de stale/canary).")
            except Exception:
                pass
            return False

        if allow_replace_collapsed:
            try:
                agregar_evento(
                    f"üõ†Ô∏è IA: reemplazo permitido (modelo colapsado {prev_feat_count}f ‚Üí nuevo {len(feats_used)}f)."
                )
            except Exception:
                pass

        if (not force) and auc_drop and (not allow_replace_collapsed):
            canary_mode = bool(TRAIN_CANARY_FORCE_UNRELIABLE and (stale_override or (small_test and brier_not_worse and f1_not_worse)))
            if canary_mode:
                try:
                    motivo = "stale" if stale_override else "test peque√±o"
                    agregar_evento(
                        f"üü° IA CANARY: AUC baj√≥ ({prev_auc:.3f}‚Üí{auc:.3f}) pero se refresca en modo seguro ({motivo})."
                    )
                except Exception:
                    pass

        # 17) Guardado at√≥mico (compatible con tu funci√≥n si existe)
        meta = {
            "trained_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "rows_total": int(n_total),
            "rows_train": int(n_train),
            "rows_calib": int(n_cal),
            "rows_test": int(n_test),
            "pos": int(np.sum(y == 1)),
            "neg": int(np.sum(y == 0)),
            "auc": float(auc),
            "f1": float(f1t),
            "brier": float(brier),
            "cv_auc": float(cv_auc) if isinstance(cv_auc, (int, float)) else None,
            "threshold": float(thr),
            "reliable": bool(False if canary_mode else reliable),
            "reliable_candidate": bool(reliable),
            "canary_mode": bool(canary_mode),
            "canary_started_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S") if canary_mode else None,
            "canary_target_closed": int(CANARY_MIN_CLOSED_SIGNALS) if canary_mode else 0,
            "refresh_policy": "champion_canary" if canary_mode else "champion_direct",
            "calibration": str(calib_kind),
            "calib_precision_at_thr": float(calib_prec_at_thr) if isinstance(calib_prec_at_thr, (int, float)) else None,
            "calib_n_at_thr": int(calib_n_at_thr),
            "test_precision_at_thr": float(test_prec_at_thr),
            "test_n_at_thr": int(test_n_at_thr),
            "feature_names": list(feats_used),
            "label_col": str(label_col),
            "feature_health": health_before,
            "dropped_features": [{"feature": k, "reason": r} for k, r in dropped_feats],
        }

        ok_save = False
        try:
            if "guardar_oracle_assets_atomico" in globals() and callable(guardar_oracle_assets_atomico):
                ok_save = bool(guardar_oracle_assets_atomico(modelo_final, scaler, list(feats_used), meta))
            else:
                # fallback por paths
                model_path = globals().get("_MODEL_PATH", "modelo_xgb.pkl")
                scaler_path = globals().get("_SCALER_PATH", "scaler.pkl")
                feats_path = globals().get("_FEATURES_PATH", "feature_names.pkl")
                meta_path = globals().get("_META_PATH", "model_meta.json")

                def _joblib_dump_atomic(obj, path):
                    tmp = path + ".tmp"
                    joblib.dump(obj, tmp)
                    os.replace(tmp, path)

                def _atomic_write_local(path, text):
                    tmp = path + ".tmp"
                    with open(tmp, "w", encoding="utf-8") as f:
                        f.write(text)
                    os.replace(tmp, path)

                with file_lock("oracle_assets.lock"):
                    _joblib_dump_atomic(modelo_final, model_path)
                    _joblib_dump_atomic(scaler, scaler_path)
                    _joblib_dump_atomic(list(feats_used), feats_path)
                    _atomic_write_local(meta_path, json.dumps(meta, ensure_ascii=False, indent=2))

                ok_save = True
        except Exception as e:
            try:
                agregar_evento(f"‚ö†Ô∏è IA: fallo guardado artefactos: {e}")
            except Exception:
                pass
            ok_save = False

        if not ok_save:
            return False

        # 18) Refrescar cache
        try:
            _ORACLE_CACHE["model"] = modelo_final
            _ORACLE_CACHE["scaler"] = scaler
            _ORACLE_CACHE["features"] = list(feats_used)
            _ORACLE_CACHE["meta"] = dict(meta)

            def _mt(p):
                try:
                    return os.path.getmtime(p)
                except Exception:
                    return None

            model_path = globals().get("_MODEL_PATH", "modelo_xgb.pkl")
            scaler_path = globals().get("_SCALER_PATH", "scaler.pkl")
            feats_path = globals().get("_FEATURES_PATH", "feature_names.pkl")
            meta_path = globals().get("_META_PATH", "model_meta.json")

            if "mtimes" not in _ORACLE_CACHE or not isinstance(_ORACLE_CACHE["mtimes"], dict):
                _ORACLE_CACHE["mtimes"] = {}
            _ORACLE_CACHE["mtimes"][model_path] = _mt(model_path)
            _ORACLE_CACHE["mtimes"][scaler_path] = _mt(scaler_path)
            _ORACLE_CACHE["mtimes"][feats_path] = _mt(feats_path)
            _ORACLE_CACHE["mtimes"][meta_path] = _mt(meta_path)
        except Exception:
            pass

        # 19) Marcar ‚Äúreentreno hecho‚Äù
        last_retrain_count = int(filas)
        last_retrain_ts = float(now)

        try:
            msg = f"‚úÖ IA reentrenada | AUC={auc:.3f} F1={f1t:.3f} thr={thr:.2f} calib={calib_kind}"
            if cv_auc is not None:
                msg += f" | CV_AUC={cv_auc:.3f}"
            agregar_evento(msg)
        except Exception:
            pass

        return True

    except Exception as e:
        LAST_RETRAIN_ERROR = f"{type(e).__name__}: {e}"
        try:
            agregar_evento(f"‚ö†Ô∏è IA train fail: {LAST_RETRAIN_ERROR}")
        except Exception:
            pass
        return False

    finally:
        try:
            _entrenando_lock.release()
        except Exception:
            pass

# === FIN BLOQUE 10 ===

# === BLOQUE 11 ‚Äî HUD Y PANEL VISUAL ===
RENDER_LOCK = threading.Lock()

def agregar_evento(texto: str):
    limpio = _normalizar_evento_texto(texto)
    eventos_recentes.append(f"[{time.strftime('%H:%M:%S')}] {limpio}")

def limpiar_consola():
    os.system("cls" if os.name == "nt" else "clear")

# Mostrar panel
def mostrar_panel():
    # === IA: actualizar Prob IA antes de render (NO afecta l√≥gica de trading) ===
    try:
        actualizar_prob_ia_todos()
    except Exception:
        pass

    """
    HUD principal: muestra estado de los bots, saldos, IA y eventos recientes.
    """
    global meta_mostrada

    # Respetar ventana de limpieza (para mensajes especiales)
    if time.time() < LIMPIEZA_PANEL_HASTA:
        limpiar_consola()
        return

    # Limpiar consola con protecci√≥n
    try:
        limpiar_consola()
    except Exception:
        pass

    # Margen a la izquierda para encuadrar mejor
    padding = " " * 4

    # ==========================
    # CABECERA SUPERIOR DEL HUD
    # ==========================

    # L√≠nea de estado general
    print(padding + Fore.GREEN + "üü¢ MODO OPERACI√ìN ACTIVO ‚Äì Escaneando‚Ä¶")

    # Etapa activa para depuraci√≥n de flujo
    try:
        edad_etapa = max(0, int(time.time() - float(ETAPA_TS)))
        print(padding + Fore.YELLOW + f"üß≠ ETAPA {ETAPA_ACTUAL}: {ETAPA_DETALLE} ({edad_etapa}s)")
    except Exception:
        pass

    # Saldo actual (archivo Deriv o saldo_real en memoria)
    try:
        valor = obtener_valor_saldo()
        if valor is None:
            valor = float(saldo_real)
        saldo_str = f"{float(valor):.2f}"
    except Exception:
        valor = None
        saldo_str = "--"

    print(padding + Fore.GREEN + f"üí∞ SALDO EN CUENTA REAL DERIV: {saldo_str}")

    # Saldo inicial y meta
    try:
        if SALDO_INICIAL is None and isinstance(valor, (int, float)):
            inicializar_saldo_real(float(valor))
        inicial_str = f"{float(SALDO_INICIAL):.2f}" if SALDO_INICIAL is not None else "--"
    except Exception:
        inicial_str = "--"

    try:
        meta_str = f"{float(META):.2f}" if META is not None else "--"
    except Exception:
        meta_str = "--"

    print(padding + Fore.GREEN + f"üí∞ SALDO INICIAL {inicial_str} üéØ META {meta_str}")

    # Resumen r√°pido para que el HUD no se vea "vac√≠o"
    try:
        bots_con_prob = 0
        umbral_real_vigente = float(get_umbral_real_calibrado())
        umbral_obs = float(globals().get("IA_OBSERVE_THR", 0.70) or 0.70)
        bots_real = 0
        bots_obs = 0
        mejor = None
        for b in BOT_NAMES:
            pb = estado_bots.get(b, {}).get("prob_ia")
            if isinstance(pb, (int, float)):
                bots_con_prob += 1
                if float(pb) >= float(umbral_real_vigente):
                    bots_real += 1
                if float(pb) >= float(umbral_obs):
                    bots_obs += 1
                if (mejor is None) or (float(pb) > mejor[1]):
                    mejor = (b, float(pb))
        owner = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
        owner_txt = "DEMO" if owner in (None, "none") else f"REAL:{owner}"
        mejor_txt = "--" if mejor is None else f"{mejor[0]} {mejor[1]*100:.1f}%"
        suceso_vals = [float(estado_bots.get(b, {}).get("ia_suceso_idx", 0.0) or 0.0) for b in BOT_NAMES]
        best_suceso = max(suceso_vals) if suceso_vals else 0.0
        sensores_planos = sum(1 for b in BOT_NAMES if bool(estado_bots.get(b, {}).get("ia_sensor_plano", False)))
        sensores_warmup = sum(1 for b in BOT_NAMES if bool(estado_bots.get(b, {}).get("ia_sensor_warmup", False)))
        n_min_real, n_req_real = _n_minimo_real_status()
        n_min_disp = min(int(n_min_real), int(n_req_real))
        n_min_extra = max(0, int(n_min_real) - int(n_req_real))
        n_min_txt = f"{n_min_disp}/{n_req_real}" + (f" (+{n_min_extra} acum)" if n_min_extra > 0 else "")
        print(padding + Fore.CYAN + f"üìä Prob IA visibles: {bots_con_prob}/{len(BOT_NAMES)} | OBS‚â•{umbral_obs*100:.1f}%: {bots_obs} | REAL‚â•{umbral_real_vigente*100:.1f}%: {bots_real} | Mejor: {mejor_txt} | Suceso‚Üë: {best_suceso:5.1f} | SENSOR_PLANO: {sensores_planos}/{len(BOT_NAMES)} (warmup:{sensores_warmup}) | n_min_real: {n_min_txt} | Token: {owner_txt}")

        try:
            meta_live = resolver_canary_estado(leer_model_meta() or {})
            reliable = bool(meta_live.get("reliable", False))
            canary_live = bool(meta_live.get("canary_mode", False))
            n_samples_live = int(meta_live.get("n_samples", meta_live.get("n", 0)) or 0)
            warmup_live = bool(meta_live.get("warmup_mode", n_samples_live < int(TRAIN_WARMUP_MIN_ROWS)))
            cap_base = float(IA_WARMUP_LOW_EVIDENCE_CAP_BASE)
            cap_post = float(IA_WARMUP_LOW_EVIDENCE_CAP_POST_N15)
            post_n15 = bool(_todos_bots_con_n_minimo_real())
            cap_now = cap_post if post_n15 else cap_base
            mode_h = str(DYN_ROOF_STATE.get("last_gate_mode", "A") or "A")
            confirm_h = int(DYN_ROOF_STATE.get("confirm_streak", 0) or 0)
            confirm_need_h = int(DYN_ROOF_STATE.get("last_confirm_need", DYN_ROOF_CONFIRM_TICKS) or DYN_ROOF_CONFIRM_TICKS)
            confirm_disp_h = min(confirm_h, confirm_need_h)
            confirm_extra_h = max(0, confirm_h - confirm_need_h)
            confirm_txt_h = f"{confirm_disp_h}/{confirm_need_h}" + (f" (+{confirm_extra_h} acum)" if confirm_extra_h > 0 else "")
            trigger_ok_h = bool(DYN_ROOF_STATE.get("last_trigger_ok", False))
            clone_gate = bool(DYN_ROOF_STATE.get("gate_consumed", False))
            best_prob = float(mejor[1]) if isinstance(mejor, tuple) and len(mejor) >= 2 else 0.0
            unrel_thr_live = float(_umbral_unrel_operativo(mejor[0] if isinstance(mejor, tuple) else None, best_prob))
            auto_adapt_ok = bool(
                AUTO_REAL_ALLOW_UNRELIABLE_POST_N15
                and post_n15
                and (n_samples_live >= int(AUTO_REAL_UNRELIABLE_MIN_N))
                and (best_prob >= float(unrel_thr_live))
            )
            auto_state = "OK" if reliable else ("ADAPT" if auto_adapt_ok else "BLOCK")

            c_prog = int(meta_live.get('canary_closed_signals', 0) or 0)
            c_tgt = int(meta_live.get('canary_target_closed', 0) or 0)
            c_hit = float(meta_live.get('canary_hitrate', 0.0) or 0.0) * 100.0
            canary_prog_txt = f"{c_prog}/{c_tgt}" if canary_live else "-"

            why_reasons = []
            if warmup_live:
                why_reasons.append("warmup")
            if (not reliable) and (not canary_live) and (not auto_adapt_ok):
                if not bool(AUTO_REAL_ALLOW_UNRELIABLE_POST_N15):
                    why_reasons.append("adapt_off")
                if not post_n15:
                    why_reasons.append("n15_pending")
                if n_samples_live < int(AUTO_REAL_UNRELIABLE_MIN_N):
                    why_reasons.append(f"n<{int(AUTO_REAL_UNRELIABLE_MIN_N)}")
                if best_prob < float(unrel_thr_live):
                    why_reasons.append(f"p_best<{float(unrel_thr_live)*100:.1f}%")
            if confirm_h < confirm_need_h:
                why_reasons.append(f"confirm_pending({confirm_txt_h})")
            if not trigger_ok_h:
                why_reasons.append("trigger_no")
            why_txt = "none" if not why_reasons else ",".join(why_reasons)

            print(
                padding
                + Fore.YELLOW
                + f"üß© WHY-NO: CAP‚âà{cap_now*100:.1f}% (warmup={'s√≠' if warmup_live else 'no'}) | "
                  f"AUTO={auto_state} reliable={'s√≠' if reliable else 'no'} canary={'s√≠' if canary_live else 'no'} n={n_samples_live} p_best={best_prob*100:.1f}% why={why_txt} | canary_prog={canary_prog_txt} hit={c_hit:.1f}% | "
                  f"ROOF mode={mode_h} confirm={confirm_txt_h} trigger_ok={'s√≠' if trigger_ok_h else 'no'} gate_consumed={'s√≠' if clone_gate else 'no'}"
            )

            # ===== HUD DIAGN√ìSTICO R√ÅPIDO (solo visual, no cambia l√≥gica) =====
            roof_h = float(DYN_ROOF_STATE.get("roof", DYN_ROOF_FLOOR) or DYN_ROOF_FLOOR)
            floor_h = float(DYN_ROOF_STATE.get("last_floor_eff", _umbral_real_operativo_actual()) or _umbral_real_operativo_actual())
            obs_ok = bool(best_prob >= float(umbral_obs))
            unrel_ok = bool(best_prob >= float(unrel_thr_live))
            roof_ok = bool(best_prob >= float(roof_h))
            confirm_ok = bool(confirm_h >= confirm_need_h)
            trig_ok = bool(trigger_ok_h)
            rel_ok = bool(reliable)
            can_ok = bool(canary_live)
            classic_ok = bool(best_prob >= float(IA_ACTIVACION_REAL_THR))

            p_model = float(best_prob)
            p_oper = float(best_prob) if (confirm_ok and trig_ok and (rel_ok or can_ok or auto_adapt_ok)) else 0.0

            funnel_checks = [
                ("OBS70", obs_ok),
                (f"UNREL{int(round(unrel_thr_live*100))}", unrel_ok),
                ("ROOF", roof_ok),
                (f"CONF {confirm_txt_h}", confirm_ok),
                ("TRIG", trig_ok),
                ("REL", rel_ok),
                ("CAN", can_ok),
                ("CLASS85", classic_ok),
            ]
            funnel_txt = " | ".join([f"{k}{'‚úÖ' if v else '‚ùå'}" for k, v in funnel_checks])

            bloqueos = [
                (f"UNREL{int(round(unrel_thr_live*100))}", unrel_ok, max(0.0, float(unrel_thr_live) - best_prob), "%"),
                ("ROOF", roof_ok, max(0.0, float(roof_h) - best_prob), "%"),
                (f"CONF {confirm_txt_h}", confirm_ok, float(max(0, confirm_need_h - confirm_h)), "ticks"),
                ("TRIGGER", trig_ok, 0.0, ""),
                ("RELIABLE", rel_ok, 0.0, ""),
                ("CANARY", can_ok, 0.0, ""),
                ("CLASS85", classic_ok, max(0.0, float(IA_ACTIVACION_REAL_THR) - best_prob), "%"),
            ]
            principal = next((b for b in bloqueos if not b[1]), None)
            if principal is None:
                principal_txt = "NONE"
            else:
                if principal[3] == "%":
                    principal_txt = f"{principal[0]} (faltan {principal[2]*100:.1f} pts)"
                elif principal[3] == "ticks":
                    principal_txt = f"{principal[0]} (faltan {int(principal[2])})"
                else:
                    principal_txt = principal[0]

            # Histograma compacto del bloqueo dominante para ventana reciente.
            try:
                principal_key = "ALLOW" if principal is None else str(principal[0])
                HUD_BLOQUEOS_RECIENTES.append(principal_key)
                agg = {}
                for k in HUD_BLOQUEOS_RECIENTES:
                    agg[k] = int(agg.get(k, 0)) + 1
                total_blk = max(1, len(HUD_BLOQUEOS_RECIENTES))
                top_blk = sorted(agg.items(), key=lambda kv: kv[1], reverse=True)[:3]
                top_txt = " | ".join([f"{k}:{(v*100.0/total_blk):.0f}%" for k, v in top_blk])
            except Exception:
                top_txt = "--"

            print(padding + Fore.CYAN + f"üß™ Embudo: {funnel_txt}")
            if owner in BOT_NAMES:
                principal_txt = f"{principal_txt} (solo nuevas entradas; REAL activo={owner})"
            print(padding + Fore.CYAN + f"üß≠ Decisi√≥n tick: P_model={p_model*100:.1f}% | P_oper={p_oper*100:.1f}% | Bloqueo principal={principal_txt}")
            print(padding + Fore.CYAN + f"üìè Umbrales activos: OBS={umbral_obs*100:.0f}% | UNREL={unrel_thr_live*100:.0f}% | ROOF={roof_h*100:.1f}% | FLOOR={floor_h*100:.1f}% | CLASSIC={IA_ACTIVACION_REAL_THR*100:.0f}%")
            print(padding + Fore.CYAN + f"üìâ Bloqueo dominante ({len(HUD_BLOQUEOS_RECIENTES)} ticks): {top_txt}")
            ref_racha = ultimo_bot_real if ultimo_bot_real in BOT_NAMES else "--"
            elegido_tick = mejor[0] if isinstance(mejor, tuple) and len(mejor) >= 1 else "--"
            print(padding + Fore.CYAN + f"üßæ Contexto racha: ref={ref_racha} | elegido_tick={elegido_tick} | token_real={owner_txt}")
        except Exception:
            pass

        if owner not in (None, "none") and mejor is not None and owner != mejor[0]:
            print(padding + Fore.YELLOW + f"‚õìÔ∏è Token bloqueado en {owner}; mejor IA actual es {mejor[0]} ({mejor[1]*100:.1f}%).")
    except Exception:
        pass

    # Marcar meta_mostrada si ya se alcanz√≥ la META y todav√≠a no fue aceptada
    try:
        if valor is not None and META is not None and valor >= META and not META_ACEPTADA:
            meta_mostrada = True
    except Exception:
        # No tocamos meta_mostrada si hay alg√∫n problema de conversi√≥n
        pass

    # ==========================
    # TABLA PRINCIPAL DE BOTS
    # ==========================

    print(padding + Fore.CYAN + "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    print(padding + Fore.CYAN + Style.BRIGHT + "‚îÇ ‚ú® ESTADO INTELIGENTE DE BOTS ¬∑ √öLTIMOS 40 ¬∑ TOKEN ¬∑ IA ¬∑ RENDIMIENTO      ‚îÇ" + Style.RESET_ALL)
    print(padding + Fore.CYAN + "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    print(padding + Fore.CYAN + "‚îÇ BOT    ‚îÇ √öltimos 40 Resultados                                                  ‚îÇ Token   ‚îÇ GANANCIAS‚îÇ P√âRDIDAS ‚îÇ % √âXITO  ‚îÇ Prob IA  ‚îÇ Modo IA  ‚îÇ")
    print(padding + Fore.CYAN + "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")

    # Meta IA para colorear Prob IA (estado global del modelo)
    model_meta_live = resolver_canary_estado(leer_model_meta() or {})
    n_model_live = int(model_meta_live.get("n_samples", model_meta_live.get("n", 0)) or 0)
    warmup_model_live = bool(model_meta_live.get("warmup_mode", n_model_live < int(TRAIN_WARMUP_MIN_ROWS)))
    reliable_model_live = bool(model_meta_live.get("reliable", False))
    umbral_ia = get_umbral_dinamico(model_meta_live, ORACULO_THR_MIN)

    # Sincron√≠a visual dura: si hay owner REAL en memoria, la tabla SIEMPRE lo refleja.
    owner_visual = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()

    for bot in BOT_NAMES:
        r = estado_bots[bot]["resultados"]
        token = "REAL" if owner_visual == bot else "DEMO"
        estado_bots[bot]["token"] = token
        src = estado_bots[bot].get("fuente")

        # Token + origen
        token_text = token
        if src and str(src).strip().upper() != "MANUAL":
            token_text += f" ({src})"
        token_color = Fore.GREEN if token_text.startswith("REAL") else Fore.CYAN
        token_text = token_color + token_text + Fore.RESET

        # √öltimos 40 resultados visuales
        visual = []
        for x in r[-40:]:
            if x == "GANANCIA":
                visual.append(Fore.GREEN + "‚úì")
            elif x == "P√âRDIDA":
                visual.append(Fore.RED + "‚úó")
            elif x == "INDEFINIDO":
                visual.append(Fore.YELLOW + "¬∑")
            else:
                visual.append(Fore.LIGHTBLACK_EX + "‚îÄ")
        while len(visual) < 40:
            visual.insert(0, Fore.LIGHTBLACK_EX + "‚îÄ")
        col_resultados = " ".join(visual)

        # Ganancias / P√©rdidas / % √©xito
        g = estado_bots[bot]["ganancias"]
        p = estado_bots[bot]["perdidas"]
        ganancias = Fore.GREEN + f"{g}"
        perdidas = Fore.RED + f"{p}"
        porc = estado_bots[bot].get("porcentaje_exito")
        total = estado_bots[bot].get("tamano_muestra", 0)

        if porc is not None:
            exito = f"{porc:.1f}% (n={total})"
            exito_color = (
                Fore.YELLOW if total < 10
                else (Fore.GREEN if porc >= 50 else Fore.RED)
            )
            if total < 10:
                exito += " ‚ö†"
            exito = exito_color + exito + Fore.RESET
        else:
            exito = "--"

        # --- Modo IA ---
        modo_raw = estado_bots.get(bot, {}).get("modo_ia", "off")
        modo = str(modo_raw or "off").strip().lower()

        # Normalizar variantes t√≠picas que vienen del CSV/estado
        if modo in ("0", "false", "none", "null", ""):
            modo = "off"
        # (extra) por si llega tipo "off algo" o "off-xyz"
        if modo.startswith("off"):
            modo = "off"

        # Meta IA por bot (umbrales UI, etc.) ‚Äî evita NameError y mantiene tu sem√°foro estable
        meta = IA_META.get(bot, {}) if "IA_META" in globals() else {}

        # --- Stats IA (solo telemetr√≠a) ---
        ia_sen   = estado_bots[bot].get("ia_seniales", 0)
        ia_acc   = estado_bots[bot].get("ia_aciertos", 0)
        ia_fal   = estado_bots[bot].get("ia_fallos", 0)
        ia_ready = estado_bots[bot].get("ia_ready", False)

        # ==========================================================
        # ‚úÖ Prob IA = probabilidad ACTUAL del modelo (ya calibrada/ajustada)
        #    - NO mezclar con IA90_stats (eso es hist√≥rico)
        #    - OFF / inv√°lida / vieja => "--" (gris)
        # ==========================================================

        prob_hist = get_prob_ia_historica(bot)  # se conserva por si lo usas en telemetr√≠a externa
        prob_ok = False
        prob = 0.0
        prob_str = "--"

        # 1) IA OFF => "--"
        # 2) IA ON pero prob no fresca/valida => "--"
        # 3) IA ON + prob fresca => mostrar %
        try:
            if modo != "off" and ia_prob_valida(bot, max_age_s=120.0):
                p_now = estado_bots[bot].get("prob_ia", None)
                try:
                    import math
                    if p_now is not None:
                        p = float(p_now)
                        # si viene en % (ej 53), convertir a 0.53
                        if p > 1.0 and p <= 100.0:
                            p = p / 100.0
                        if math.isfinite(p) and 0.0 <= p <= 1.0:
                            prob_ok = True
                            prob = p
                            prob_str = f"{prob*100.0:.1f}%"
                except Exception:
                    prob_ok = False
                    prob = 0.0
                    prob_str = "--"
        except Exception:
            prob_ok = False
            prob = 0.0
            prob_str = "--"

        # Fallback visual: si hay √∫ltima prob reciente pero no cumpli√≥ gate, mostrarla con *
        if not prob_ok:
            try:
                p_last = estado_bots[bot].get("prob_ia", None)
                ts_last = float(estado_bots[bot].get("ia_last_prob_ts", 0.0) or 0.0)
                if isinstance(p_last, (int, float)) and ts_last > 0 and (time.time() - ts_last) <= IA_PRED_TTL_S:
                    p_aux = float(p_last)
                    if p_aux > 1.0 and p_aux <= 100.0:
                        p_aux = p_aux / 100.0
                    if 0.0 <= p_aux <= 1.0:
                        prob_ok = True
                        prob = p_aux
                        prob_str = f"{p_aux*100.0:.1f}%*"
            except Exception:
                pass

        # Confianza IA (NECESARIA: se usa para colorear modo_str)
        confianza = calcular_confianza_ia(bot, meta)

        # Decoraci√≥n SOLO cuando hay prob real
        if prob_ok:
            flags = ""
            if modo == "low_data":
                flags += "l"   # low-data
            elif modo == "exp":
                flags += "e"   # experimental

            # Evita lectura "premium" cuando el modelo est√° en warmup/no confiable.
            if warmup_model_live or (not reliable_model_live):
                flags += "r"   # raw / no confiable

            # Penalizaci√≥n visual de recencia (no cambia l√≥gica de trading).
            try:
                ult = list(estado_bots.get(bot, {}).get("resultados", []))[-2:]
                if len(ult) == 2 and all(str(x) == "P√âRDIDA" for x in ult):
                    flags += "d"   # drawdown reciente
            except Exception:
                pass

            if flags:
                prob_str += f"[{flags}]"

            # Mantener ancho de columna estable para no romper la tabla.
            if len(prob_str) > 10:
                prob_str = prob_str[:10]

        # Sem√°foro IA (UI FIJA)
        # ----------------------------------------------
        # Regla anti-confusi√≥n:
        # Si este bot es el que tiene el token REAL (trigger_real=True o token="REAL"),
        # NO mostramos Prob IA en vivo (puede cambiar mientras corre el contrato).
        # En su lugar mostramos: "-- | OFF" para evitar decisiones ‚Äúen caliente‚Äù.
        try:
            st_ui = estado_bots.get(bot, {}) if isinstance(estado_bots, dict) else {}
        except Exception:
            st_ui = {}

        token_ui = str(st_ui.get("token") or "DEMO").strip().upper()
        ui_hide_ia = bool(st_ui.get("trigger_real", False)) or token_ui.startswith("REAL")

        # ‚úÖ FIX: high_thr_ui SIEMPRE definido (aunque ui_hide_ia=True)
        try:
            _fn = globals().get("get_umbral_ia_vigente", None)
            if callable(_fn):
                high_thr_ui = float(_fn())
            else:
                high_thr_ui = float(IA_VERDE_THR)
        except Exception:
            high_thr_ui = float(IA_VERDE_THR)

        mid_thr_ui = max(0.0, high_thr_ui - 0.05)

        if ui_hide_ia:
            prob_ok = False
            prob_str = Fore.LIGHTBLACK_EX + "--" + Fore.RESET
            modo_str = Fore.LIGHTBLACK_EX + "OFF" + Fore.RESET
        else:
            if (modo != "off") and prob_ok:
                if (modo == "low_data") or warmup_model_live or (not reliable_model_live):
                    # En warmup/no-confiable no pintar como "verde premium".
                    prob_color = Fore.YELLOW if prob >= mid_thr_ui else Fore.LIGHTBLACK_EX
                elif prob >= high_thr_ui:
                    prob_color = Fore.GREEN
                elif prob >= mid_thr_ui:
                    prob_color = Fore.YELLOW
                else:
                    prob_color = Fore.RED
            else:
                prob_color = Fore.LIGHTBLACK_EX

            prob_str = prob_color + prob_str + Fore.RESET

            modo_map = {
                "low_data": "LWDATA",
                "exp": "EXP",
                "modelo": "MODELO",
                "off": "OFF",
            }
            modo_base = modo_map.get(modo, (modo.upper() if modo != "off" else "OFF"))

            if modo != "off":
                if confianza >= IA_ACTIVACION_REAL_THR:
                    modo_color = Fore.GREEN
                elif confianza >= 0.55:
                    modo_color = Fore.YELLOW
                else:
                    modo_color = Fore.LIGHTBLACK_EX
            else:
                modo_color = Fore.LIGHTBLACK_EX

            su_idx = int(round(float(estado_bots.get(bot, {}).get("ia_suceso_idx", 0.0) or 0.0)))
            is_plano = bool(estado_bots.get(bot, {}).get("ia_sensor_plano", False))
            modo_tag = f"S{max(0, min(99, su_idx)):02d}" + ("!" if is_plano else "")
            modo_txt = f"{modo_base} {modo_tag}" if modo_base != "OFF" else "OFF"
            if len(modo_txt) > 10:
                modo_txt = modo_txt[:10]
            modo_str = modo_color + modo_txt + Fore.RESET

        # --- Audio IA "es hora de invertir" (umbral fijo) ---
        audio_thr = float(globals().get("AUDIO_IA53_THR", high_thr_ui))


        token_local = (estado_bots.get(bot, {}).get("token") or "DEMO")
        es_demo_local = (str(token_local).strip().upper() == "DEMO")

        if (modo != "off") and prob_ok and (prob >= audio_thr) and not IA53_TRIGGERED[bot]:
            reproducir_evento("ia_53", es_demo=es_demo_local, dentro_gatewin=True)
            IA53_TRIGGERED[bot] = True
        elif (not prob_ok) or (modo == "off") or (prob < audio_thr):
            IA53_TRIGGERED[bot] = False


        # L√≠nea completa del bot
        linea_bot = (
            padding + f"‚îÇ {bot:<6} ‚îÇ {col_resultados:<80} ‚îÇ "
            f"{token_text:<9} ‚îÇ "
            f"{ganancias:<10} ‚îÇ "
            f"{perdidas:<10} ‚îÇ "
            f"{exito:<10} ‚îÇ "
            f"{prob_str:<10} ‚îÇ "
            f"{modo_str:<10} ‚îÇ"
        )
        print(linea_bot)

    print(padding + Fore.CYAN + "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")

    # ==========================
    # EVENTOS + TELEMETR√çA IA
    # ==========================

    # Eventos recientes
    mostrar_eventos()

    # Telemetr√≠a IA (modelo XGBoost)
    ruta_inc = "dataset_incremental.csv"
    dataset_rows = contar_filas_incremental()
    meta = _ORACLE_CACHE.get("meta") or {}
    try:
        # Normalizar SIEMPRE el meta en memoria
        if isinstance(meta, dict) and meta:
            meta = _normalize_model_meta(meta)
        else:
            meta = {}
        # Fallback duro: si el cache est√° incompleto, lee disco
        if (int(meta.get("n_samples", meta.get("n", 0)) or 0) == 0) and os.path.exists(_META_PATH):
            meta_disk = leer_model_meta() or {}
            if isinstance(meta_disk, dict) and meta_disk:
                meta = meta_disk
                _ORACLE_CACHE["meta"] = meta_disk
    except Exception:
        meta = meta if isinstance(meta, dict) else {}

    if dataset_rows == 0 and not meta:
        print(Fore.CYAN + " IA ‚ñ∂ sin dataset_incremental.csv (n=0). Esperando que los bots generen datos...")
    elif dataset_rows < MIN_FIT_ROWS_LOW and not meta:
        faltan = max(0, MIN_FIT_ROWS_LOW - dataset_rows)
        print(Fore.CYAN + f" IA ‚ñ∂ dataset con n={dataset_rows}, pero sin modelo entrenado a√∫n.")
        print(Fore.CYAN + f"      Faltan {faltan} filas para el primer entrenamiento.")
    elif not meta:
        print(Fore.CYAN + f" IA ‚ñ∂ dataset listo (n={dataset_rows}), pero sin modelo entrenado todav√≠a.")
        print(Fore.CYAN + "      Se entrenar√° autom√°ticamente por tick o al usar [E].")
        print(Fore.CYAN + f"      Requisitos m√≠nimos: filas √∫tiles >= {MIN_FIT_ROWS_LOW}, 2 clases (GAN/PERD), y features v√°lidas.")
        print(Fore.CYAN + f"      Modo confiable recomendado desde n >= {TRAIN_WARMUP_MIN_ROWS}.")
        try:
            df_diag = pd.read_csv(ruta_inc, encoding="utf-8", on_bad_lines="skip") if os.path.exists(ruta_inc) else pd.DataFrame()
            y_diag = pd.to_numeric(df_diag.get("result_bin", pd.Series(dtype=float)), errors="coerce")
            pos_diag = int((y_diag == 1).sum())
            neg_diag = int((y_diag == 0).sum())
            feats_validas = int(len([c for c in df_diag.columns if c in INCREMENTAL_FEATURES_V2]))
            last_err = str(globals().get("LAST_RETRAIN_ERROR", "") or "--")
            print(Fore.CYAN + f"      Diagn√≥stico: clases pos/neg={pos_diag}/{neg_diag} | features v√°lidas={feats_validas}/{len(INCREMENTAL_FEATURES_V2)} | √∫ltimo error train={last_err}")
        except Exception:
            pass
    else:
        pos = int(meta.get("pos", meta.get("n_pos", 0)) or 0)
        neg = int(meta.get("neg", meta.get("n_neg", 0)) or 0)
        n   = int(meta.get("n_samples", meta.get("n", 0)) or 0)

        # Fallback final: si no hay n, usa pos+neg
        if n == 0 and (pos + neg) > 0:
            n = pos + neg

        auc = float(meta.get("auc", 0.0) or 0.0)
        thr = float(meta.get("threshold", ORACULO_THR_MIN))
        reliable = bool(meta.get("reliable", False))
        auc_applicable = bool(meta.get("auc_applicable", False))
        warmup_mode = bool(meta.get("warmup_mode", n < int(TRAIN_WARMUP_MIN_ROWS)))

        modo_txt = "CONFIABLE ‚úÖ" if (reliable and n >= MIN_FIT_ROWS_PROD and not warmup_mode) else "EXPERIMENTAL ‚ö†"
        auc_txt = f"{auc:.3f}" if auc_applicable else "N/A (clases insuficientes en TEST)"

        print(Fore.CYAN + f" IA ‚ñ∂ modelo XGBoost entrenado: n={n} (GAN={pos}, PERD={neg})")
        print(Fore.CYAN + f"      AUC={auc_txt}  | Thr={thr:.2f}  | Modo={modo_txt}")
        datos_utiles = int(max(0, pos + neg))
        mismatch = int(max(0, n - datos_utiles))
        if mismatch > 0:
            print(Fore.YELLOW + f"      ‚ö†Ô∏è Data quality IA: n-meta={n} pero cierres √∫tiles={datos_utiles} (delta={mismatch}).")
        if warmup_mode:
            print(Fore.CYAN + f"      Confianza IA: BAJA (Warmup n={n}<{int(TRAIN_WARMUP_MIN_ROWS)} | cierres √∫tiles={datos_utiles}).")
            print(Fore.CYAN + f"      Warmup activo: n={n}<{int(TRAIN_WARMUP_MIN_ROWS)} (solo monitoreo/calibraci√≥n).")
        else:
            print(Fore.CYAN + f"      Confianza IA: {'MEDIA/ALTA' if reliable else 'MEDIA'} | cierres √∫tiles={datos_utiles}.")

    # Mostrar contadores de aciertos IA por bot (resumen compacto para reducir ruido)
    resumen_hits = []
    for bot in BOT_NAMES:
        sig = int(estado_bots[bot].get("ia_seniales", 0) or 0)
        if sig <= 0:
            continue
        ac = int(estado_bots[bot].get("ia_aciertos", 0) or 0)
        pct = (ac / sig * 100.0) if sig > 0 else 0.0
        resumen_hits.append((pct, bot, ac, sig))

    if resumen_hits:
        top_hits = sorted(resumen_hits, key=lambda x: x[0], reverse=True)[:3]
        txt = " | ".join([f"{b}:{ac}/{sg} ({pc:.1f}%)" for pc, b, ac, sg in top_hits])
        print(Fore.CYAN + f" IA ACIERTOS (Top): {txt}")
    else:
        print(Fore.CYAN + " IA ACIERTOS: sin cierres auditados todav√≠a.")

    # HIST√ìRICO: se√±ales IA que llegaron a ejecutarse y cerraron con resultado
    # (se mantiene con IA_METRIC_THRESHOLD para comparabilidad hist√≥rica de auditor√≠a)
    print(Fore.YELLOW + f" IA HIST√ìRICO (se√±ales cerradas, ‚â•{IA_METRIC_THRESHOLD*100:.0f}%):")
    has_hist = False
    for bot in BOT_NAMES:
        stats = IA90_stats.get(bot)
        if stats and stats.get("n", 0) > 0:
            has_hist = True
            okh = int(stats.get("ok", 0) or 0)
            nh = int(stats.get("n", 0) or 0)
            pct_raw_h = float((okh / nh) * 100.0) if nh > 0 else 0.0
            print(Fore.YELLOW + f"   {bot}: {okh}/{nh} ({pct_raw_h:.1f}%)")
    if not has_hist:
        print(Fore.YELLOW + f"   (A√∫n no hay operaciones cerradas con se√±al IA ‚â•{IA_METRIC_THRESHOLD*100:.0f}%.)")

    # ACTUAL: qui√©n est√° >= umbral vigente para compuerta REAL en este tick.
    umbral_actual_hud = float(_umbral_senal_actual_hud())
    print(Fore.YELLOW + f"\nIA SE√ëALES OBSERVACI√ìN (‚â•{umbral_actual_hud*100:.0f}% ahora):")
    now = []
    for bot in BOT_NAMES:
        st = estado_bots.get(bot, {}) if isinstance(estado_bots, dict) else {}

        # Anti-confusi√≥n: si este bot tiene token REAL, no lo consideramos ‚Äúse√±al actual‚Äù
        token_ui = str(st.get("token") or "DEMO").strip().upper()
        if bool(st.get("trigger_real", False)) or token_ui.startswith("REAL"):
            continue

        modo = (st.get("modo_ia") or "off").lower()
        p = st.get("prob_ia", None)
        if modo != "off" and isinstance(p, (int, float)) and p >= float(umbral_actual_hud):
            now.append((bot, float(p)))

    if bool(REAL_CLASSIC_GATE):
        try:
            roof_h = float(DYN_ROOF_STATE.get("roof", DYN_ROOF_FLOOR) or DYN_ROOF_FLOOR)
            cbot_h = DYN_ROOF_STATE.get("confirm_bot")
            cst_h = int(DYN_ROOF_STATE.get("confirm_streak", 0) or 0)
            mode_h = str(DYN_ROOF_STATE.get("last_gate_mode", "A") or "A")
            floor_eff_h = float(DYN_ROOF_STATE.get("last_floor_eff", _umbral_real_operativo_actual()) or _umbral_real_operativo_actual())
            confirm_need_h = int(DYN_ROOF_STATE.get("last_confirm_need", DYN_ROOF_CONFIRM_TICKS) or DYN_ROOF_CONFIRM_TICKS)
            trigger_ok_h = bool(DYN_ROOF_STATE.get("last_trigger_ok", False))
            crowd_h = int(DYN_ROOF_STATE.get("crowd_count", 0) or 0)
            n_min_real, n_req_real = _n_minimo_real_status()
            bloqueado_txt = "bloqueado" if n_min_real < n_req_real else "ok"
            cst_disp_h = min(cst_h, confirm_need_h)
            cst_extra_h = max(0, cst_h - confirm_need_h)
            cst_txt_h = f"{cst_disp_h}/{confirm_need_h}" + (f" (+{cst_extra_h} acum)" if cst_extra_h > 0 else "")
            n_disp_h = min(int(n_min_real), int(n_req_real))
            n_extra_h = max(0, int(n_min_real) - int(n_req_real))
            n_txt_h = f"{n_disp_h}/{n_req_real}" + (f" (+{n_extra_h} acum)" if n_extra_h > 0 else "")
            print(
                Fore.YELLOW
                + f" Compuerta REAL (operativa): mode={mode_h} | roof={roof_h*100:.1f}% | floor={floor_eff_h*100:.1f}% | "
                  f"confirm={cst_txt_h}" + (f" ({cbot_h})" if cbot_h else "")
                  + f" | trigger_ok={'s√≠' if trigger_ok_h else 'no'} | crowd={crowd_h}"
                  + f" | n_min_real={n_txt_h} ({bloqueado_txt})"
            )
        except Exception:
            pass

    if not now:
        print(Fore.YELLOW + f"(Ning√∫n bot ‚â•{umbral_actual_hud*100:.0f}% en este tick.)")
    else:
        for b, p in sorted(now, key=lambda x: x[1], reverse=True):
            print(Fore.YELLOW + f"  {b}: {p*100:.1f}%")

    try:
        hot_rows = []
        for b in BOT_NAMES:
            st = estado_bots.get(b, {})
            hot = list(st.get("ia_sensor_hot_feats", []) or [])[:3]
            if hot:
                hot_rows.append(f"{b}:{','.join(hot)}")
        if hot_rows:
            hot_msg = " SENSOR_PLANO hot-features: " + " | ".join(hot_rows)
            try:
                term_cols_clip = os.get_terminal_size().columns
            except Exception:
                term_cols_clip = 140
            # Mantener esta l√≠nea lejos del HUD/panel derecho (evita solapado visual).
            # Tope fijo corto para consolas angostas o con zoom/fuentes variables.
            max_hot_len = 72
            if len(hot_msg) > max_hot_len:
                hot_msg = hot_msg[:max(0, max_hot_len - 3)] + "..."
            print(Fore.YELLOW + hot_msg)
    except Exception:
        pass

        # Calibraci√≥n detallada movida a reporte externo (menos ruido en HUD principal)
    print(Fore.MAGENTA + "\n‚ÑπÔ∏è Calibraci√≥n IA detallada desactivada en HUD (usar: python reporte_real_vs_ficticio_ia.py --session debug).")

    panel_lines = [
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
        "‚îÇ üéÆ PANEL DE CONTROL TECLADO               ‚îÇ",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
        "‚îÇ [S] Salir  [P] Pausar  [C] Continuar      ‚îÇ",
        "‚îÇ [R] Reiniciar ciclo  [T] Ver token        ‚îÇ",
        "‚îÇ [L] Limpiar visual  [D] Limpieza dura     ‚îÇ",
        "‚îÇ [G] Probar audio  [E] Entrenar IA ya      ‚îÇ",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
        "‚îÇ ü§ñ ¬øC√ìMO INVIERTES?                        ‚îÇ",
        "‚îÇ [5‚Äì0] Elige bot (p.ej. 7 = fulll47)       ‚îÇ",
        "‚îÇ [1‚Äì6] Elige ciclo [p.ej. 3 = Marti #3)    ‚îÇ",
    ]

    token_file = leer_token_actual()
    token_hud  = "DEMO" if (token_file in (None, "none")) else f"REAL:{token_file}"
    activo_real = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else next((b for b in BOT_NAMES if estado_bots[b]["token"] == "REAL"), None)
    fuente = estado_bots.get(activo_real, {}).get("fuente") or "AUTO" if activo_real else "--"
    panel_lines.append(f"‚îÇ Fuente={fuente} ‚Üí Token={token_hud:<12}          ‚îÇ")

    panel_lines.append("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")

    if PENDIENTE_FORZAR_BOT:
        rest = 0
        if PENDIENTE_FORZAR_EXPIRA:
            rest = max(0, int(PENDIENTE_FORZAR_EXPIRA - time.time()))
        panel_lines += [
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
            f"‚îÇ Bot seleccionado: {PENDIENTE_FORZAR_BOT:<22}‚îÇ",
            f"‚îÇ Tiempo para decidir: {rest:>3}s               ‚îÇ",
            f"‚îÇ Elige ciclo [1..{MAX_CICLOS}] o ESC          ‚îÇ",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
        ]


    if HUD_VISIBLE:
        dibujar_hud_gatewin(len(panel_lines), HUD_LAYOUT)
    def _strip_ansi(s: str) -> str:
        return re.sub(r'\x1b\[[0-9;]*m', '', s)
    panel_width = max(len(_strip_ansi(l)) for l in panel_lines)
    panel_height = len(panel_lines)
    try:
        term_cols, term_rows = os.get_terminal_size()
    except:
        term_cols, term_rows = 140, 50
    start_col = max(1, term_cols - panel_width - 1)
    start_row = max(1, term_rows - panel_height - 1)
    for i, line in enumerate(panel_lines):
        print(f"\x1b[{start_row + i};{start_col}H" + Fore.MAGENTA + line + Fore.RESET)
    print(f"\x1b[{term_rows};1H", end="")

# Mostrar advertencia meta
def mostrar_advertencia_meta():
    global salir, pausado, MODAL_ACTIVO, META_ACEPTADA, meta_mostrada, SALDO_INICIAL, META

    pausado = True
    MODAL_ACTIVO = True

    try:
        terminal_width = max(os.get_terminal_size().columns, 100)
        terminal_height = max(os.get_terminal_size().lines, 32)
    except Exception:
        terminal_width, terminal_height = 100, 32

    # √Årea del modal para refresco incremental (sin limpiar toda la consola en cada tick)
    box_w = min(max(terminal_width - 6, 80), 140)
    box_h = min(max(terminal_height - 6, 22), 30)
    left = max(1, (terminal_width - box_w) // 2)
    top = max(2, (terminal_height - box_h) // 2)

    # Sonido meta en loop hasta [S] o [C]
    if AUDIO_AVAILABLE:
        if pygame.mixer.get_init() and "meta_15" in SOUND_CACHE:
            try:
                SOUND_CACHE["meta_15"].play(loops=-1)
            except Exception:
                pass
        elif winsound:
            try:
                base_dir = os.path.dirname(__file__)
                sound_path = os.path.join(base_dir, "meta15%.wav")
                winsound.PlaySound(sound_path, winsound.SND_LOOP | winsound.SND_ASYNC)
            except Exception:
                pass

    # Confetti + shake suave
    palette = [Fore.YELLOW, Fore.CYAN, Fore.MAGENTA, Fore.GREEN, Fore.RED, Fore.WHITE]
    glyphs = ['|', '!', ':', '*', '+']
    particles = []
    max_particles = max(30, box_w // 2)

    def _stop_meta_sound():
        if AUDIO_AVAILABLE:
            if pygame.mixer.get_init() and "meta_15" in SOUND_CACHE:
                try:
                    SOUND_CACHE["meta_15"].stop()
                except Exception:
                    pass
            elif winsound:
                try:
                    winsound.PlaySound(None, winsound.SND_PURGE)
                except Exception:
                    pass

    def _center_in_box(msg: str) -> str:
        pad = max(0, box_w - 2 - len(msg))
        left_pad = pad // 2
        right_pad = pad - left_pad
        return " " * left_pad + msg + " " * right_pad

    def _draw_frame(tick: int):
        # borde
        print(f"[{top};{left}H" + Fore.YELLOW + "‚ñà" * box_w + Fore.RESET, end='')
        for r in range(1, box_h - 1):
            print(f"[{top+r};{left}H" + Fore.YELLOW + "‚ñà" + Fore.RESET, end='')
            print(f"[{top+r};{left+box_w-1}H" + Fore.YELLOW + "‚ñà" + Fore.RESET, end='')
        print(f"[{top+box_h-1};{left}H" + Fore.YELLOW + "‚ñà" * box_w + Fore.RESET, end='')

        # limpiar interior
        blank = " " * (box_w - 2)
        for r in range(1, box_h - 1):
            print(f"[{top+r};{left+1}H{blank}", end='')

        shake = -1 if (tick % 4 in (0, 1)) else 1
        title = "üéâ ¬°¬°¬°FELICIDADES!!! üéâ"
        y = top + 2
        x = left + 1 + max(0, (box_w - 2 - len(title)) // 2 + shake)
        print(f"[{y};{x}H" + Fore.CYAN + title + Fore.RESET, end='')

        lines = [
            "‚úÖ Has alcanzado tu meta diaria del +20% de ganancia.",
            "",
            "üí° Recomendaci√≥n:",
            "EvaBot busca una ganancia diaria aproximada del 20% de tu capital.",
            "Puedes seguir invirtiendo bajo tu responsabilidad o esperar al siguiente d√≠a.",
            "",
            "‚ö†Ô∏è Importante:",
            "Ning√∫n sistema es infalible y siempre existe riesgo de p√©rdida.",
            "Lee el Manual de Usuario para horarios recomendados y detalles clave.",
            "",
            "Presiona [S] para SALIR y asegurar beneficios, o [C] para continuar invirtiendo.",
        ]
        row = top + 4
        for msg in lines:
            if row >= top + box_h - 2:
                break
            print(f"[{row};{left+1}H" + _center_in_box(msg), end='')
            row += 1

        # confetti cayendo
        if len(particles) < max_particles and random.random() < 0.55:
            particles.append({
                "x": left + 2 + random.randint(0, max(1, box_w - 6)),
                "y": top + 1,
                "v": random.choice((1, 1, 2)),
                "ch": random.choice(glyphs),
                "color": random.choice(palette),
            })

        alive = []
        for part in particles:
            part["y"] += part["v"]
            if part["y"] < top + box_h - 1:
                alive.append(part)
                if left + 1 <= part["x"] <= left + box_w - 2 and top + 1 <= part["y"] <= top + box_h - 2:
                    print(f"[{int(part['y'])};{int(part['x'])}H" + part["color"] + part["ch"] + Fore.RESET, end='')
        particles[:] = alive

        print(f"[{terminal_height};1H", end='', flush=True)

    limpiar_consola()
    tick = 0
    while True:
        tick += 1
        _draw_frame(tick)

        if HAVE_MSVCRT and msvcrt.kbhit():
            try:
                t = msvcrt.getch()
                if t in (b'\x00', b'\xe0'):
                    msvcrt.getch()
                    continue
                tecla = t.decode("utf-8", errors="ignore").lower()
            except Exception:
                tecla = ""

            if tecla in ("s",):
                print("\nüõë Cerrando EvaBot...")
                _stop_meta_sound()
                salir = True
                MODAL_ACTIVO = False
                break

            if tecla in ("c", "\r"):
                print("\n‚úîÔ∏è Continuando bajo responsabilidad del usuario...")
                _stop_meta_sound()
                try:
                    if MAIN_LOOP:
                        fut = asyncio.run_coroutine_threadsafe(refresh_saldo_real(forzado=True), MAIN_LOOP)
                        fut.result(timeout=15)
                    valor = obtener_valor_saldo()
                    if valor is not None:
                        SALDO_INICIAL = round(valor, 2)
                        META = round(SALDO_INICIAL * 1.20, 2)
                        inicializar_saldo_real(SALDO_INICIAL)
                except Exception as e:
                    print(f"‚ö†Ô∏è Error reiniciando meta: {e}")
                pausado = False
                META_ACEPTADA = True
                meta_mostrada = False
                MODAL_ACTIVO = False
                break

        time.sleep(0.08)

# Dibujar HUD
def dibujar_hud_gatewin(panel_height=8, layout=None):
    if not sys.stdout.isatty():
        return
    HUD_INNER_WIDTH = 50
    HUD_WIDTH = HUD_INNER_WIDTH + 2
    activo_real = next((b for b in BOT_NAMES if estado_bots[b]["token"] == "REAL"), None)
    try:
        term_cols, term_rows = os.get_terminal_size()
    except:
        term_cols, term_rows = 140, 50
    hud_lines = [
        "‚îå" + "‚îÄ" * HUD_INNER_WIDTH + "‚îê",
        "‚îÇ ‚è±Ô∏è  HUD: Or√°culo evaluando bots..." + " " * (HUD_INNER_WIDTH - 32) + " ‚îÇ",
        "‚îú" + "‚îÄ" * HUD_INNER_WIDTH + "‚î§",
    ]
    emoji, estado, detalle = evaluar_semaforo()
    hud_lines += [
        f"‚îÇ Estado: {emoji} {estado:<{HUD_INNER_WIDTH-10}}‚îÇ",
        f"‚îÇ {detalle:<{HUD_INNER_WIDTH}}‚îÇ",
        "‚îú" + "‚îÄ" * HUD_INNER_WIDTH + "‚î§",
        f"‚îÇ {'ü§ñ ¬øC√ìMO INVIERTES?':<{HUD_INNER_WIDTH}}‚îÇ",
        f"‚îÇ {'[5‚Äì0] Elige bot (p.ej. 7 = fulll47)':<{HUD_INNER_WIDTH}}‚îÇ",
        f"‚îÇ {[f'[1‚Äì{MAX_CICLOS}] Elige ciclo (p.ej. 3 = Marti #3)'][0]:<{HUD_INNER_WIDTH}}‚îÇ",
    ]
    activo_real = next((b for b in BOT_NAMES if estado_bots[b]["token"] == "REAL"), None)
    if activo_real:
        cyc = estado_bots[activo_real].get("ciclo_actual", 1)
        hud_lines.insert(-1, f"‚îÇ Bot REAL: {activo_real} ¬∑ Ciclo {cyc}/{MAX_CICLOS}".ljust(HUD_INNER_WIDTH) + " ‚îÇ")
    prox_ciclo = ciclo_martingala_siguiente()
    prox_txt = f"C{prox_ciclo}"
    if int(prox_ciclo) == 1:
        prox_txt = "C1 (reinicio)"
    hud_lines.insert(-1, f"‚îÇ Martingala: {marti_ciclos_perdidos}/{MAX_CICLOS} p√©rdidas seguidas ¬∑ Pr√≥x {prox_txt}".ljust(HUD_INNER_WIDTH) + " ‚îÇ")
    hud_lines.insert(-1, f"‚îÇ {marti_audit_resumen_linea():<{HUD_INNER_WIDTH}}‚îÇ")
    # HUD muestra ciclo actual/siguiente de martingala; sin bloqueo duro de anti-repetici√≥n.
    hud_lines.append("‚îî" + "‚îÄ" * HUD_INNER_WIDTH + "‚îò")
    layout = (layout or HUD_LAYOUT).lower()
    hud_height = len(hud_lines)
    start_col = max(1, (term_cols - HUD_WIDTH) // 2)
    start_row = max(2, term_rows - hud_height - 1)
    for i, line in enumerate(hud_lines):
        print(f"\x1b[{start_row + i};{start_col}H" + Fore.YELLOW + line + Fore.RESET)

def mostrar_eventos():
    if eventos_recentes:
        print(Fore.MAGENTA + "\nEventos recientes:")
        for ev in list(eventos_recentes)[-5:]:
            print(Fore.MAGENTA + " - " + ev)
# === FIN BLOQUE 11 ===

# === BLOQUE 12 ‚Äî CONTROL MANUAL REAL Y CONDICIONES SEGURAS ===
MAIN_LOOP = None

def set_main_loop(loop):
    global MAIN_LOOP
    MAIN_LOOP = loop

# ==================== VENTANA DE DECISI√ìN IA ====================
# Debe empatar con el BOT (VENTANA_DECISION_IA_S) para que el humano alcance a elegir ciclo.
VENTANA_DECISION_IA_S = 30

PENDIENTE_FORZAR_BOT = None
PENDIENTE_FORZAR_INICIO = 0.0
PENDIENTE_FORZAR_EXPIRA = 0.0

FORZAR_LOCK = threading.Lock()

def condiciones_seguras_para(bot: str) -> bool:
    # Usa el mismo umbral operativo que el HUD/audio
    thr = get_umbral_operativo()
    prob = estado_bots.get(bot, {}).get("prob_ia") or 0.0
    n    = estado_bots.get(bot, {}).get("tamano_muestra", 0)
    return (n >= ORACULO_N_MIN) and (prob >= thr)

# forzar_real_manual
def forzar_real_manual(bot: str, ciclo: int):
    if not FORZAR_LOCK.acquire(blocking=False):
        agregar_evento("üîí Forzar REAL: ya en progreso; espera.")
        return
    try:
        ciclo = max(1, min(int(ciclo), MAX_CICLOS))

        # A√±adido: Confirmaci√≥n en rojo si no es seguro (para evitar cierres forzados por malas decisiones)
        CONFIRMAR_EN_ROJO = True  # Activado por defecto para seguridad
        if CONFIRMAR_EN_ROJO and HAVE_MSVCRT and not condiciones_seguras_para(bot):
            global MODAL_ACTIVO
            MODAL_ACTIVO = True
            try:
                with RENDER_LOCK:
                    print(Fore.YELLOW + f"‚ö†Ô∏è Sem√°foro no verde para {bot}. ¬øForzar de todos modos? [Y/N]")
                while True:
                    if msvcrt.kbhit():
                        k = msvcrt.getch().decode("utf-8", errors="ignore").lower()
                        if k == "y":
                            break
                        elif k == "n":
                            agregar_evento("‚ùé Forzar REAL cancelado (no confirmado).")
                            return
                    time.sleep(0.05)
            finally:
                MODAL_ACTIVO = False

        # Nueva l√≥gica: Marcar como se√±al IA si prob >= thr_ia
        prob = estado_bots.get(bot, {}).get("prob_ia") or 0.0
        thr_ia = get_umbral_operativo()

        if prob >= thr_ia and not estado_bots[bot]["ia_senal_pendiente"]:
            estado_bots[bot]["ia_senal_pendiente"] = True
            estado_bots[bot]["ia_prob_senal"] = prob

            # ‚úÖ FIX REAL: registrar APERTURA de se√±al con epoch PRE real (para contabilidad correcta)
            # Esto s√≠ ‚Äúlo consume‚Äù el cierre autom√°tico posterior (log_ia_close v√≠a ia_audit_scan_close).
            try:
                epoch_sig = None
                try:
                    epoch_sig = ia_audit_get_last_pre_epoch(bot)
                except Exception:
                    epoch_sig = None

                if epoch_sig is not None:
                    log_ia_open(
                        bot,
                        int(epoch_sig),
                        float(prob),
                        float(thr_ia),
                        "MANUAL"
                    )
            except Exception:
                pass


        if not escribir_orden_real(bot, ciclo):
            agregar_evento(f"üîí Forzar REAL bloqueado para {bot.upper()}: ya hay otro bot en REAL.")
            return

        estado_bots[bot]["reintentar_ciclo"] = True
        estado_bots[bot]["ciclo_actual"] = ciclo
        global marti_paso
        marti_paso = ciclo - 1
        estado_bots[bot]["fuente"] = "MANUAL"

        requerido = float(MARTI_ESCALADO[ciclo - 1])
        val = obtener_valor_saldo()
        if val is None or val < requerido:
            agregar_evento(f"‚ö†Ô∏è Saldo < requerido para ciclo #{ciclo} en {bot} (pide {requerido}). Intentando igual.")

        # escribir_orden_real(...) ya dej√≥ token+HUD sincronizados; evitamos doble token_sync.
        agregar_evento(f"‚ö° Forzar REAL: {bot} ‚Üí ciclo #{ciclo} (fuente=MANUAL)")
        with RENDER_LOCK:
            mostrar_panel()
    except Exception as e:
        agregar_evento(f"‚õî Forzar REAL fall√≥ en {bot}: {e}")
    finally:
        FORZAR_LOCK.release()

def evaluar_semaforo():
    thr = get_umbral_operativo()

    mejor = (None, None, 0)
    for b in BOT_NAMES:
        d = estado_bots.get(b, {})
        prob = d.get("prob_ia")
        n    = d.get("tamano_muestra", 0)
        if prob is not None and (mejor[0] is None or prob > mejor[0]):
            mejor = (prob, b, n)
    prob, bbest, n = mejor

    owner = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
    try: saldo_val = float(obtener_valor_saldo() or 0.0)
    except: saldo_val = 0.0
    costo = float(sum(MARTI_ESCALADO[:max(1, int(MAX_CICLOS))]))
    costo_c1 = float(MARTI_ESCALADO[0]) if MARTI_ESCALADO else 0.0

    detalle = ""
    if owner and owner not in (None, "none"):
        detalle = f"Token en uso por {owner}. Puedes forzar 5‚Äì0 ‚Üí 1..5."
        return "üü°", "AVISO", detalle
    if saldo_val < costo_c1:
        falta = costo_c1 - saldo_val
        detalle = f"Saldo < C1 ({costo_c1:.2f}). Faltan {falta:.2f} USD para abrir nueva orden."
        return "üü°", "AVISO", detalle
    if saldo_val < costo:
        detalle = f"Saldo parcial: cubre C1 pero no todo C1..C{int(MAX_CICLOS)} ({costo:.2f})."
        return "üü¢", "SE√ëAL LISTA", detalle

    n_inc = contar_filas_incremental()
    if n_inc < MIN_FIT_ROWS_LOW:
        detalle = f"IA en modo WARMUP: n={n_inc}. Faltan {MIN_FIT_ROWS_LOW - n_inc} filas para entrenamiento estable."
        return "üü°", "EN ESPERA", detalle

    if prob is None or n < 10:
        return "üü°", "EN ESPERA", "Pocos datos √∫tiles a√∫n."
    if n < ORACULO_N_MIN and (prob or 0) < thr:
        return "üü°", "EN ESPERA", f"n={n}<{ORACULO_N_MIN} y prob={prob:.0%}<{int(thr*100)}%"
    if n < ORACULO_N_MIN:
        return "üü°", "EN ESPERA", f"n={n}<{ORACULO_N_MIN}"
    if (prob or 0) < thr:
        return "üü°", "EN ESPERA", f"prob={prob:.0%}<{int(thr*100)}%"

    tecla = (bbest or "?")[-2:]
    detalle = f"{bbest} ‚Ä¢ Prob={prob:.0%} ‚Ä¢ n={n} ‚Üí pulsa [{tecla}] y el ciclo."
    return "üü¢", "SE√ëAL LISTA", detalle

# NUEVAS FUNCIONES PARA RESET
RESET_ON_START = False  # Cambiado a False para mantener historial entre sesiones
AUTO_REPAIR_ON_START = True  # Repara estructura de CSVs al iniciar sin borrar historial completo

def _csv_header_bot():
    return [
        "fecha","ts","epoch","activo","direction","monto","resultado","ganancia_perdida","trade_status",
        "rsi_9","rsi_14","sma_5","sma_20","sma_spread","cruce_sma","breakout",
        "rsi_reversion","racha_actual","payout","puntaje_estrategia",
        "volatilidad","es_rebote","hora_bucket","result_bin",
        "payout_decimal_rounded","payout_multiplier","payout_total","close","high","low"
    ]

def resetear_csv_bot(nombre_bot: str):
    ruta = f"registro_enriquecido_{nombre_bot}.csv"
    try:
        with open(ruta, "w", newline="", encoding="utf-8") as f:
            csv.writer(f).writerow(_csv_header_bot())
    except Exception as e:
        print(f"‚ö†Ô∏è No pude resetear {ruta}: {e}")

def resetear_incremental_y_modelos(borrar_modelos: bool = True):
    try:
        if os.path.exists("dataset_incremental.csv"):
            os.remove("dataset_incremental.csv")
    except Exception as e:
        print(f"‚ö†Ô∏è No pude borrar dataset_incremental.csv: {e}")

    if borrar_modelos:
        for f in ("modelo_xgb.pkl","scaler.pkl","feature_names.pkl"):
            try:
                if os.path.exists(f):
                    os.remove(f)
            except Exception as e:
                print(f"‚ö†Ô∏è No pude borrar {f}: {e}")

def resetear_estado_hud(estado_bots: dict):
    for bot in list(estado_bots.keys()):
        estado_bots[bot].update({
            "resultados": [], "ganancias": 0, "perdidas": 0,
            "porcentaje_exito": None, "tamano_muestra": 0,
            "prob_ia": 0.0, "token": "DEMO",
            "fuente": None, "modo_ia": "off",
            "ia_seniales": 0, "ia_aciertos": 0, "ia_fallos": 0, "ia_senal_pendiente": False,
            "ia_prob_senal": None
        })

def limpieza_dura():
    for nb in BOT_NAMES:
        resetear_csv_bot(nb)
    resetear_incremental_y_modelos(borrar_modelos=True)
    resetear_estado_hud(estado_bots)
    print("üß® Limpieza dura ejecutada. Ok.")

def _asegurar_estructura_datos_inicio() -> list[str]:
    """
    Verifica y corrige desalineaciones comunes al arranque sin borrar hist√≥rico completo.

    Objetivo:
    - Evitar que una estructura vieja/mixta deje al bot en estado incoherente al iniciar.
    - Reparar incremental mutante usando el flujo existente.
    - Reencuadrar CSVs enriquecidos de bots al header can√≥nico cuando detecta desv√≠os.
    """
    msgs = []

    # 1) Incremental: usa el reparador robusto ya existente (no-op si est√° sano).
    try:
        if reparar_dataset_incremental_mutante(ruta="dataset_incremental.csv", cols=_canonical_incremental_cols()):
            msgs.append("üßπ Inicio seguro: dataset_incremental reparado autom√°ticamente.")
    except Exception as e:
        msgs.append(f"‚ö†Ô∏è Inicio seguro: no se pudo validar/reparar dataset_incremental ({e}).")

    # 2) CSVs enriquecidos por bot: si falta/rompe header, se recrea SOLO header can√≥nico.
    header_ref = _csv_header_bot()
    required = {"resultado", "trade_status", "epoch", "monto"}
    for bot in BOT_NAMES:
        ruta = f"registro_enriquecido_{bot}.csv"
        if not os.path.exists(ruta):
            continue
        try:
            header = None
            for enc in ("utf-8", "latin-1", "windows-1252"):
                try:
                    with open(ruta, "r", encoding=enc, errors="replace") as f:
                        first = f.readline().strip()
                    header = [c.strip() for c in first.split(",")] if first else []
                    break
                except Exception:
                    continue

            header_set = set(header or [])
            malformed = (not header) or (not required.issubset(header_set))

            # Tambi√©n tratar como incompatible si trae una sola columna "mutante" gigante.
            if (not malformed) and len(header) <= 2:
                malformed = True

            if malformed:
                bak = f"{ruta}.bak_startfix_{int(time.time())}"
                try:
                    shutil.copy2(ruta, bak)
                except Exception:
                    bak = None
                with open(ruta, "w", newline="", encoding="utf-8") as f:
                    csv.writer(f).writerow(header_ref)
                if bak:
                    msgs.append(f"üßπ Inicio seguro: {bot} ten√≠a estructura inv√°lida; reiniciado header (backup: {os.path.basename(bak)}).")
                else:
                    msgs.append(f"üßπ Inicio seguro: {bot} ten√≠a estructura inv√°lida; reiniciado header.")
        except Exception as e:
            msgs.append(f"‚ö†Ô∏è Inicio seguro: no se pudo validar {bot} ({e}).")

    return msgs

# Backfill seguro
def backfill_incremental(ultimas=500):
    try:
        try:
            feature_names = joblib.load("feature_names.pkl")
            feature_names = [c for c in feature_names if c != "result_bin"]
        except Exception:
            feature_names = [
                "rsi_9","rsi_14","sma_5","sma_spread","cruce_sma","breakout",
                "rsi_reversion","racha_actual","payout","puntaje_estrategia",
                "volatilidad","es_rebote","hora_bucket",
            ]
        inc = "dataset_incremental.csv"
        cols = feature_names + ["result_bin"]

        # 0) Reparar incremental si qued√≥ "mutante" (header corrupto / columnas extra / mezcla de campos)
        with file_lock("inc.lock"):
            if reparar_dataset_incremental_mutante(inc, cols):
                agregar_evento("üßπ Incremental: esquema reparado (header/filas inconsistentes).")
            if not os.path.exists(inc) or os.stat(inc).st_size == 0:
                with open(inc, "w", newline="", encoding="utf-8") as f:
                    csv.DictWriter(f, fieldnames=cols).writeheader()

        firmas_existentes = set()
        if os.path.exists(inc):
            df_inc = pd.read_csv(inc, encoding="utf-8", on_bad_lines="skip")
            if not df_inc.empty:
                sigs = df_inc[feature_names].round(6).astype(str).agg("|".join, axis=1) + "|" + df_inc["result_bin"].astype(int).astype(str)
                firmas_existentes = set(sigs.tolist())


        for bot in BOT_NAMES:
            ruta = f"registro_enriquecido_{bot}.csv"
            if not os.path.exists(ruta):
                continue
            df = None
            for enc in ("utf-8","latin-1","windows-1252"):
                try:
                    df = pd.read_csv(ruta, encoding=enc, on_bad_lines="skip")
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è Error en backfill para {bot}: {e}")
                    continue
            if df is None or df.empty:
                continue

            req = [
                "rsi_9","rsi_14","sma_5","sma_20","cruce_sma","breakout",
                "rsi_reversion","racha_actual","puntaje_estrategia"
            ]
            if not set(req).issubset(df.columns) or "resultado" not in df.columns:
                continue

            for c in req + ["payout","payout_decimal_rounded"]:
                if c in df.columns:
                    df[c] = pd.to_numeric(df[c], errors="coerce")

            df["resultado_norm"] = df["resultado"].apply(normalizar_resultado)

            sub = df[df["resultado_norm"].isin(["GANANCIA","P√âRDIDA"])]
            sub = sub[sub[req].notna().all(axis=1)].tail(ultimas)
            if sub.empty:
                continue

            nuevas_filas = []
            descartadas = 0
            
            nuevas_filas = []
            for _, r in sub.iterrows():
                # base m√≠nima
                fila = {k: float(r[k]) for k in req}
                sp = _calcular_sma_spread_robusto({
                    "sma_5": r.get("sma_5", 0.0),
                    "sma_20": r.get("sma_20", 0.0),
                    "close": r.get("close", r.get("cierre", None)),
                })
                if sp is None or not np.isfinite(float(sp)):
                    descartadas += 1
                    continue
                fila["sma_spread"] = float(sp)

                # Diccionario completo para helpers enriquecidos
                row_dict_full = r.to_dict()

                                # ==========================
                # payout normalizado (ROI 0‚Äì1.5 aprox)
                # ==========================
                pay = calcular_payout_feature(row_dict_full)
                # Si falta payout, NO lo inventamos como 0.0: descartamos la fila
                # (backfill es entrenamiento, aqu√≠ ser conservador = IA m√°s estable)
                if pay is None or pay < 0.05:
                    descartadas += 1
                    continue

                # ‚úÖ FIX: estas asignaciones DEBEN ocurrir antes del continue
                fila["payout"] = float(pay)
                row_dict_full["payout"] = float(pay)

                # Enriquecer se√±ales evento antes de extraer features finales
                row_dict_full = enriquecer_features_evento(row_dict_full)

                # ==========================
                # puntaje_estrategia normalizado 0‚Äì1
                # ==========================
                pe = calcular_puntaje_estrategia_normalizado(row_dict_full)
                if pe is None and "puntaje_estrategia" in r:
                    pe = _norm_01(r.get("puntaje_estrategia"))
                if pe is not None:
                    fila["puntaje_estrategia"] = pe

                # ==========================
                # volatilidad: normalizada a [0,1]
                # - si viene en el CSV y es v√°lida, la usamos
                # - si falta / NaN, la calculamos con calcular_volatilidad_simple (proxy SMA5 vs SMA20)
                # ==========================
                vol_raw = row_dict_full.get("volatilidad", None)
                try:
                    vol = float(vol_raw) if vol_raw not in (None, "") else np.nan
                except Exception:
                    vol = np.nan
                if pd.isna(vol):
                    vol = calcular_volatilidad_simple(row_dict_full)
                try:
                    vol_f = float(vol)
                except Exception:
                    vol_f = float("nan")
                if (not math.isfinite(vol_f)) or vol_f <= 0.0:
                    vol_hist = calcular_volatilidad_por_bot(bot, lookback=50)
                    if vol_hist is not None:
                        vol_f = float(vol_hist)
                if (not math.isfinite(vol_f)):
                    vol_f = 0.0

                fila["volatilidad"] = max(0.0, min(float(vol_f), 1.0))

                # ==========================
                # nuevas features: rebote y hora (0‚Äì1)
                # ==========================
                fila["es_rebote"]   = float(max(0.0, min(1.0, _safe_float_local(row_dict_full.get("es_rebote")) or calcular_es_rebote(row_dict_full))))
                hb, hm = calcular_hora_features(row_dict_full)
                if float(hm) >= 1.0:
                    lt = time.localtime()
                    idx48 = int(lt.tm_hour * 2 + (1 if lt.tm_min >= 30 else 0))
                    hb = float(max(0, min(47, idx48))) / 47.0
                fila["hora_bucket"] = float(max(0.0, min(1.0, float(hb))))

                # ==========================
                # label final (GANANCIA / P√âRDIDA)
                # ==========================
                label = 1 if r["resultado_norm"] == "GANANCIA" else 0
                fila_dict = fila.copy()
                fila_dict["result_bin"] = label

                # Validaci√≥n defensiva
                valid, reason = validar_fila_incremental(fila_dict, feature_names)
                if not valid:
                    agregar_evento(f"‚ö†Ô∏è Incremental: fila descartada en backfill ({reason})")
                    descartadas += 1
                    continue

                # Clipping defensivo
                fila_dict = clip_feature_values(fila_dict, feature_names)

                # Evitar duplicados v√≠a firma
                sig = _make_sig(fila_dict)
                if sig in firmas_existentes:
                    continue
                firmas_existentes.add(sig)

                nuevas_filas.append(fila_dict)

            if nuevas_filas:
                with file_lock("inc.lock"):
                    with open(inc, "a", newline="", encoding="utf-8") as f:
                        w = csv.DictWriter(f, fieldnames=cols)
                        for rd in nuevas_filas:
                            w.writerow(rd)
                        f.flush(); os.fsync(f.fileno())
        agregar_evento("‚úÖ IA: backfill incremental completado.")
    except Exception as e:
        agregar_evento(f"‚ö†Ô∏è IA: fallo en backfill: {e}")
# === FIN BLOQUE 12 ===

# === BLOQUE 13 ‚Äî LOOP PRINCIPAL, WEBSOCKET Y TECLADO ===
# Orden operativo por etapas (solo trazabilidad/depuraci√≥n; no altera trading)
ETAPAS_PROGRAMA = {
    "BOOT_01": "Arranque y validaci√≥n de entorno",
    "BOOT_02": "Carga de audio/tokens y reset opcional",
    "BOOT_03": "Backfill + primer entrenamiento IA",
    "BOOT_04": "Sincronizaci√≥n inicial HUD/CSV",
    "TICK_01": "Lectura de token y carga incremental por bot",
    "TICK_02": "Watchdog REAL + detecci√≥n de cierre",
    "TICK_03": "Selecci√≥n IA / ventana manual / asignaci√≥n REAL",
    "TICK_04": "Refresh saldo + render HUD",
    "STOP": "Salida controlada",
}
ETAPA_ACTUAL = "BOOT_01"
ETAPA_DETALLE = ETAPAS_PROGRAMA[ETAPA_ACTUAL]
ETAPA_TS = time.time()

def set_etapa(codigo, detalle_extra=None, anunciar=False):
    """
    Marca etapa actual del programa para facilitar diagn√≥stico en vivo.
    No modifica ninguna decisi√≥n de trading.
    """
    global ETAPA_ACTUAL, ETAPA_DETALLE, ETAPA_TS

    codigo = str(codigo or "").strip().upper()
    if codigo not in ETAPAS_PROGRAMA:
        return

    base = ETAPAS_PROGRAMA[codigo]
    detalle = f"{base} | {detalle_extra}" if detalle_extra else base

    ETAPA_ACTUAL = codigo
    ETAPA_DETALLE = detalle
    ETAPA_TS = time.time()

    if anunciar:
        agregar_evento(f"üß≠ ETAPA {codigo}: {detalle}")

# Nueva constante para watchdog de REAL - Bajado para m√°s reactividad
REAL_TIMEOUT_S = 120  # 2 minutos sin actividad para aviso/rearme
REAL_STUCK_FORCE_RELEASE_S = 90  # segundos extra tras aviso para liberar REAL si no hay cierre
REAL_TRIGGER_MIN = IA_ACTIVACION_REAL_THR  # regla operativa: entrada REAL desde 85% o mayor

# =========================================================
# TECHO DIN√ÅMICO + COMPUERTA REAL (anti-bug de activaci√≥n baja)
# =========================================================
# Lote de actualizaci√≥n del maestro (ticks de lectura IA)
DYN_ROOF_BATCH_TICKS = 15
# Paciencia dura antes de empezar a bajar el techo (4 lotes = 60 ticks)
DYN_ROOF_HOLD_BATCHES = 4
DYN_ROOF_HOLD_TICKS = DYN_ROOF_BATCH_TICKS * DYN_ROOF_HOLD_BATCHES
# Derretido lento del techo: -0.5pp por lote tras la paciencia
DYN_ROOF_STEP = 0.005
# Piso duro para REAL
DYN_ROOF_FLOOR = 0.70
# Ventaja m√≠nima del mejor vs segundo mejor
DYN_ROOF_GAP = 0.03
# Confirmaci√≥n m√≠nima (ticks consecutivos del MISMO bot)
DYN_ROOF_CONFIRM_TICKS = 2
# Tolerancia para considerar "tocado" el techo (near-roof)
DYN_ROOF_NEAR_TOL = 0.005
# Penalizaci√≥n por evidencia corta (n < 30): requiere +2pp al techo
DYN_ROOF_LOW_N_MIN = 30
DYN_ROOF_LOW_N_PENALTY = 0.02
PROB_CLONE_STD_MIN = 0.01
PROB_CLONE_GAP_MIN = 0.005
REAL_POST_TRADE_COOLDOWN_S = 45
REAL_POST_TRADE_COOLDOWN_CROWDED_S = 240
DYN_ROOF_CROWD_P_MIN = 0.90
DYN_ROOF_CROWD_MIN_BOTS = 3
DYN_ROOF_CROWD_EXTRA_ROOF = 0.02
DYN_ROOF_CROWD_EXTRA_GAP = 0.02
# Clustering en zona 70-80%: evita seleccionar bots con margen m√≠nimo "fake".
DYN_ROOF_CLUSTER_P_MIN = 0.70
DYN_ROOF_CLUSTER_MIN_BOTS = 3
DYN_ROOF_CLUSTER_EXTRA_GAP = 0.01
# Si el top est√° empatado/pr√°cticamente empatado, mantener bot en confirmaci√≥n
# para no reiniciar confirm_streak en cada tick por micro-ruido.
DYN_ROOF_TIE_KEEP_CONFIRM_TOL = 0.003
DYN_ROOF_GATE_REARM_HYST = 0.02
DYN_ROOF_GATE_REARM_TICKS = 2
DYN_ROOF_LOW_BAL_WARN_COOLDOWN_S = 60
DYN_ROOF_STALL_TO_MODE_C_S = 2 * 60 * 60
DYN_ROOF_MODE_C_FLOOR = 0.70
DYN_ROOF_MODE_C_CONFIRM_TICKS = 3
DYN_ROOF_MODE_C_MIN_EVIDENCE_N = 20
DYN_ROOF_MODE_C_MIN_EVIDENCE_LB = 0.60
REAL_COOLDOWN_UNTIL_TS = 0.0
LAST_RETRAIN_ERROR = ""

DYN_ROOF_STATE = {
    "tick": 0,
    "roof": float(max(DYN_ROOF_FLOOR, IA_OBJETIVO_REAL_THR)),
    "last_touch_tick": 0,
    "melt_batches_applied": 0,
    "confirm_bot": None,
    "confirm_streak": 0,
    "last_open_tick": 0,
    "last_floor": None,
    "allow_real_prev": False,
    "gate_consumed": False,
    "gate_rearm_streak": 0,
    "crowd_count": 0,
    "last_low_balance_warn_ts": 0.0,
    "last_p_best": 0.0,
    "prev_probs": {},
    "last_real_open_ts": 0.0,
}


def _cooldown_post_trade_s() -> float:
    """Cooldown din√°mico post-trade: m√°s largo si el mercado est√° saturado de probabilidades altas."""
    try:
        crowd_count = int(DYN_ROOF_STATE.get("crowd_count", 0) or 0)
        p_best = float(DYN_ROOF_STATE.get("last_p_best", 0.0) or 0.0)
        if crowd_count >= int(DYN_ROOF_CROWD_MIN_BOTS) and p_best >= float(DYN_ROOF_CROWD_P_MIN):
            return float(REAL_POST_TRADE_COOLDOWN_CROWDED_S)
    except Exception:
        pass
    return float(REAL_POST_TRADE_COOLDOWN_S)


def _marcar_compuerta_real_consumida() -> None:
    """Consume la apertura de compuerta REAL para evitar r√°fagas mientras la se√±al siga pegada."""
    try:
        DYN_ROOF_STATE["gate_consumed"] = True
    except Exception:
        pass


def _cooldown_post_trade_s() -> float:
    """Cooldown din√°mico post-trade: m√°s largo si el mercado est√° saturado de probabilidades altas."""
    try:
        crowd_count = int(DYN_ROOF_STATE.get("crowd_count", 0) or 0)
        p_best = float(DYN_ROOF_STATE.get("last_p_best", 0.0) or 0.0)
        if crowd_count >= int(DYN_ROOF_CROWD_MIN_BOTS) and p_best >= float(DYN_ROOF_CROWD_P_MIN):
            return float(REAL_POST_TRADE_COOLDOWN_CROWDED_S)
    except Exception:
        pass
    return float(REAL_POST_TRADE_COOLDOWN_S)


def _marcar_compuerta_real_consumida() -> None:
    """Consume la apertura de compuerta REAL para evitar r√°fagas mientras la se√±al siga pegada."""
    try:
        DYN_ROOF_STATE["gate_consumed"] = True
    except Exception:
        pass


def _cooldown_post_trade_s() -> float:
    """Cooldown din√°mico post-trade: m√°s largo si el mercado est√° saturado de probabilidades altas."""
    try:
        crowd_count = int(DYN_ROOF_STATE.get("crowd_count", 0) or 0)
        p_best = float(DYN_ROOF_STATE.get("last_p_best", 0.0) or 0.0)
        if crowd_count >= int(DYN_ROOF_CROWD_MIN_BOTS) and p_best >= float(DYN_ROOF_CROWD_P_MIN):
            return float(REAL_POST_TRADE_COOLDOWN_CROWDED_S)
    except Exception:
        pass
    return float(REAL_POST_TRADE_COOLDOWN_S)


def _marcar_compuerta_real_consumida() -> None:
    """Consume la apertura de compuerta REAL para evitar r√°fagas mientras la se√±al siga pegada."""
    try:
        DYN_ROOF_STATE["gate_consumed"] = True
    except Exception:
        pass


def _todos_bots_con_n_minimo_real(min_n: int | None = None) -> bool:
    """True si TODOS los bots alcanzaron el m√≠nimo de muestra para habilitar umbral REAL reducido."""
    try:
        n_req = int(IA_ACTIVACION_REAL_MIN_N_POR_BOT if min_n is None else min_n)
        for b in BOT_NAMES:
            n_b = int(estado_bots.get(b, {}).get("tamano_muestra", 0) or 0)
            if n_b < n_req:
                return False
        return True
    except Exception:
        return False


def _umbral_real_operativo_actual() -> float:
    """
    Umbral REAL din√°mico:
    - Base 85%
    - Baja a 75% cuando TODOS los bots tienen n>=15
    """
    try:
        if _todos_bots_con_n_minimo_real():
            return float(IA_ACTIVACION_REAL_THR_POST_N15)
    except Exception:
        pass
    return float(IA_ACTIVACION_REAL_THR)


def _n_minimo_real_status() -> tuple[int, int]:
    """Retorna (m√≠nimo n actual entre bots, n requerido) para diagn√≥stico en HUD."""
    try:
        n_req = int(IA_ACTIVACION_REAL_MIN_N_POR_BOT)
        n_vals = [int(estado_bots.get(b, {}).get("tamano_muestra", 0) or 0) for b in BOT_NAMES]
        n_min = min(n_vals) if n_vals else 0
        return int(n_min), int(n_req)
    except Exception:
        return 0, int(IA_ACTIVACION_REAL_MIN_N_POR_BOT)


def _smart_clone_override_ok(best_bot: str, p_best: float, p_second: float, clone_flat: bool) -> bool:
    """
    Permite destrabar el candado clone_flat SOLO cuando hay evidencia real fuerte.

    Objetivo:
    - Evitar falsos bloqueos por planicie de probabilidades en ticks donde
      el mejor bot realmente ya demostr√≥ edge consistente.
    - Mantener conservadurismo: exige N, l√≠mite inferior (LB), prob alta y
      micro-GAP positivo frente al segundo.
    """
    try:
        if not bool(SMART_LOCKS_ENABLE):
            return False
        if not bool(clone_flat):
            return False
        if not best_bot:
            return False

        ev = _evidencia_bot_umbral_objetivo(best_bot)
        ev_n = int(ev.get("n", 0) or 0)
        ev_lb = float(ev.get("lb", 0.0) or 0.0)
        p1 = float(p_best or 0.0)
        p2 = float(p_second or 0.0)
        gap = float(p1 - p2)

        return bool(
            (ev_n >= int(SMART_CLONE_OVERRIDE_MIN_N))
            and (ev_lb >= float(SMART_CLONE_OVERRIDE_MIN_LB))
            and (p1 >= float(SMART_CLONE_OVERRIDE_MIN_PROB))
            and (gap >= float(SMART_CLONE_OVERRIDE_MIN_GAP))
        )
    except Exception:
        return False


def _umbral_unrel_operativo(best_bot: str | None, best_prob: float | None = None) -> float:
    """
    Umbral UNREL din√°mico (m√≠nimo ajuste):
    - Base: AUTO_REAL_UNRELIABLE_MIN_PROB (63%)
    - En lateral con evidencia suficiente por bot, puede bajar hasta un piso seguro.
    """
    try:
        base = float(AUTO_REAL_UNRELIABLE_MIN_PROB)
        if not bool(AUTO_REAL_UNREL_LATERAL_ADAPT_ENABLE):
            return base
        if not isinstance(best_bot, str) or (best_bot not in BOT_NAMES):
            return base

        st = estado_bots.get(best_bot, {}) if isinstance(estado_bots, dict) else {}
        n_bot = int(st.get("tamano_muestra", 0) or 0)
        wr_bot = float((st.get("porcentaje_exito", 0.0) or 0.0) / 100.0)
        p_best = float(best_prob or 0.0)

        lateral_ok = bool(
            (n_bot >= int(AUTO_REAL_UNREL_LATERAL_MIN_N))
            and (wr_bot >= float(AUTO_REAL_UNREL_LATERAL_MIN_WR))
            and (p_best >= float(AUTO_REAL_UNREL_LATERAL_MIN_PROB))
        )
        if lateral_ok:
            return float(max(float(AUTO_REAL_UNREL_LATERAL_MIN_PROB), min(base, p_best)))
        return base
    except Exception:
        return float(AUTO_REAL_UNRELIABLE_MIN_PROB)


def _actualizar_compuerta_techo_dinamico() -> dict:
    """
    Actualiza el techo din√°mico y eval√∫a la compuerta REAL del mejor bot del tick.

    Reglas clave:
    - roof sube r√°pido por m√°ximos (roof=max(roof, p_best)).
    - roof baja lento tras paciencia (hold), por lotes de batch ticks.
    - compuerta REAL exige: piso duro, techo efectivo, GAP y confirmaci√≥n doble.
    """
    floor_now = float(_umbral_real_operativo_actual())
    modo_relajado_n15 = bool(_todos_bots_con_n_minimo_real())
    meta_live = _ORACLE_CACHE.get("meta") or leer_model_meta() or {}
    n_samples_meta = int(meta_live.get("n_samples", meta_live.get("n", 0)) or 0)
    warmup_mode = bool(meta_live.get("warmup_mode", n_samples_meta < int(TRAIN_WARMUP_MIN_ROWS)))
    reliable_mode = bool(meta_live.get("reliable", False)) and (not warmup_mode)
    last_real_open_ts = float(DYN_ROOF_STATE.get("last_real_open_ts", 0.0) or 0.0)
    stall_s = max(0.0, time.time() - last_real_open_ts) if last_real_open_ts > 0 else float(DYN_ROOF_STALL_TO_MODE_C_S + 1)
    mode_c_candidate = bool(
        modo_relajado_n15
        and reliable_mode
        and (stall_s >= float(DYN_ROOF_STALL_TO_MODE_C_S))
    )
    out = {
        "best_bot": None,
        "p_best": 0.0,
        "p_second": 0.0,
        "gap_ok": False,
        "roof": float(DYN_ROOF_STATE.get("roof", floor_now)),
        "roof_eff": float(DYN_ROOF_STATE.get("roof", floor_now)),
        "confirm_streak": int(DYN_ROOF_STATE.get("confirm_streak", 0) or 0),
        "allow_real": False,
        "n_best": 0,
        "new_open": False,
        "gate_mode": "A",
        "stall_s": float(stall_s),
    }
    try:
        DYN_ROOF_STATE["tick"] = int(DYN_ROOF_STATE.get("tick", 0) or 0) + 1
        tick_now = int(DYN_ROOF_STATE["tick"])

        live = []
        for b in BOT_NAMES:
            try:
                if str(estado_bots.get(b, {}).get("modo_ia", "off")).lower() == "off":
                    continue
                if not ia_prob_valida(b, max_age_s=12.0):
                    continue
                p = float(estado_bots.get(b, {}).get("prob_ia", 0.0) or 0.0)
                n = int(estado_bots.get(b, {}).get("tamano_muestra", 0) or 0)
                if np.isfinite(p):
                    live.append((b, p, n))
            except Exception:
                continue

        if not live:
            DYN_ROOF_STATE["confirm_bot"] = None
            DYN_ROOF_STATE["confirm_streak"] = 0
            return out

        live.sort(key=lambda x: x[1], reverse=True)
        best_bot, p_best, n_best = live[0]
        p_second = float(live[1][1]) if len(live) > 1 else 0.0

        # Empates pr√°cticos del top (ej. 85.0%/85.0%/85.0%) pueden alternar
        # best_bot por ruido m√≠nimo y reiniciar confirmaci√≥n. Si el bot ya en
        # confirmaci√≥n sigue pr√°cticamente empatado con el top, lo mantenemos.
        try:
            tie_tol = float(DYN_ROOF_TIE_KEEP_CONFIRM_TOL)
            confirm_bot_prev = DYN_ROOF_STATE.get("confirm_bot")
            if isinstance(confirm_bot_prev, str) and confirm_bot_prev in {b for b, _p, _n in live}:
                p_confirm_prev = None
                n_confirm_prev = 0
                for b_live, p_live, n_live in live:
                    if b_live == confirm_bot_prev:
                        p_confirm_prev = float(p_live)
                        n_confirm_prev = int(n_live)
                        break
                if isinstance(p_confirm_prev, (int, float)) and abs(float(p_best) - float(p_confirm_prev)) <= float(tie_tol):
                    best_bot = str(confirm_bot_prev)
                    p_best = float(p_confirm_prev)
                    n_best = int(n_confirm_prev)
                    rest = [float(p) for b, p, _n in live if b != best_bot]
                    p_second = max(rest) if rest else 0.0
        except Exception:
            pass

        crowd_count = sum(1 for _b, p, _n in live if float(p) >= float(DYN_ROOF_CROWD_P_MIN))
        probs_live = [float(x[1]) for x in live]
        spread_std = float(np.std(probs_live)) if probs_live else 0.0

        prev_floor = DYN_ROOF_STATE.get("last_floor", None)
        if not isinstance(prev_floor, (int, float)) or abs(float(prev_floor) - float(floor_now)) > 1e-12:
            DYN_ROOF_STATE["roof"] = float(floor_now)
            DYN_ROOF_STATE["last_floor"] = float(floor_now)
            DYN_ROOF_STATE["last_touch_tick"] = int(tick_now)
            DYN_ROOF_STATE["melt_batches_applied"] = 0

        roof = float(DYN_ROOF_STATE.get("roof", floor_now) or floor_now)
        last_touch = int(DYN_ROOF_STATE.get("last_touch_tick", 0) or 0)

        # Regla A: tocar/romper techo resetea paciencia; romperlo adem√°s lo eleva.
        near_touch = float(p_best) >= float(roof - DYN_ROOF_NEAR_TOL)
        if near_touch:
            roof = max(float(roof), float(p_best))
            DYN_ROOF_STATE["roof"] = float(roof)
            DYN_ROOF_STATE["last_touch_tick"] = int(tick_now)
            DYN_ROOF_STATE["melt_batches_applied"] = 0
            last_touch = int(tick_now)
        else:
            # Regla B: derretido lento solo despu√©s de hold y por lotes.
            elapsed = int(tick_now - last_touch)
            if elapsed > int(DYN_ROOF_HOLD_TICKS):
                batches_now = int((elapsed - int(DYN_ROOF_HOLD_TICKS)) // int(DYN_ROOF_BATCH_TICKS))
                batches_applied = int(DYN_ROOF_STATE.get("melt_batches_applied", 0) or 0)
                if batches_now > batches_applied:
                    delta_batches = int(batches_now - batches_applied)
                    roof = max(float(floor_now), float(roof - (delta_batches * DYN_ROOF_STEP)))
                    DYN_ROOF_STATE["roof"] = float(roof)
                    DYN_ROOF_STATE["melt_batches_applied"] = int(batches_now)

        roof = float(DYN_ROOF_STATE.get("roof", floor_now) or floor_now)
        penalty = float(DYN_ROOF_LOW_N_PENALTY) if int(n_best) < int(DYN_ROOF_LOW_N_MIN) else 0.0
        roof_eff = float(roof + penalty)
        crowding = bool(crowd_count >= int(DYN_ROOF_CROWD_MIN_BOTS))
        if crowding:
            roof_eff = float(roof_eff + float(DYN_ROOF_CROWD_EXTRA_ROOF))

        # GAP din√°mico:
        # - Si solo hay 1 bot v√°lido, no se bloquea por GAP.
        # - En modo relajado (n>=15 en todos) pedimos micro-GAP cuando hay
        #   clustering en 70-80% para evitar m√°rgenes casi id√©nticos persistentes.
        if len(live) <= 1:
            gap_ok = True
        else:
            cluster_count = sum(1 for _b, p, _n in live if float(p) >= float(DYN_ROOF_CLUSTER_P_MIN))
            clustering_soft = bool(cluster_count >= int(DYN_ROOF_CLUSTER_MIN_BOTS))
            gap_req = float(DYN_ROOF_GAP)
            if crowding:
                gap_req += float(DYN_ROOF_CROWD_EXTRA_GAP)
            if modo_relajado_n15 and clustering_soft:
                gap_req = max(float(DYN_ROOF_CLUSTER_EXTRA_GAP), gap_req)
            elif modo_relajado_n15 and (not crowding):
                # Mantener modo B fluido cuando no hay clustering real.
                gap_req = 0.0
            gap_ok = bool((float(p_best) - float(p_second)) >= float(gap_req))

        clone_flat = bool(
            (len(live) >= 2)
            and (
                (spread_std < float(PROB_CLONE_STD_MIN))
                or ((float(p_best) - float(p_second)) < float(PROB_CLONE_GAP_MIN))
            )
        )
        smart_clone_override = _smart_clone_override_ok(best_bot, p_best, p_second, clone_flat)
        if clone_flat:
            gap_ok = False
        if smart_clone_override:
            gap_ok = True

        mode_c_active = bool(mode_c_candidate and float(p_best) < float(floor_now))
        gate_mode = "C" if mode_c_active else ("B" if modo_relajado_n15 else "A")
        floor_eff = float(DYN_ROOF_MODE_C_FLOOR) if mode_c_active else float(floor_now)

        # En modo relajado (n>=15 en todos): entrar con piso post-n15 sin depender del roof.
        if modo_relajado_n15:
            floor_gate = floor_eff if mode_c_active else floor_now
            pass_gate = bool((float(p_best) >= float(floor_now)) and bool(gap_ok))
        else:
            pass_gate = (
                (float(p_best) >= float(roof_eff))
                and (float(p_best) >= float(floor_eff))
                and bool(gap_ok)
            )
        if modo_relajado_n15:
            pass_gate = bool((float(p_best) >= float(floor_gate)) and bool(gap_ok))

        if mode_c_active:
            ev = _evidencia_bot_umbral_objetivo(best_bot)
            ev_n = int(ev.get("n", 0) or 0)
            ev_lb = float(ev.get("lb", 0.0) or 0.0)
            suceso_ok_mode_c = bool(estado_bots.get(best_bot, {}).get("ia_suceso_ok", False))
            pass_gate = bool(
                pass_gate
                and suceso_ok_mode_c
                and (ev_n >= int(DYN_ROOF_MODE_C_MIN_EVIDENCE_N))
                and (ev_lb >= float(DYN_ROOF_MODE_C_MIN_EVIDENCE_LB))
            )

        # Confirmaci√≥n: 2 ticks consecutivos del mismo bot.
        confirm_bot = DYN_ROOF_STATE.get("confirm_bot")
        confirm_streak = int(DYN_ROOF_STATE.get("confirm_streak", 0) or 0)
        if pass_gate:
            if confirm_bot == best_bot:
                confirm_streak += 1
            else:
                confirm_bot = best_bot
                confirm_streak = 1
        else:
            confirm_bot = None
            confirm_streak = 0

        DYN_ROOF_STATE["confirm_bot"] = confirm_bot
        DYN_ROOF_STATE["confirm_streak"] = int(confirm_streak)

        confirm_need = int(DYN_ROOF_MODE_C_CONFIRM_TICKS if mode_c_active else DYN_ROOF_CONFIRM_TICKS)
        allow_real = bool(pass_gate and (confirm_streak >= int(confirm_need)))
        allow_real_prev = bool(DYN_ROOF_STATE.get("allow_real_prev", False))
        gate_consumed = bool(DYN_ROOF_STATE.get("gate_consumed", False))
        rearm_streak = int(DYN_ROOF_STATE.get("gate_rearm_streak", 0) or 0)
        prev_probs = DYN_ROOF_STATE.get("prev_probs", {})
        if not isinstance(prev_probs, dict):
            prev_probs = {}
        prev_p_best = prev_probs.get(best_bot, None)
        crossed_up = bool(
            (isinstance(prev_p_best, (int, float)) and (float(prev_p_best) < float(floor_eff)) and (float(p_best) >= float(floor_eff)))
            or ((prev_p_best is None) and (float(p_best) >= float(floor_eff)))
        )
        suceso_ok = bool(estado_bots.get(best_bot, {}).get("ia_suceso_ok", False))

        if not allow_real:
            gate_consumed = False
            rearm_streak = 0
        elif gate_consumed:
            if float(p_best) <= float(roof_eff - DYN_ROOF_GATE_REARM_HYST):
                rearm_streak += 1
                if rearm_streak >= int(DYN_ROOF_GATE_REARM_TICKS):
                    gate_consumed = False
                    rearm_streak = 0
            else:
                rearm_streak = 0

        # Trigger de apertura:
        # - Modo A: exige cruce al alza (anti-r√°faga estricto).
        # - Modo B (post-n15): si ya hubo confirmaci√≥n sostenida, usar suceso_ok
        #   para no quedar "pegado" cuando p_best orbita el mismo nivel sin nuevo cruce.
        # - Modo C: mantiene criterio conservador basado en suceso_ok + evidencia.
        if mode_c_active:
            trigger_ok = bool(suceso_ok)
        elif modo_relajado_n15:
            trigger_ok = bool(suceso_ok or crossed_up)
        else:
            trigger_ok = bool(crossed_up)
        if warmup_mode and (not mode_c_active):
            # En modo B (post-n15) no anular trigger por warmup si la compuerta ya
            # pas√≥ allow_real y hay suceso_ok; evita bloqueo infinito en EXPERIMENTAL.
            if not modo_relajado_n15:
                trigger_ok = bool(trigger_ok and suceso_ok)
            else:
                trigger_ok = bool(trigger_ok)

        last_open_tick = int(DYN_ROOF_STATE.get("last_open_tick", 0) or 0)
        new_open = bool(
            allow_real
            and (not allow_real_prev)
            and trigger_ok
            and (not gate_consumed)
            and (last_open_tick != tick_now)
        )
        if new_open:
            DYN_ROOF_STATE["last_open_tick"] = int(tick_now)
        DYN_ROOF_STATE["allow_real_prev"] = bool(allow_real)
        DYN_ROOF_STATE["gate_consumed"] = bool(gate_consumed)
        DYN_ROOF_STATE["gate_rearm_streak"] = int(rearm_streak)
        DYN_ROOF_STATE["crowd_count"] = int(crowd_count)
        DYN_ROOF_STATE["last_p_best"] = float(p_best)
        DYN_ROOF_STATE["last_gate_mode"] = str(gate_mode)
        DYN_ROOF_STATE["last_floor_eff"] = float(floor_eff)
        DYN_ROOF_STATE["last_confirm_need"] = int(confirm_need)
        DYN_ROOF_STATE["last_trigger_ok"] = bool(trigger_ok)
        for b_live, p_live, _n_live in live:
            prev_probs[str(b_live)] = float(p_live)
        DYN_ROOF_STATE["prev_probs"] = prev_probs

        out.update({
            "best_bot": best_bot,
            "p_best": float(p_best),
            "p_second": float(p_second),
            "gap_ok": bool(gap_ok),
            "roof": float(roof),
            "roof_eff": float(roof_eff),
            "confirm_streak": int(confirm_streak),
            "allow_real": bool(allow_real),
            "n_best": int(n_best),
            "new_open": bool(new_open),
            "crowd_count": int(crowd_count),
            "crowding": bool(crowding),
            "crossed_up": bool(crossed_up),
            "suceso_ok": bool(suceso_ok),
            "trigger_ok": bool(trigger_ok),
            "gate_mode": str(gate_mode),
            "stall_s": float(stall_s),
            "floor_eff": float(floor_eff),
            "confirm_need": int(confirm_need),
            "clone_flat": bool(clone_flat),
            "smart_clone_override": bool(smart_clone_override),
            "spread_std": float(spread_std),
        })
        return out
    except Exception:
        return out


def _umbral_senal_actual_hud() -> float:
    """
    Umbral visual para "IA SE√ëALES ACTUALES".
    - En compuerta cl√°sica din√°mica: el candado duro es FLOOR (70%).
    - Fuera de ese modo: conserva IA_METRIC_THRESHOLD.
    """
    try:
        if bool(REAL_CLASSIC_GATE):
            return float(DYN_ROOF_FLOOR)
        return float(IA_METRIC_THRESHOLD)
    except Exception:
        return float(IA_METRIC_THRESHOLD)

# Cargar datos bot
# Cargar datos bot
async def cargar_datos_bot(bot, token_actual):
    ruta = f"registro_enriquecido_{bot}.csv"
    if not os.path.exists(ruta):
        return

    try:
        snapshot = SNAPSHOT_FILAS.get(bot, 0)

        # Fuente de verdad de owner REAL para no pintar DEMO transitorio en HUD/tabla.
        effective_owner = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else (token_actual if token_actual in BOT_NAMES else next((b for b in BOT_NAMES if estado_bots.get(b, {}).get("token") == "REAL"), None))

        # Sincroniza token visual SIEMPRE, incluso si no entran filas nuevas este tick.
        estado_bots[bot]["token"] = "REAL" if effective_owner == bot else "DEMO"

        # Gate r√°pido (opcional): si el archivo no creci√≥, salimos sin leer todo el CSV
        actual = contar_filas_csv(bot)
        if actual <= snapshot:
            return

        df = pd.read_csv(ruta, encoding="utf-8", on_bad_lines="skip")
        if df.empty:
            # Lectura temporalmente vac√≠a (archivo en escritura / parse fall√≥).
            # NO resetees SNAPSHOT_FILAS porque provoca re-procesos y ruido.
            return

        # Si snapshot qued√≥ desfasado frente al df real, lo corregimos
        if snapshot >= len(df):
            SNAPSHOT_FILAS[bot] = len(df)
            return

        nuevas = df.iloc[snapshot:]
        # IMPORTANTE: el snapshot debe seguir a df (no a contar_filas_csv),
        # porque read_csv puede saltarse l√≠neas malas con on_bad_lines="skip".
        SNAPSHOT_FILAS[bot] = len(df)

        required_cols = [
            "rsi_9", "rsi_14", "sma_5", "cruce_sma", "breakout",
            "rsi_reversion", "racha_actual", "puntaje_estrategia"
        ]
        try:
            _, _, features_live, _ = get_oracle_assets()
            if isinstance(features_live, list) and features_live:
                for feat in features_live:
                    if isinstance(feat, str) and feat and feat not in required_cols:
                        required_cols.append(feat)
            elif "sma_20" not in required_cols:
                required_cols.append("sma_20")
        except Exception:
            if "sma_20" not in required_cols:
                required_cols.append("sma_20")

        for _, row in nuevas.iterrows():
            fila_dict = canonicalizar_campos_bot_maestro(row.to_dict())

            try:
                if fila_dict.get("payout") in (None, ""):
                    payout_feat = calcular_payout_feature(fila_dict)
                    if payout_feat is not None:
                        fila_dict["payout"] = float(payout_feat)
                if fila_dict.get("volatilidad") in (None, ""):
                    fila_dict["volatilidad"] = float(calcular_volatilidad_simple(fila_dict))
                if fila_dict.get("hora_bucket") in (None, ""):
                    fila_dict["hora_bucket"] = float(calcular_hora_bucket(fila_dict))
                if fila_dict.get("sma_spread") in (None, ""):
                    sp = _calcular_sma_spread_robusto(fila_dict)
                    if sp is not None:
                        fila_dict["sma_spread"] = float(sp)
            except Exception:
                pass

            trade_status = str(fila_dict.get("trade_status", "")).strip().upper()
            resultado = normalizar_resultado(fila_dict.get("resultado", ""))

            try:
                ep_dec = int(float(fila_dict.get("epoch", 0) or 0))
                cyc_dec = int(float(fila_dict.get("ciclo_martingala", fila_dict.get("ciclo", 1)) or 1))
            except Exception:
                ep_dec, cyc_dec = 0, 1
            token_dec = "REAL" if effective_owner == bot else "DEMO"
            act_dec = str(fila_dict.get("activo", ""))
            dir_dec = str(fila_dict.get("direction", fila_dict.get("direccion", "")) or "")
            estado_bots[bot]["ia_decision_id"] = f"{bot}|{ep_dec}|C{cyc_dec}|{act_dec}|{dir_dec}|{token_dec}"

            # =========================
            # 1) FILAS NO-CERRADAS (PRE_TRADE / incompletas)
            #    - Calculamos Prob IA para el HUD
            #    - NO tocamos historial, n, ni %√©xito (evita los ‚Äú¬∑‚Äù intercalados)
            # =========================
            if resultado not in ("GANANCIA", "P√âRDIDA"):
                # Guarda epoch PRE m√°s reciente para heartbeat ACK (sin depender de filas nuevas constantes)
                try:
                    ep_pre = fila_dict.get("epoch", 0)
                    ep_pre = int(float(ep_pre)) if str(ep_pre).strip() != "" else 0
                    if ep_pre > 0:
                        estado_bots[bot]["ultimo_epoch_pretrade"] = ep_pre
                except Exception:
                    pass

                # Si el bot marc√≥ CERRADO pero no trajo resultado v√°lido,
                # cerramos se√±al pendiente (si exist√≠a) sin contaminar historial.
                if trade_status == "CERRADO":
                    if estado_bots[bot].get("ia_senal_pendiente"):
                        estado_bots[bot]["ia_senal_pendiente"] = False
                        estado_bots[bot]["ia_prob_senal"] = None

                    estado_bots[bot]["token"] = "REAL" if effective_owner == bot else "DEMO"
                    last_update_time[bot] = time.time()
                    continue

                missing = [col for col in required_cols if pd.isna(fila_dict.get(col))]
                if missing:
                    agregar_evento(f"‚ö†Ô∏è {bot}: PRE_TRADE incompleto, faltan {len(missing)} cols: {missing[:5]}")
                    # IMPORTANTE: si falta data, no inventamos 0.0 (queda sin predicci√≥n)
                    estado_bots[bot]["prob_ia"] = None
                    estado_bots[bot]["modo_ia"] = "off"
                    estado_bots[bot]["ia_ready"] = False

                    meta = leer_model_meta() or {}
                    escribir_ia_ack(bot, fila_dict.get("epoch"), None, "OFF", meta)

                else:
                    try:
                        prob_ia, modo_ia = oraculo_predict_visible(fila_dict)

                        # Normaliza (evita 'OFF' vs 'off' y valores fuera de rango)
                        modo_norm = str(modo_ia or "off").strip().lower()
                        prob_norm = None
                        try:
                            if prob_ia is not None:
                                p = float(prob_ia)
                                if 0.0 <= p <= 1.0:
                                    prob_norm = p
                        except Exception:
                            prob_norm = None

                        prob_norm = _ajustar_prob_operativa(prob_norm)
                        estado_bots[bot]["prob_ia"] = prob_norm
                        estado_bots[bot]["modo_ia"] = modo_norm

                        meta = leer_model_meta() or {}
                        reliable = bool(meta.get("reliable", False))
                        n_inc = contar_filas_incremental()
                        rows = int(n_inc or 0)
                        estado_bots[bot]["ia_ready"] = bool(
                            reliable and (rows >= MIN_FIT_ROWS_LOW) and (modo_norm != "off") and (prob_norm is not None)
                        )

                        escribir_ia_ack(bot, fila_dict.get("epoch"), prob_norm, modo_norm.upper(), meta)

                    except Exception as e:
                        agregar_evento(f"‚ö†Ô∏è {bot}: PRED_FAIL pretrade: {type(e).__name__}")
                        estado_bots[bot]["prob_ia"] = None
                        estado_bots[bot]["modo_ia"] = "off"
                        estado_bots[bot]["ia_ready"] = False

                        meta = leer_model_meta() or {}
                        escribir_ia_ack(bot, fila_dict.get("epoch"), None, "OFF", meta)



                estado_bots[bot]["token"] = "REAL" if effective_owner == bot else "DEMO"
                last_update_time[bot] = time.time()
                continue

            # =========================
            # 2) FILAS CERRADAS (GANANCIA / P√âRDIDA)
            #    - Aqu√≠ s√≠ actualizamos historial y estad√≠sticas reales
            # =========================
            estado_bots[bot]["ultimo_resultado"] = resultado
            estado_bots[bot]["resultados"].append(resultado)
            estado_bots[bot]["tamano_muestra"] += 1

            if resultado == "GANANCIA":
                estado_bots[bot]["ganancias"] += 1
            elif resultado == "P√âRDIDA":
                estado_bots[bot]["perdidas"] += 1

            total = estado_bots[bot]["tamano_muestra"]
            if total > 0:
                estado_bots[bot]["porcentaje_exito"] = (estado_bots[bot]["ganancias"] / total) * 100

            # Cierre especial para REAL manual: SIEMPRE 1 sola operaci√≥n
            if (
                MODO_REAL_MANUAL
                and estado_bots[bot].get("fuente") == "MANUAL"
                and resultado in ("GANANCIA", "P√âRDIDA")
            ):
                reason = f"REAL manual: {resultado} ‚Üí una operaci√≥n y regreso a DEMO"
                cerrar_por_fin_de_ciclo(bot, reason)
                agregar_evento(f"‚úÖ REAL MANUAL cerrado para {bot.upper()} tras {resultado}. Volviendo a DEMO.")

            # --- Contadores de IA: SOLO cuando llega un cierre real ---
            if estado_bots[bot].get("ia_senal_pendiente"):
                prob_senal = estado_bots[bot].get("ia_prob_senal")
                thr_ia = get_umbral_operativo()

                if prob_senal is not None and prob_senal >= thr_ia:
                    estado_bots[bot]["ia_seniales"] += 1
                    if resultado == "GANANCIA":
                        estado_bots[bot]["ia_aciertos"] += 1
                    elif resultado == "P√âRDIDA":
                        estado_bots[bot]["ia_fallos"] += 1

                if prob_senal is not None and prob_senal >= float(IA_ACTIVACION_REAL_THR):
                    IA90_stats[bot]["n"] += 1
                    if resultado == "GANANCIA":
                        IA90_stats[bot]["ok"] += 1

                n_ia90 = IA90_stats[bot]["n"]
                ok_ia90 = IA90_stats[bot]["ok"]
                if n_ia90 > 0:
                    pct_raw = (ok_ia90 / n_ia90) * 100.0
                    pct_suav = (ok_ia90 + 1) / (n_ia90 + 2) * 100.0
                    IA90_stats[bot]["pct_raw"] = pct_raw
                    IA90_stats[bot]["pct_smooth"] = pct_suav
                    # En HUD principal usamos el porcentaje crudo para mantener
                    # consistencia exacta con la fracci√≥n ok/n.
                    IA90_stats[bot]["pct"] = pct_raw
                else:
                    IA90_stats[bot]["pct_raw"] = 0.0
                    IA90_stats[bot]["pct_smooth"] = 50.0
                    IA90_stats[bot]["pct"] = 0.0

                # Cerramos se√±al pendiente SOLO aqu√≠ (en cierre)
                estado_bots[bot]["ia_senal_pendiente"] = False
                estado_bots[bot]["ia_prob_senal"] = None

            estado_bots[bot]["token"] = "REAL" if effective_owner == bot else "DEMO"
            last_update_time[bot] = time.time()

        # Mant√©n tu pipeline incremental como estaba
        anexar_incremental_desde_bot(bot)

    except Exception as e:
        print(f"‚ö†Ô∏è Error cargando datos para {bot}: {e}")

# Obtener saldo real
async def obtener_saldo_real():
    global saldo_real, ULTIMA_ACT_SALDO
    token_demo, token_real = leer_tokens_usuario()
    if not token_real:
        return
    if not WEBSOCKETS_OK:
        return
    try:
        async with websockets.connect(DERIV_WS_URL) as ws:
            auth_msg = json.dumps({"authorize": token_real})
            await ws.send(auth_msg)
            resp = json.loads(await ws.recv())
            if "error" in resp:
                print(f"‚ö†Ô∏è Error en auth: {resp['error']['message']}")
                return
            bal_msg = json.dumps({"balance": 1, "subscribe": 1})
            await ws.send(bal_msg)
            resp = json.loads(await ws.recv())
            if "error" in resp:
                print(f"‚ö†Ô∏è Error en balance: {resp['error']['message']}")
                return
            if "balance" in resp:
                saldo_real = f"{resp['balance']['balance']:.2f}"
                ULTIMA_ACT_SALDO = time.time()
    except Exception as e:
        print(f"‚ö†Ô∏è Error obteniendo saldo: {e}")

async def refresh_saldo_real(forzado=False):
    global ULTIMA_ACT_SALDO
    if forzado or time.time() - ULTIMA_ACT_SALDO > REFRESCO_SALDO:
        await obtener_saldo_real()

def obtener_valor_saldo():
    global saldo_real
    try:
        return float(saldo_real)
    except:
        return None

def inicializar_saldo_real(valor):
    global SALDO_INICIAL, META
    SALDO_INICIAL = round(valor, 2)
    META = round(SALDO_INICIAL * 1.20, 2)

# Escuchar teclas
def escuchar_teclas():
    global pausado, salir, reinicio_manual, LIMPIEZA_PANEL_HASTA, HUD_VISIBLE
    global PENDIENTE_FORZAR_BOT, PENDIENTE_FORZAR_INICIO, PENDIENTE_FORZAR_EXPIRA

    bot_map = {'5': 'fulll45', '6': 'fulll46', '7': 'fulll47', '8': 'fulll48', '9': 'fulll49', '0': 'fulll50'}
    last_key_time = 0  # debounce 200 ms

    while True:
        if MODAL_ACTIVO:
            time.sleep(0.1); continue

        now = time.time()
        if HAVE_MSVCRT and msvcrt.kbhit():
            if now - last_key_time < 0.2:
                time.sleep(0.05); continue
            last_key_time = now

            try:
                k = msvcrt.getch()
                if k in (b'\x00', b'\xe0'):  
                    msvcrt.getch(); continue
                k = k.decode("utf-8", errors="ignore").lower()
            except:
                continue

            if k == "s":
                print("\n\nüî¥ Saliendo del programa..."); salir = True; break
            elif k == "p":
                pausado = True; print("\n‚è∏Ô∏è Programa pausado. Presiona [C] para continuar.")
            elif k == "c":
                pausado = False; print("\n‚ñ∂Ô∏è Programa reanudado.")
            elif k == "r":
                reinicio_manual = True; print("\nüîÅ Reinicio de Martingala solicitado.")
            elif k == "t":
                tok = leer_token_actual(); print(f"\nüîç TOKEN ACTUAL: {tok or 'none'}")
            elif k == "l":
                LIMPIEZA_PANEL_HASTA = time.time() + 15; print("\nüéπ Limpieza visual‚Ä¶")
            elif k == "d":
                reiniciar_completo(borrar_csv=False, limpiar_visual_segundos=15, modo_suave=True); print("\nüßΩ Limpieza dura ejecutada.")
            elif k == "g":
                reproducir_evento("test", es_demo=True, dentro_gatewin=True); print("\nüéµ Test de audio‚Ä¶")
            elif k == "e":
                try:
                    # Cooldown anti-repetici√≥n (Windows repite tecla y entrena 2 veces)
                    if "LAST_MANUAL_RETRAIN_TS" not in globals():
                        globals()["LAST_MANUAL_RETRAIN_TS"] = 0.0
                    nowt = time.time()
                    if (nowt - float(globals()["LAST_MANUAL_RETRAIN_TS"])) < 30.0:
                        agregar_evento("üß† Entrenamiento ignorado (cooldown 30s).")
                    else:
                        globals()["LAST_MANUAL_RETRAIN_TS"] = nowt
                        maybe_retrain(force=True)
                        print("\nüß† Entrenamiento forzado.")
                except Exception as e:
                    print(f"\n‚ö†Ô∏è No se pudo entrenar: {e}")

            elif k in bot_map:
                PENDIENTE_FORZAR_BOT = bot_map[k]
                PENDIENTE_FORZAR_INICIO = time.time()
                PENDIENTE_FORZAR_EXPIRA = PENDIENTE_FORZAR_INICIO + VENTANA_DECISION_IA_S
                agregar_evento(f"üéØ Bot seleccionado: {PENDIENTE_FORZAR_BOT}. Elige ciclo [1..{MAX_CICLOS}] o ESC.")
                with RENDER_LOCK:
                    mostrar_panel()

            elif PENDIENTE_FORZAR_BOT and k.isdigit() and k in [str(i) for i in range(1, MAX_CICLOS+1)]:
                ciclo = int(k)
                bot_sel = PENDIENTE_FORZAR_BOT
                PENDIENTE_FORZAR_BOT = None
                PENDIENTE_FORZAR_INICIO = 0.0
                PENDIENTE_FORZAR_EXPIRA = 0.0
                forzar_real_manual(bot_sel, ciclo)

            elif PENDIENTE_FORZAR_BOT and k == "\x1b":  # ESC
                agregar_evento("‚ùé Forzar REAL cancelado.")
                PENDIENTE_FORZAR_BOT = None
                PENDIENTE_FORZAR_INICIO = 0.0
                PENDIENTE_FORZAR_EXPIRA = 0.0
                with RENDER_LOCK:
                    mostrar_panel()

        else:
            time.sleep(0.05)

if sys.stdout.isatty():
    threading.Thread(target=escuchar_teclas, daemon=True).start()

# Main - A√±adida pasada inicial para sincronizar HUD con CSV existentes
DIAGNOSTIC_MODE = ("--diagnostico" in sys.argv) or (os.getenv("MAESTRO_DIAGNOSTICO", "0") == "1")


def _log_exception(tag: str, exc: Exception | None = None):
    try:
        ts = time.strftime('%F %T')
        detail = traceback.format_exc()
        if exc is not None and (not detail or detail.strip() == "NoneType: None"):
            detail = f"{type(exc).__name__}: {exc}"
        with open("crash.log", "a", encoding="utf-8") as f:
            f.write(f"[{ts}] {tag}\n{detail}\n")
    except Exception:
        pass



def _auditar_saturacion_features_bot(bot: str, lookback: int = 800) -> dict:
    """Diagn√≥stico ligero de features casi-constantes en CERRADO."""
    out = {"ok": False, "bot": bot, "n": 0, "dominance": {}}
    ruta = f"registro_enriquecido_{bot}.csv"
    if not os.path.exists(ruta):
        return out
    try:
        df = pd.read_csv(ruta, sep=",", encoding="utf-8", engine="python", on_bad_lines="skip")
    except Exception:
        return out
    if df is None or df.empty:
        return out
    try:
        if "resultado" in df.columns:
            rr = df["resultado"].astype(str).str.upper().str.strip()
            df = df[rr.isin(["GANANCIA", "P√âRDIDA", "PERDIDA"])].copy()
    except Exception:
        pass
    if df.empty:
        return out
    if int(lookback) > 0 and len(df) > int(lookback):
        df = df.tail(int(lookback)).copy()

    cols = ["cruce_sma", "breakout", "rsi_reversion", "puntaje_estrategia"]
    out["n"] = int(len(df))
    out["ok"] = True
    for c in cols:
        if c not in df.columns:
            continue
        s = pd.to_numeric(df[c], errors="coerce").dropna()
        if s.empty:
            continue
        vc = s.value_counts(dropna=False)
        dom = float(vc.iloc[0]) / float(max(1, len(s)))
        out["dominance"][c] = float(dom)
    return out


def _auditar_saturacion_todos_bots(lookback: int = 800) -> dict:
    """Resume saturaci√≥n de se√±ales por bot (no bloqueante)."""
    out = {"bots": {}, "hot_bots": []}
    for b in BOT_NAMES:
        rep = _auditar_saturacion_features_bot(b, lookback=lookback)
        out["bots"][b] = rep
        dom = rep.get("dominance", {}) if isinstance(rep, dict) else {}
        hot = [k for k, v in dom.items() if isinstance(v, (int, float)) and v >= 0.90]
        if hot:
            out["hot_bots"].append({"bot": b, "features": hot, "dominance": dom})
    return out


def _auditar_calidad_incremental(path: str = "dataset_incremental.csv") -> dict:
    """Chequeo liviano de calidad de labels para detectar n-meta inflado."""
    out = {"ok": False, "rows": 0, "valid": 0, "invalid": 0, "path": path}
    if not os.path.exists(path):
        return out
    try:
        df = pd.read_csv(path, sep=",", encoding="utf-8", engine="python", on_bad_lines="skip")
    except Exception:
        return out
    if df is None or df.empty:
        out["ok"] = True
        return out
    out["rows"] = int(len(df))
    if "result_bin" not in df.columns:
        out["invalid"] = int(len(df))
        out["ok"] = True
        return out
    rb = pd.to_numeric(df["result_bin"], errors="coerce")
    valid_mask = rb.isin([0, 1])
    out["valid"] = int(valid_mask.sum())
    out["invalid"] = int((~valid_mask).sum())
    out["ok"] = True
    return out

def _auditar_salud_features_incremental(path: str = "dataset_incremental.csv") -> dict:
    """Diagn√≥stico de presencia/variaci√≥n para core-13 en incremental."""
    core13 = [
        "rsi_9","rsi_14","sma_5","sma_spread","cruce_sma","breakout",
        "rsi_reversion","racha_actual","payout","puntaje_estrategia",
        "volatilidad","es_rebote","hora_bucket",
    ]
    out = {"ok": False, "path": path, "rows": 0, "missing": [], "dominance": {}, "low_var": []}
    if not os.path.exists(path):
        return out
    try:
        df = pd.read_csv(path, sep=",", encoding="utf-8", engine="python", on_bad_lines="skip")
    except Exception:
        return out
    if df is None or df.empty:
        out["ok"] = True
        return out

    out["rows"] = int(len(df))
    out["missing"] = [c for c in core13 if c not in df.columns]
    for c in core13:
        if c not in df.columns:
            continue
        s = pd.to_numeric(df[c], errors="coerce").dropna()
        if s.empty:
            out["low_var"].append(c)
            out["dominance"][c] = 1.0
            continue
        top = float(s.value_counts(normalize=True, dropna=True).iloc[0])
        uniq = int(s.nunique(dropna=True))
        out["dominance"][c] = top
        if uniq <= 2:
            out["low_var"].append(c)

    out["ok"] = True
    return out



def _boot_health_check():
    msgs = []
    try:
        if not WEBSOCKETS_OK:
            msgs.append("‚ö†Ô∏è Dependencia faltante: websockets (sin WS/saldo, resto del HUD sigue).")
        if not PYGAME_OK:
            msgs.append("‚ö†Ô∏è Dependencia faltante: pygame (audio desactivado, ejecuci√≥n contin√∫a).")
        csv_presentes = [b for b in BOT_NAMES if os.path.exists(f"registro_enriquecido_{b}.csv")]
        if not csv_presentes:
            msgs.append("‚ö†Ô∏è No hay CSV enriquecidos de bots todav√≠a; esperando generaci√≥n de datos.")
        if not os.access(os.getcwd(), os.W_OK):
            msgs.append("‚ö†Ô∏è Sin permisos de escritura en cwd (no se podr√°n persistir logs/modelos).")

        # Se√±ales congeladas: diagn√≥stico operativo r√°pido por bot (no bloqueante)
        sat_all = _auditar_saturacion_todos_bots(lookback=900)
        hot_bots = sat_all.get("hot_bots", []) if isinstance(sat_all, dict) else []
        for hb in hot_bots[:6]:
            bot = hb.get("bot", "?")
            dom = hb.get("dominance", {}) if isinstance(hb.get("dominance", {}), dict) else {}
            feats = hb.get("features", []) if isinstance(hb.get("features", []), list) else []
            hot = [f"{k}={float(dom.get(k, 0.0))*100:.1f}%" for k in feats]
            if hot:
                msgs.append(f"‚ö†Ô∏è Features saturadas en {bot}: " + ", ".join(hot))

        # Calidad de labels del incremental (si hay inv√°lidas, la IA aprende con humo)
        incq = _auditar_calidad_incremental("dataset_incremental.csv")
        if incq.get("ok", False):
            rows = int(incq.get("rows", 0) or 0)
            invalid = int(incq.get("invalid", 0) or 0)
            valid = int(incq.get("valid", 0) or 0)
            if rows > 0 and invalid > 0:
                msgs.append(f"‚ö†Ô∏è Incremental con labels inv√°lidas: valid={valid}, invalid={invalid}, total={rows}.")

        # Salud de features core-13: presencia + variaci√≥n + dominancia
        featq = _auditar_salud_features_incremental("dataset_incremental.csv")
        if featq.get("ok", False):
            miss = featq.get("missing", []) or []
            low = featq.get("low_var", []) or []
            dom = featq.get("dominance", {}) or {}
            hot = [k for k, v in dom.items() if isinstance(v, (int, float)) and v >= FEATURE_MAX_DOMINANCE]
            if miss:
                msgs.append("‚ö†Ô∏è Incremental core-13 faltantes: " + ", ".join(miss))
            if low:
                msgs.append("‚ö†Ô∏è Incremental features con baja variaci√≥n (nunique<=2): " + ", ".join(low))
            if hot:
                tops = [f"{k}={float(dom.get(k, 0.0))*100:.1f}%" for k in hot]
                msgs.append("‚ö†Ô∏è Incremental features dominantes (>90%): " + ", ".join(tops))
    except Exception as e:
        msgs.append(f"‚ö†Ô∏è Health-check parcial con error: {e}")
    return msgs


async def main():
    global salir, pausado, reinicio_manual, SALDO_INICIAL
    global PENDIENTE_FORZAR_BOT, PENDIENTE_FORZAR_INICIO, PENDIENTE_FORZAR_EXPIRA, REAL_OWNER_LOCK
    global REAL_LOCK_MISMATCH_SINCE

    try:
        set_etapa("BOOT_01", "Inicializando main()", anunciar=True)
        # Seguridad: NO borrar real.lock al arrancar; evita carreras entre instancias.
        set_etapa("BOOT_02", "Leyendo tokens de usuario")
        tokens = leer_tokens_usuario()
        if tokens == (None, None):
            print("‚ö†Ô∏è Tokens ausentes. Modo sin-saldo activo (HUD/IA contin√∫an).")
        init_audio()
        for _msg in _boot_health_check():
            print(_msg)
            try:
                agregar_evento(_msg)
            except Exception:
                pass

        if DIAGNOSTIC_MODE:
            print("üß™ MODO DIAGN√ìSTICO activo: sin auto-operaci√≥n REAL.")
            globals()["MODO_REAL_MANUAL"] = True

        if RESET_ON_START:
            for nb in BOT_NAMES:
                resetear_csv_bot(nb)
            resetear_incremental_y_modelos(borrar_modelos=True)
            resetear_estado_hud(estado_bots)
            print("üßº Sesi√≥n limpia: CSVs de bots, dataset incremental y estado HUD reiniciados.")
        elif AUTO_REPAIR_ON_START:
            for _msg in _asegurar_estructura_datos_inicio():
                print(_msg)
                try:
                    agregar_evento(_msg)
                except Exception:
                    pass
        reiniciar_completo(borrar_csv=False, limpiar_visual_segundos=15, modo_suave=True)
        loop = asyncio.get_running_loop()
        set_main_loop(loop)
        await refresh_saldo_real(forzado=True)
        valor = obtener_valor_saldo()
        if valor is not None:
            inicializar_saldo_real(valor)

        set_etapa("BOOT_03", "Backfill y primer entrenamiento")
        # Backfill IA desde los logs enriquecidos
        try:
            backfill_incremental(ultimas=1500)
        except Exception as e:
            agregar_evento(f"‚ö†Ô∏è IA: error en backfill inicial: {e}")

        # Intentar un primer entrenamiento, si ya hay suficientes filas
        try:
            maybe_retrain(force=True)
        except Exception as e:
            agregar_evento(f"‚ö†Ô∏è IA: error al intentar entrenar tras el backfill: {e}")

        set_etapa("BOOT_04", "Sincronizando HUD con CSV")
        # Pasada inicial para sincronizar HUD con CSV existentes
        token_actual_loop = "--"  # Dummy para carga inicial
        for bot in BOT_NAMES:
            await cargar_datos_bot(bot, token_actual_loop)

        while True:
            if salir:
                set_etapa("STOP", "Se√±al de salida detectada", anunciar=True)
                break
            if pausado:
                await asyncio.sleep(1)
                continue
            if reinicio_manual:
                reinicio_manual = False
                reiniciar_completo(borrar_csv=False, limpiar_visual_segundos=15, modo_suave=True)
                await refresh_saldo_real(forzado=True)

            try:  
                set_etapa("TICK_01")
                token_actual_loop = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else (leer_token_actual() or next((b for b in BOT_NAMES if estado_bots.get(b, {}).get("token") == "REAL"), None))

                # Reconciliaci√≥n anti-desincron√≠a maestro‚Üîbots:
                # si memoria dice REAL pero token_actual.txt ya est√° en none por varios segundos,
                # liberamos lock fantasma para permitir nuevas asignaciones REAL correctas.
                owner_mem_now = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None
                owner_file_now = leer_token_archivo_raw()
                if owner_mem_now and (owner_file_now is None):
                    if REAL_LOCK_MISMATCH_SINCE <= 0.0:
                        REAL_LOCK_MISMATCH_SINCE = time.time()
                    elif (time.time() - REAL_LOCK_MISMATCH_SINCE) >= float(REAL_LOCK_RECONCILE_S):
                        agregar_evento(f"ü©π Reconciliaci√≥n lock REAL: liberando owner fantasma {owner_mem_now.upper()} (archivo token ya est√° en none).")
                        try:
                            _set_ui_token_holder(None)
                        except Exception:
                            pass
                        REAL_OWNER_LOCK = None
                        REAL_LOCK_MISMATCH_SINCE = 0.0
                        token_actual_loop = leer_token_actual() or None
                else:
                    REAL_LOCK_MISMATCH_SINCE = 0.0
                # Heartbeat: mantiene ACK alineado al HUD aunque no entren filas nuevas ese tick.
                refrescar_ia_ack_desde_hud(intervalo_s=1.0)
                owner_mem = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None
                owner_file = token_actual_loop if token_actual_loop in BOT_NAMES else None
                activo_real = owner_mem or owner_file or next((b for b in BOT_NAMES if estado_bots[b]["token"] == "REAL"), None)
                if activo_real in BOT_NAMES:
                    _set_ui_token_holder(activo_real)
                    _enforce_single_real_standby(activo_real)
                for bot in BOT_NAMES:
                    try:  # Aislamiento per-bot para evitar skips globales
                        if reinicio_forzado.is_set():
                            # Menos ruido: no agregar evento si repetido
                            reinicio_forzado.clear()
                            # No mostrar_panel inmediato; dejar al tick
                            break
                        await cargar_datos_bot(bot, token_actual_loop)
                        # Evita desincronizar REAL por inactividad normal durante contrato.
                        # El owner REAL se vigila en TICK_02 (watchdog sin salida a DEMO).
                        if time.time() - last_update_time[bot] > 60:
                            if estado_bots.get(bot, {}).get("token") != "REAL":
                                reiniciar_bot(bot)
                    except Exception as e_bot:
                        agregar_evento(f"‚ö†Ô∏è Error en {bot}: {e_bot}")
                else:
                    # Reentreno peri√≥dico no bloqueante (evita quedarse en OFF si boot ocurri√≥ con pocos datos)
                    try:
                        now_rt = time.time()
                        if (now_rt - float(globals().get("_LAST_AUTO_RETRAIN_TICK", 0.0) or 0.0)) >= float(AUTO_RETRAIN_TICK_S):
                            globals()["_LAST_AUTO_RETRAIN_TICK"] = now_rt
                            maybe_retrain(force=False)
                    except Exception:
                        pass

                    set_etapa("TICK_02")
                    # Watchdog para REAL pegado
                    ahora = time.time()
                    for bot in BOT_NAMES:
                        if estado_bots[bot]["token"] == "REAL":
                            t_last = last_update_time.get(bot, 0)
                            t_real = estado_bots[bot].get("real_activado_en", 0.0)
                            # Si lleva demasiado sin actualizarse desde que entr√≥ a REAL:
                            # NO salir a DEMO aqu√≠: la salida solo ocurre con cierre GANANCIA/P√âRDIDA.
                            if t_real > 0 and (ahora - max(t_last, t_real) > REAL_TIMEOUT_S):
                                first_warn = float(estado_bots[bot].get("real_timeout_first_warn", 0.0) or 0.0)
                                if first_warn <= 0.0:
                                    estado_bots[bot]["real_timeout_first_warn"] = ahora
                                    agregar_evento(f"‚è±Ô∏è Seguridad: {bot} sin actividad reciente en REAL. Esperando cierre por {REAL_STUCK_FORCE_RELEASE_S}s antes de liberar.")
                                elif (ahora - first_warn) > REAL_STUCK_FORCE_RELEASE_S:
                                    agregar_evento(f"üßØ Timeout REAL en {bot}: sin cierre confirmado. Liberando a DEMO sin avanzar martingala.")
                                    cerrar_por_fin_de_ciclo(bot, "Timeout sin cierre")
                                    activo_real = None
                                    break

                    for bot in BOT_NAMES:
                        if estado_bots[bot]["token"] == "REAL":
                            # Detecta el √∫ltimo cierre REAL de forma robusta (sin depender de SNAPSHOT_FILAS,
                            # porque TICK_01 ya puede haber avanzado el snapshot antes de este bloque).
                            cierre_info = detectar_cierre_martingala(
                                bot,
                                min_fila=REAL_ENTRY_BASELINE.get(bot, 0),
                                require_closed=True,
                                require_real_token=True,
                                expected_ciclo=estado_bots.get(bot, {}).get("ciclo_actual", None),
                            )

                            # Ventana anti-stale tras activar REAL (protecci√≥n vigente)
                            if time.time() < (estado_bots[bot].get("ignore_cierres_hasta") or 0):
                                cierre_info = None

                            # Cierre inmediato: en REAL siempre 1 operaci√≥n y vuelve a DEMO (gane o pierda)
                            if cierre_info and isinstance(cierre_info, tuple) and len(cierre_info) >= 4:
                                res, monto, ciclo, payout_total = cierre_info
                                sig = (res, round(float(monto or 0.0), 2), int(ciclo or 0), round(float(payout_total or 0.0), 4))

                                # Evita reprocesar el mismo cierre en ticks consecutivos
                                if sig == LAST_REAL_CLOSE_SIG.get(bot):
                                    continue

                                LAST_REAL_CLOSE_SIG[bot] = sig

                                if res in ("GANANCIA", "P√âRDIDA"):
                                    registrar_resultado_real(res, bot=bot, ciclo_operado=ciclo)
                                    if res == "GANANCIA":
                                        cerrar_por_fin_de_ciclo(bot, "Ganancia en REAL (fin de turno)")
                                    else:
                                        cerrar_por_fin_de_ciclo(bot, "P√©rdida en REAL (fin de turno)")
                                    activo_real = None
                                    break

                    if not activo_real:
                        set_etapa("TICK_03")

                        # üîí Lock estricto: una sola inversi√≥n REAL a la vez.
                        # Si token_actual.txt o el estado en memoria ya tienen due√±o REAL,
                        # no evaluamos ni promovemos otro bot aunque cumpla umbral.
                        owner_lock = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
                        holder_memoria = next((b for b in BOT_NAMES if estado_bots.get(b, {}).get("token") == "REAL"), None)
                        lock_activo = (owner_lock in BOT_NAMES) or (holder_memoria in BOT_NAMES)
                        if lock_activo:
                            activo_real = owner_lock if owner_lock in BOT_NAMES else holder_memoria
                            _enforce_single_real_standby(activo_real)

                        # Umbral maestro calibrado con hist√≥ricos de Prob IA (top quantil),
                        # acotado por [AUTO_REAL_THR_MIN .. AUTO_REAL_THR] para activar REAL
                        # usando los valores altos observados recientemente.
                        if REAL_CLASSIC_GATE:
                            umbral_ia_real = float(_umbral_real_operativo_actual())
                            dyn_gate = _actualizar_compuerta_techo_dinamico()
                            if isinstance(dyn_gate, dict) and bool(dyn_gate.get("new_open", False)):
                                agregar_evento(
                                    "üß≠ Compuerta REAL abierta: "
                                    f"{dyn_gate.get('best_bot','--')} | "
                                    f"p_best={float(dyn_gate.get('p_best',0.0))*100:.1f}% "
                                    f"roof_eff={float(dyn_gate.get('roof_eff',0.0))*100:.1f}% "
                                    f"floor={float(dyn_gate.get('floor_eff',0.0))*100:.1f}% "
                                    f"gap_ok={'s√≠' if dyn_gate.get('gap_ok') else 'no'} "
                                    f"cross={'s√≠' if dyn_gate.get('crossed_up') else 'no'} "
                                    f"suceso={'s√≠' if dyn_gate.get('suceso_ok') else 'no'} "
                                    f"mode={dyn_gate.get('gate_mode','A')} "
                                    f"stall={int(float(dyn_gate.get('stall_s',0.0))//60)}m "
                                    f"confirm={int(dyn_gate.get('confirm_streak',0))}/{int(dyn_gate.get('confirm_need', DYN_ROOF_CONFIRM_TICKS))}"
                                )
                        else:
                            umbral_ia_real = max(float(REAL_TRIGGER_MIN), float(get_umbral_real_calibrado()))
                            dyn_gate = None

                        # Saldo informativo: no bloquear por colch√≥n completo, solo por ciclo ejecutable.
                        try:
                            saldo_val = float(obtener_valor_saldo() or 0.0)
                        except Exception:
                            saldo_val = 0.0
                        costo_ciclo1 = float(MARTI_ESCALADO[0])
                        costo_plan = float(sum(MARTI_ESCALADO[:max(1, int(MAX_CICLOS))]))

                        # Candidatos: prob v√°lida, reciente, IA activa (no OFF)
                        candidatos = []
                        diag_gate = _leer_gate_desde_diagnostico(ttl_s=60.0)
                        if not lock_activo:
                            for b in BOT_NAMES:
                                try:
                                    modo_b = str(estado_bots.get(b, {}).get("modo_ia", "off")).lower()
                                    if modo_b == "off":
                                        continue
                                    if not ia_prob_valida(b, max_age_s=12.0):
                                        continue
                                    # Redundancia: no bloquear en seco; aplicar penalizaci√≥n de score y desempate posterior.
                                    redundante_tick = bool(estado_bots.get(b, {}).get("ia_input_redundante", False))

                                    p = estado_bots[b].get("prob_ia", None)
                                    if not isinstance(p, (int, float)):
                                        continue
                                    # Primer filtro suave: evitar basura por debajo del piso operativo.
                                    piso_operativo = float(_umbral_real_operativo_actual()) if REAL_CLASSIC_GATE else float(IA_ACTIVACION_REAL_THR)
                                    if float(p) < float(piso_operativo):
                                        continue

                                    # Modo cl√°sico reforzado: compuerta din√°mica anti-bug.
                                    # Solo el mejor bot del tick puede pasar, con piso duro + GAP + confirmaci√≥n doble.
                                    if REAL_CLASSIC_GATE:
                                        if not isinstance(dyn_gate, dict):
                                            continue
                                        if b != dyn_gate.get("best_bot"):
                                            continue
                                        if not bool(dyn_gate.get("allow_real", False)):
                                            continue

                                        regime_score = _score_regimen_contexto(_ultimo_contexto_operativo_bot(b))
                                        p_post = float(p)
                                        score_final = float(p_post)
                                        estado_bots[b]["ia_regime_score"] = float(regime_score)
                                        estado_bots[b]["ia_evidence_n"] = int(estado_bots[b].get("ia_evidence_n", 0) or 0)
                                        estado_bots[b]["ia_evidence_wr"] = float(estado_bots[b].get("ia_evidence_wr", 0.0) or 0.0)
                                        candidatos.append((float(score_final), b, float(p), float(p_post), float(regime_score), 0, 0.0, 0.0))
                                        continue

                                    # 1) Gate de calidad por racha/rebote (priorizar precisi√≥n real)
                                    ctx = _ultimo_contexto_operativo_bot(b)
                                    racha_now = float(ctx.get("racha_actual", 0.0) or 0.0)
                                    rebote_now = float(ctx.get("es_rebote", 0.0) or 0.0)
                                    if racha_now <= float(GATE_RACHA_NEG_BLOQUEO):
                                        if not (bool(GATE_PERMITE_REBOTE_EN_NEG) and rebote_now >= 0.5):
                                            continue

                                    # 2) Validaci√≥n por r√©gimen/activo (evita mezclar HZ con mal tramo reciente)
                                    activo_now = str(ctx.get("activo", "") or "").strip()
                                    ok_reg, wr_reg, n_reg = _gate_regimen_activo_ok(b, activo=activo_now)
                                    if not ok_reg:
                                        agregar_evento(
                                            f"üßØ Gate r√©gimen: {b}/{activo_now or 'NA'} bloqueado "
                                            f"(WR{n_reg}={wr_reg*100:.1f}% < {GATE_ACTIVO_MIN_WR*100:.1f}%)."
                                        )
                                        continue

                                    # 3) Gate por segmento (payout/vol/hora) para ejecutar donde hay m√°s se√±al estable
                                    ok_seg, wr_seg, n_seg, seg_key = _gate_segmento_ok(b, ctx)
                                    if not ok_seg:
                                        agregar_evento(
                                            f"üß± Gate segmento: {b}/{seg_key} bloqueado "
                                            f"(WR{n_seg}={wr_seg*100:.1f}% < {GATE_SEGMENTO_MIN_WR*100:.1f}%)."
                                        )
                                        continue

                                    # 4) Capa A del embudo: score de r√©gimen
                                    regime_score = _score_regimen_contexto(ctx)
                                    if regime_score < float(REGIME_GATE_MIN_SCORE):
                                        continue

                                    # 5) √çndice de evidencia por bot en umbral objetivo (evita inflar 0.70+ sin soporte)
                                    ev = _evidencia_bot_umbral_objetivo(b)
                                    ev_n = int(ev.get("n", 0) or 0)
                                    ev_wr = float(ev.get("wr", 0.0) or 0.0)
                                    ev_lb = float(ev.get("lb", 0.0) or 0.0)
                                    if (ev_n >= int(EVIDENCE_MIN_N_HARD)) and (not bool(ev.get("ok_hard", True))):
                                        agregar_evento(
                                            f"üß™ Evidencia: {b} bloqueado (n={ev_n}, WR={ev_wr*100:.1f}%, LB={ev_lb*100:.1f}% < LB_min {EVIDENCE_MIN_LB_HARD*100:.1f}%)."
                                        )
                                        continue

                                    # Candado blando: con muestra intermedia exigimos LB m√≠nimo intermedio.
                                    if (ev_n >= int(EVIDENCE_MIN_N_SOFT)) and (ev_lb < float(EVIDENCE_MIN_LB_SOFT)):
                                        continue

                                    # 6) Prob REAL posterior (modelo + r√©gimen + evidencia + bound)
                                    p_post = _prob_real_posterior(float(p), float(regime_score), int(ev_n), float(ev_wr), float(ev_lb))

                                    # Guardas por bot (alineadas al HUD): evitar promoci√≥n cuando hay
                                    # desalineaci√≥n severa entre probabilidad y performance real reciente.
                                    if (ev_n >= int(EVIDENCE_MIN_N_SOFT)) and (ev_wr < float(IA_PROMO_MIN_WR_POR_BOT)):
                                        agregar_evento(
                                            f"üß± Guarda WR bot: {b} bloqueado (WR={ev_wr*100:.1f}% < {IA_PROMO_MIN_WR_POR_BOT*100:.1f}%, n={ev_n})."
                                        )
                                        continue
                                    overconf_gap = float(p_post) - float(ev_wr)
                                    if (ev_n >= int(EVIDENCE_MIN_N_SOFT)) and (overconf_gap > float(IA_PROMO_MAX_OVERCONF_GAP)):
                                        agregar_evento(
                                            f"üßØ Guarda calibraci√≥n: {b} bloqueado (p_real-WR={overconf_gap*100:.1f}pp > {IA_PROMO_MAX_OVERCONF_GAP*100:.1f}pp)."
                                        )
                                        continue

                                    # Guardas por bot (alineadas al HUD): evitar promoci√≥n cuando hay
                                    # desalineaci√≥n severa entre probabilidad y performance real reciente.
                                    if (ev_n >= int(EVIDENCE_MIN_N_SOFT)) and (ev_wr < float(IA_PROMO_MIN_WR_POR_BOT)):
                                        agregar_evento(
                                            f"üß± Guarda WR bot: {b} bloqueado (WR={ev_wr*100:.1f}% < {IA_PROMO_MIN_WR_POR_BOT*100:.1f}%, n={ev_n})."
                                        )
                                        continue
                                    overconf_gap = float(p_post) - float(ev_wr)
                                    if (ev_n >= int(EVIDENCE_MIN_N_SOFT)) and (overconf_gap > float(IA_PROMO_MAX_OVERCONF_GAP)):
                                        agregar_evento(
                                            f"üßØ Guarda calibraci√≥n: {b} bloqueado (p_real-WR={overconf_gap*100:.1f}pp > {IA_PROMO_MAX_OVERCONF_GAP*100:.1f}pp)."
                                        )
                                        continue

                                    # Candado final: el umbral REAL se valida sobre la probabilidad posterior (no p_model)
                                    thr_post = float(umbral_ia_real)
                                    if ev_n < int(EVIDENCE_MIN_N_SOFT):
                                        thr_post = min(0.99, thr_post + float(EVIDENCE_LOW_N_EXTRA_MARGIN))
                                    if float(p_post) < float(thr_post):
                                        continue

                                    # Candado anti-overconfidence global: si el diagn√≥stico reporta gap alto,
                                    # solo promover con evidencia fuerte (LB + N) aunque p_post supere umbral.
                                    if bool(diag_gate.get("force_evidence", False)):
                                        if not ((ev_n >= int(EVIDENCE_MIN_N_HARD)) and (ev_lb >= float(EVIDENCE_MIN_LB_HARD))):
                                            continue

                                    # 7) Ranking final (Capa B + r√©gimen + evidencia)
                                    evidence_score = min(1.0, p_post + min(0.15, ev_n / 400.0))
                                    suceso_idx_b = float(estado_bots.get(b, {}).get("ia_suceso_idx", 0.0) or 0.0) / 100.0
                                    sensor_plano_b = bool(estado_bots.get(b, {}).get("ia_sensor_plano", False))
                                    score_final = (
                                        float(REGIME_GATE_WEIGHT_PROB) * float(p_post)
                                        + float(REGIME_GATE_WEIGHT_REGIME) * float(regime_score)
                                        + float(REGIME_GATE_WEIGHT_EVIDENCE) * float(evidence_score)
                                        + float(IA_SUCESO_SCORE_WEIGHT) * float(max(0.0, min(1.0, suceso_idx_b)))
                                    )
                                    if redundante_tick:
                                        score_final = float(score_final) - float(IA_REDUNDANCY_SCORE_PENALTY)
                                    if sensor_plano_b:
                                        score_final = float(score_final) - float(IA_SENSOR_PLANO_SCORE_PENALTY)

                                    estado_bots[b]["ia_regime_score"] = float(regime_score)
                                    estado_bots[b]["ia_evidence_n"] = int(ev_n)
                                    estado_bots[b]["ia_evidence_wr"] = float(ev_wr)

                                    candidatos.append((float(score_final), b, float(p), float(p_post), float(regime_score), int(ev_n), float(ev_wr), float(ev_lb)))
                                except Exception:
                                    continue

                            candidatos.sort(key=lambda x: x[0], reverse=True)

                            # Selecci√≥n autom√°tica: tomar la mejor se√±al elegible >= umbral REAL vigente.

                        # Si hay se√±al y el saldo no cubre el plan completo, solo avisar (no bloquear).
                        if candidatos and saldo_val < costo_plan:
                            ahora_warn = time.time()
                            last_warn = float(DYN_ROOF_STATE.get("last_low_balance_warn_ts", 0.0) or 0.0)
                            if (ahora_warn - last_warn) >= float(DYN_ROOF_LOW_BAL_WARN_COOLDOWN_S):
                                if saldo_val >= costo_ciclo1:
                                    agregar_evento(
                                        f"‚ÑπÔ∏è Saldo parcial: cubre C1 ({costo_ciclo1:.2f}) pero no C1..C{int(MAX_CICLOS)} ({costo_plan:.2f})."
                                    )
                                else:
                                    falta = costo_ciclo1 - saldo_val
                                    agregar_evento(
                                        f"‚ö†Ô∏è Saldo insuficiente para C1: faltan {falta:.2f} USD (C1={costo_ciclo1:.2f})."
                                    )
                                DYN_ROOF_STATE["last_low_balance_warn_ts"] = float(ahora_warn)

                        # ==================== AUTO-PRESELECCI√ìN (MODO MANUAL) ====================
                        # Si la IA detecta se√±al y t√∫ est√°s en manual, preselecciona el mejor bot y abre la ventana
                        # para que solo elijas el ciclo (1..MAX_CICLOS) dentro del tiempo.
                        if MODO_REAL_MANUAL:
                            ahora = time.time()

                            # Si expir√≥, limpiamos
                            if PENDIENTE_FORZAR_BOT and PENDIENTE_FORZAR_EXPIRA and ahora > PENDIENTE_FORZAR_EXPIRA:
                                agregar_evento("‚åõ Ventana de decisi√≥n expirada. Se√±al descartada.")
                                PENDIENTE_FORZAR_BOT = None
                                PENDIENTE_FORZAR_INICIO = 0.0
                                PENDIENTE_FORZAR_EXPIRA = 0.0

                            owner = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else leer_token_actual()
                            if candidatos and (PENDIENTE_FORZAR_BOT is None) and (owner in (None, "none")):
                                ciclo_auto = ciclo_martingala_siguiente()
                                if reset_martingala_por_saldo(ciclo_auto, saldo_val):
                                    ciclo_auto = 1
                                mejor = elegir_candidato_rotacion_marti(candidatos, ciclo_auto)
                                if mejor is None and int(ciclo_auto) > 1:
                                    agregar_evento(f"üßØ Rotaci√≥n C{ciclo_auto}: sin bot nuevo elegible. No se repite bot en esta martingala.")
                                if mejor is not None:
                                    score_top, mejor_bot, prob, p_post, reg_score, ev_n, ev_wr, ev_lb = mejor
                                    agregar_evento(f"üß† Embudo IA: {mejor_bot} score={score_top*100:.1f}% | p_model={prob*100:.1f}% | p_real={p_post*100:.1f}% | reg={reg_score*100:.1f}% | WR={ev_wr*100:.1f}% LB={ev_lb*100:.1f}% (n={ev_n})")
                                    PENDIENTE_FORZAR_BOT = mejor_bot
                                    PENDIENTE_FORZAR_INICIO = ahora
                                    PENDIENTE_FORZAR_EXPIRA = ahora + VENTANA_DECISION_IA_S

                                    # marcamos se√±al pendiente (sirve para contabilidad IA luego)
                                    estado_bots[mejor_bot]["ia_senal_pendiente"] = True
                                    estado_bots[mejor_bot]["ia_prob_senal"] = prob

                                    agregar_evento(
                                        f"üü¢ Se√±al IA en {mejor_bot} ({prob*100:.1f}%). "
                                        f"Tienes {VENTANA_DECISION_IA_S}s para elegir ciclo [1..{MAX_CICLOS}] o ESC."
                                    )
                        # ==================== /AUTO-PRESELECCI√ìN ====================

                        if candidatos and not MODO_REAL_MANUAL:
                            meta_live = resolver_canary_estado(leer_model_meta() or {})
                            modelo_reliable = bool(meta_live.get("reliable", False))
                            canary_mode_live = bool(meta_live.get("canary_mode", False))
                            if canary_mode_live:
                                c_prog = int(meta_live.get("canary_closed_signals", 0) or 0)
                                c_tgt = int(meta_live.get("canary_target_closed", 0) or 0)
                                c_hit = float(meta_live.get("canary_hitrate", 0.0) or 0.0) * 100.0
                                canary_escape = False
                                canary_escape_why = ""
                                try:
                                    dgate = dyn_gate if isinstance(dyn_gate, dict) else {}
                                    p_best_d = float(dgate.get("p_best", 0.0) or 0.0)
                                    c_streak_d = int(dgate.get("confirm_streak", 0) or 0)
                                    trig_ok_d = bool(dgate.get("trigger_ok", False))
                                    if bool(CANARY_ALLOW_STRONG_GATE_REAL) and bool(dgate.get("allow_real", False)):
                                        if (
                                            p_best_d >= float(CANARY_STRONG_GATE_MIN_PROB)
                                            and c_streak_d >= int(CANARY_STRONG_GATE_MIN_CONFIRM)
                                            and trig_ok_d
                                        ):
                                            canary_escape = True
                                            canary_escape_why = (
                                                f"p_best={p_best_d*100:.1f}% confirm={c_streak_d} trigger_ok=s√≠"
                                            )
                                except Exception:
                                    canary_escape = False

                                if canary_escape:
                                    agregar_evento(
                                        f"üü† IA AUTO CANARY escape: se habilita REAL por compuerta fuerte ({canary_escape_why})."
                                    )
                                else:
                                    agregar_evento(
                                        f"üü° IA AUTO en CANARY: REAL bloqueado temporalmente ({c_prog}/{c_tgt}, hit={c_hit:.1f}%)."
                                    )
                                    candidatos = []
                            elif not modelo_reliable:
                                n_samples_live = int(meta_live.get("n_samples", meta_live.get("n", 0)) or 0)
                                auc_live = float(meta_live.get("auc", 0.0) or 0.0)
                                warmup_live = bool(meta_live.get("warmup_mode", n_samples_live < int(TRAIN_WARMUP_MIN_ROWS)))
                                post_n15 = bool(_todos_bots_con_n_minimo_real())
                                best_prob = max((float(x[2]) for x in candidatos), default=0.0)
                                best_bot_local = None
                                try:
                                    best_bot_local = max(candidatos, key=lambda x: float(x[2]))[1] if candidatos else None
                                except Exception:
                                    best_bot_local = None
                                unrel_thr_live = float(_umbral_unrel_operativo(best_bot_local, best_prob))
                                gate_strong_unrel = False
                                try:
                                    dgate = dyn_gate if isinstance(dyn_gate, dict) else {}
                                    gate_strong_unrel = bool(
                                        AUTO_REAL_UNRELIABLE_ALLOW_STRONG_GATE
                                        and bool(dgate.get("allow_real", False))
                                        and bool(dgate.get("trigger_ok", False))
                                        and (float(dgate.get("p_best", 0.0) or 0.0) >= float(AUTO_REAL_UNRELIABLE_GATE_MIN_PROB))
                                    )
                                except Exception:
                                    gate_strong_unrel = False
                                allow_unreliable = bool(
                                    AUTO_REAL_ALLOW_UNRELIABLE_POST_N15
                                    and post_n15
                                    and (n_samples_live >= int(AUTO_REAL_UNRELIABLE_MIN_N))
                                    and (best_prob >= float(unrel_thr_live))
                                    and (auc_live >= float(AUTO_REAL_UNRELIABLE_MIN_AUC))
                                    and ((not (bool(AUTO_REAL_BLOCK_WHEN_WARMUP) and warmup_live)) or bool(gate_strong_unrel))
                                )
                                if allow_unreliable:
                                    if gate_strong_unrel and warmup_live:
                                        agregar_evento(
                                            f"üü† IA AUTO bypass warmup: compuerta fuerte habilita REAL "
                                            f"(p_best={best_prob*100:.1f}%, n={n_samples_live}, auc={auc_live:.3f})."
                                        )
                                    else:
                                        agregar_evento(
                                            f"‚ö†Ô∏è IA AUTO modo adaptativo: reliable=false, pero se habilita por post-n15 "
                                            f"(n={n_samples_live}, auc={auc_live:.3f}, p_best={best_prob*100:.1f}%)."
                                        )
                                else:
                                    why_nr = []
                                    if n_samples_live < int(AUTO_REAL_UNRELIABLE_MIN_N):
                                        why_nr.append(f"n<{int(AUTO_REAL_UNRELIABLE_MIN_N)}")
                                    if best_prob < float(unrel_thr_live):
                                        why_nr.append(f"p_best<{unrel_thr_live*100:.0f}%")
                                    if auc_live < float(AUTO_REAL_UNRELIABLE_MIN_AUC):
                                        why_nr.append(f"auc<{AUTO_REAL_UNRELIABLE_MIN_AUC:.2f}")
                                    if bool(AUTO_REAL_BLOCK_WHEN_WARMUP) and warmup_live:
                                        why_nr.append("warmup")
                                    why_nr_txt = ", ".join(why_nr) if why_nr else "regla_adapt"
                                    agregar_evento(
                                        f"üõ°Ô∏è IA AUTO bloqueado: modelo no confiable (reliable=false, {why_nr_txt})."
                                    )
                                    candidatos = []
                            elif time.time() < float(REAL_COOLDOWN_UNTIL_TS):
                                restantes = max(0.0, float(REAL_COOLDOWN_UNTIL_TS) - time.time())
                                agregar_evento(f"‚è≥ IA AUTO cooldown post-trade activo ({restantes:.0f}s).")
                                candidatos = []

                        if candidatos and not MODO_REAL_MANUAL:
                            ciclo_auto = ciclo_martingala_siguiente()
                            if reset_martingala_por_saldo(ciclo_auto, saldo_val):
                                ciclo_auto = 1
                            mejor = elegir_candidato_rotacion_marti(candidatos, ciclo_auto)
                            if mejor is None and int(ciclo_auto) > 1:
                                agregar_evento(f"üßØ IA AUTO C{ciclo_auto}: sin bot nuevo elegible. Se omite entrada para evitar repetici√≥n.")
                            if mejor is not None:
                                score_top, mejor_bot, prob, p_post, reg_score, ev_n, ev_wr, ev_lb = mejor
                                agregar_evento(f"‚öôÔ∏è IA AUTO: {mejor_bot} score={score_top*100:.1f}% | p_model={prob*100:.1f}% | p_real={p_post*100:.1f}% | reg={reg_score*100:.1f}% | WR={ev_wr*100:.1f}% LB={ev_lb*100:.1f}% (n={ev_n})")
                                monto = MARTI_ESCALADO[max(0, min(len(MARTI_ESCALADO)-1, ciclo_auto - 1))]
                                val = obtener_valor_saldo()
                                if val is None or val < monto:
                                    pass
                                else:
                                    estado_bots[mejor_bot]["ia_senal_pendiente"] = True
                                    estado_bots[mejor_bot]["ia_prob_senal"] = prob

                                    # Handoff entre ciclos REAL: si qued√≥ lock residual de otro bot,
                                    # liberarlo antes de emitir la nueva orden para no bloquear rotaci√≥n.
                                    owner_prev = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else None
                                    if owner_prev and owner_prev != mejor_bot and ciclo_auto > 1:
                                        cerrar_por_fin_de_ciclo(owner_prev, f"Handoff rotaci√≥n C{ciclo_auto}‚Üí{mejor_bot}")

                                    ok_real = escribir_orden_real(mejor_bot, ciclo_auto)
                                    if ok_real:
                                        estado_bots[mejor_bot]["fuente"] = "IA_AUTO"
                                        estado_bots[mejor_bot]["ciclo_actual"] = ciclo_auto
                                        activo_real = REAL_OWNER_LOCK if REAL_OWNER_LOCK in BOT_NAMES else mejor_bot
                                        marti_activa = True
                                    else:
                                        estado_bots[mejor_bot]["ia_senal_pendiente"] = False
                                        estado_bots[mejor_bot]["ia_prob_senal"] = None
                        else:
                            max_prob = max((estado_bots[bot]["prob_ia"] for bot in BOT_NAMES if estado_bots[bot]["ia_ready"]), default=0)
                            if max_prob < umbral_ia_real:
                                pass

                    set_etapa("TICK_04")
                    await refresh_saldo_real()
                    if meta_mostrada and not pausado and not MODAL_ACTIVO:
                        mostrar_advertencia_meta()
                    if not MODAL_ACTIVO:
                        with RENDER_LOCK:
                            mostrar_panel()
            except Exception as e:
                set_etapa("TICK_04", f"Error: {str(e)}")
                agregar_evento(f"‚ö†Ô∏è Error en loop principal: {str(e)}")
                await asyncio.sleep(1)  
            await asyncio.sleep(2)
    except Exception as e:
        set_etapa("STOP", f"Error en main: {str(e)}", anunciar=True)
        agregar_evento(f"‚õî Error en main: {str(e)}")
        _log_exception("Error en main()", e)

if __name__ == "__main__":
    # ============================================
    # MODO LIMPIEZA INICIAL (Opci√≥n A datos buenos)
    # ============================================
    MODO_LIMPIEZA_DATASET = False  # ‚Üê PONER True SOLO PARA EJECUTAR LA LIMPIEZA UNA VEZ

    if MODO_LIMPIEZA_DATASET:
        print("\nüöø MODO LIMPIEZA DATASET_INCREMENTAL ACTIVADO")
        print("   - Se borrar√° dataset_incremental.csv")
        print("   - Se borrar√°n modelo_ia.json y meta_ia.json")
        print("   - Luego se reconstruir√° dataset_incremental.csv")
        print("     usando las √∫ltimas 500 filas enriquecidas de cada bot.\n")

        try:
            # 1) Borrar dataset_incremental + modelo + meta
            resetear_incremental_y_modelos(borrar_modelos=True)

            # 2) Volver a llenar dataset_incremental SOLO con datos enriquecidos buenos
            backfill_incremental(ultimas=500)

            print("\n‚úÖ Limpieza + backfill completados correctamente.")
            print("   dataset_incremental.csv ahora contiene solo filas con:")
            print("   volatilidad, es_rebote, hora_bucket y resto de features nuevas.")
        except Exception as e:
            print(f"\n‚õî Error durante limpieza/backfill: {e}")

        input("\nPulsa ENTER para cerrar este modo, luego edita el archivo y pon MODO_LIMPIEZA_DATASET = False.")
        sys.exit(0)

    # ======================
    # MODO NORMAL (loop loop)
    # ======================
    while True:  
        try:
            asyncio.run(main())
        except KeyboardInterrupt:
            print("\nüî¥ Programa terminado por el usuario.")
            break
        except Exception as e:
            print(f"‚õî Error cr√≠tico: {str(e)}")
            _log_exception("Error cr√≠tico en __main__", e)
            time.sleep(5)

# === FIN BLOQUE 13 ===
# === BLOQUE 99 ‚Äî RESUMEN FINAL DE LO QUE SE LOGRA ===
#
# - Bot maestro 5R6M-1-2-4-8-16 con:
#   * Martingala 1-2-4-8-16 intacta.
#   * Tokens DEMO/REAL y handshake maestro‚Üíbots intactos.
#   * CSV enriquecidos, dataset_incremental.csv, IA XGBoost, reentrenos intactos.
#   * HUD visual con Prob IA, % √©xito, saldo, meta, eventos
#   * Audio para GANANCIA/P√âRDIDA, racha, meta, IA 53%, etc.
# - Organizaci√≥n por bloques numerados:
#   ver √≠ndice de bloques al inicio del archivo.
#
# Esta organizaci√≥n no cambia la l√≥gica original, solo la hace m√°s mantenible.
# === FIN BLOQUE 99 ===
